{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f663b545",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os, glob, re, itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d36462",
   "metadata": {},
   "source": [
    "## 1. Working on 'combined.csv' (CRM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191316ef",
   "metadata": {},
   "source": [
    "### Write out a combined dataframe for every log, every random/ipweights, every encoding, every k0, to 5_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_root  = \"4_output\"\n",
    "output_root = \"5_analysis\"\n",
    "\n",
    "# Walk k-fold directories, merge per-encoding CSVs, add metadata, compute UB OR, and write combined.csv\n",
    "for dirpath, dirnames, filenames in os.walk(input_root):\n",
    "    base = os.path.basename(dirpath)\n",
    "    if not base.startswith(\"k\"):\n",
    "        continue\n",
    "\n",
    "    csv_pattern = os.path.join(dirpath, \"*\", \"*.csv\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    if not csv_files:\n",
    "        continue\n",
    "\n",
    "    pieces = []\n",
    "    for fp in csv_files:\n",
    "        method_name = os.path.basename(os.path.dirname(fp))\n",
    "\n",
    "        # 1) Read metrics CSV (semicolon-delimited)\n",
    "        try:\n",
    "            df = pd.read_csv(fp, sep=\";\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipped {fp} due to read error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 2) Read the single .txt alongside the CSV (runtime in seconds)\n",
    "        txt_pattern = os.path.join(os.path.dirname(fp), \"*.txt\")\n",
    "        txt_files = glob.glob(txt_pattern)\n",
    "        if txt_files:\n",
    "            try:\n",
    "                with open(txt_files[0], \"r\") as f:\n",
    "                    txt_val = f.read().strip()\n",
    "                try:\n",
    "                    txt_val = float(txt_val)\n",
    "                except ValueError:\n",
    "                    pass  # keep as string if not numeric\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not read {txt_files[0]}: {e}\")\n",
    "                txt_val = None\n",
    "        else:\n",
    "            txt_val = None\n",
    "\n",
    "        # 3) Compute UB odds ratio from OR and LB OR (normal approx)\n",
    "        std_err_or = (np.log(df[\"Odds ratio\"]) - np.log(df[\"LB odds ratio\"])) / 1.96\n",
    "        df[\"UB odds ratio\"] = np.exp(np.log(df[\"Odds ratio\"]) + 1.96 * std_err_or)\n",
    "\n",
    "        # 4) Attach metadata\n",
    "        df[\"Feature Encoding\"]  = method_name\n",
    "        df[\"Filename\"]          = os.path.basename(fp)\n",
    "        df[\"Runtime (seconds)\"] = txt_val\n",
    "\n",
    "        pieces.append(df)\n",
    "\n",
    "    # 5) Concatenate per-k directory and write to mirror path in output_root\n",
    "    combined = pd.concat(pieces, ignore_index=True)\n",
    "    relative_subpath = os.path.relpath(dirpath, input_root)\n",
    "    save_dir = os.path.join(output_root, relative_subpath)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    out_fp = os.path.join(save_dir, \"combined.csv\")\n",
    "    combined.to_csv(out_fp, index=False, sep=\",\")\n",
    "    print(f\"✅ Saved combined.csv for {base} → {out_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bde1a9",
   "metadata": {},
   "source": [
    "### Load a single 'combined' from 5_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read a combined CSV and move 'Feature Encoding' to the first column\n",
    "# file_path = \"5_analysis/random/sepsis/sepsis_decl_features/k2/combined.csv\"\n",
    "# combined = pd.read_csv(file_path)\n",
    "\n",
    "# # Reorder columns: put 'Feature Encoding' first\n",
    "# cols = combined.columns.tolist()\n",
    "# cols.pop(cols.index(\"Feature Encoding\"))\n",
    "# cols.insert(0, \"Feature Encoding\")\n",
    "# combined = combined[cols]\n",
    "\n",
    "# combined.round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954c4f6",
   "metadata": {},
   "source": [
    "## 2. Working on 'aggregated.csv' (CRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53528121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that helps counting the number of variables in the LHS of a rule\n",
    "# (e.g., in \"['A', 'B', 'C']\" it returns 3)\n",
    "# this is a difficult task because variables can contain commas, apostrophes, and nested brackets\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Helper to count how many top-level elements are inside the leading [...] in Rule\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def count_lhs_vars(rule: str) -> int:\n",
    "    text = rule\n",
    "    start = text.find('[')\n",
    "    if start < 0:\n",
    "        return 0\n",
    "\n",
    "    # find matching ]\n",
    "    depth = 0\n",
    "    in_s = in_d = esc = False\n",
    "    end = None\n",
    "    for i, ch in enumerate(text[start:], start):\n",
    "        if esc:\n",
    "            esc = False\n",
    "            continue\n",
    "        if ch == '\\\\':\n",
    "            esc = True\n",
    "            continue\n",
    "\n",
    "        if in_s:\n",
    "            if ch == \"'\":\n",
    "                in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            if ch == '\"':\n",
    "                in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\":\n",
    "            in_s = True\n",
    "            continue\n",
    "        if ch == '\"':\n",
    "            in_d = True\n",
    "            continue\n",
    "\n",
    "        if ch == '[':\n",
    "            depth += 1\n",
    "            continue\n",
    "        if ch == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                end = i\n",
    "                break\n",
    "\n",
    "    if end is None:\n",
    "        return 0\n",
    "\n",
    "    # split on commas outside of any quotes\n",
    "    content = text[start+1:end]\n",
    "    parts = []\n",
    "    curr = \"\"\n",
    "    in_s = in_d = esc = False\n",
    "    for ch in content:\n",
    "        if esc:\n",
    "            curr += ch\n",
    "            esc = False\n",
    "            continue\n",
    "        if ch == '\\\\':\n",
    "            curr += ch\n",
    "            esc = True\n",
    "            continue\n",
    "\n",
    "        if in_s:\n",
    "            curr += ch\n",
    "            if ch == \"'\":\n",
    "                in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            curr += ch\n",
    "            if ch == '\"':\n",
    "                in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\":\n",
    "            curr += ch\n",
    "            in_s = True\n",
    "            continue\n",
    "        if ch == '\"':\n",
    "            curr += ch\n",
    "            in_d = True\n",
    "            continue\n",
    "\n",
    "        # only split top-level commas\n",
    "        if ch == ',':\n",
    "            parts.append(curr.strip())\n",
    "            curr = \"\"\n",
    "        else:\n",
    "            curr += ch\n",
    "\n",
    "    # final element\n",
    "    if curr or content == \"\":\n",
    "        parts.append(curr.strip())\n",
    "\n",
    "    return len(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f0c5b",
   "metadata": {},
   "source": [
    "### automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba619e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Walk every subfolder of your analysis output and rebuild `aggregated.csv`\n",
    "# -------------------------------------------------------------------------\n",
    "input_root = '5_analysis'\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(input_root):\n",
    "    if 'combined.csv' not in filenames:\n",
    "        continue\n",
    "\n",
    "    combined_fp = os.path.join(dirpath, 'combined.csv')\n",
    "    df = pd.read_csv(combined_fp, sep=',')\n",
    "\n",
    "    # 1) Flags\n",
    "    df['is_lb_or_gt1'] = df['LB odds ratio'] > 1\n",
    "    df['neg_or'] = df['is_lb_or_gt1'] & df['Rule'].str.endswith('!Label')\n",
    "    df['pos_or'] = df['is_lb_or_gt1'] & ~df['Rule'].str.endswith('!Label')\n",
    "    df['n_vars'] = df['Rule'].apply(count_lhs_vars)\n",
    "    for k in (1, 2, 3):\n",
    "        df[f'k={k}'] = ((df['n_vars'] == k) & df['is_lb_or_gt1']).astype(int)\n",
    "\n",
    "    # 2) First-seen runtime → minutes\n",
    "    first_rts = df.groupby('Feature Encoding')['Runtime (seconds)'].first()\n",
    "    runtime_mins = (first_rts / 60).round(2)\n",
    "\n",
    "    # 3) Aggregation\n",
    "    aggregated = (\n",
    "        df\n",
    "        .groupby('Feature Encoding')\n",
    "        .agg(\n",
    "            **{\n",
    "                'Total Rules': ('Rule', 'count'),\n",
    "                'Rules LB OR>1': ('is_lb_or_gt1', 'sum'),\n",
    "                'Positive Rules': ('pos_or', 'sum'),\n",
    "                'Negative Rules': ('neg_or', 'sum'),\n",
    "                **{f'k={k}': (f'k={k}', 'sum') for k in (1, 2, 3)},\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 4) Add runtime columns\n",
    "    aggregated['Runtime (Minutes)'] = aggregated['Feature Encoding'].map(runtime_mins)\n",
    "    aggregated['Runtime (Hours)'] = (aggregated['Runtime (Minutes)'] / 60).round(2)\n",
    "\n",
    "    # 5) Write out\n",
    "    out_fp = os.path.join(dirpath, 'aggregated.csv')\n",
    "    aggregated.to_csv(out_fp, index=False, sep=',')\n",
    "\n",
    "    print(f\"✅ Saved aggregated.csv for {dirpath} → {out_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa108e96",
   "metadata": {},
   "source": [
    "## 3. Create 'combined_sorted.csv' (CRM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5940d6",
   "metadata": {},
   "source": [
    "### Per K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory containing your experiment subfolders\n",
    "root_dir = '5_analysis/random/BPI15A/BPI15A_payload_560925_features'\n",
    "# Pattern to match all combined.csv files recursively\n",
    "pattern = os.path.join(root_dir, '**', 'combined.csv')\n",
    "\n",
    "for file_path in glob.glob(pattern, recursive=True):\n",
    "    save_dir = os.path.dirname(file_path)\n",
    "    base = os.path.basename(save_dir)\n",
    "    \n",
    "    # 1) Load your combined.csv\n",
    "    combined = pd.read_csv(file_path, sep=',')\n",
    "    \n",
    "    # 2) Sort on LB odds ratio descending\n",
    "    combined = combined.sort_values(by='LB odds ratio', ascending=False)\n",
    "\n",
    "    # 3) Drop all where LB odds ratio <= 1\n",
    "    combined = combined[combined['LB odds ratio'] > 1]\n",
    "\n",
    "    # 4) Round all numeric columns to 3 decimal places\n",
    "    float_cols = combined.select_dtypes(include=['float64']).columns\n",
    "    combined[float_cols] = combined[float_cols].round(3)\n",
    "\n",
    "    # 5) Drop unwanted columns\n",
    "    combined = combined.drop(columns=['Support RHS', 'Filename', 'Runtime (seconds)'])\n",
    "\n",
    "    # 6) Move 'Feature Encoding' to second column\n",
    "    cols = combined.columns.tolist()\n",
    "    cols.insert(1, cols.pop(cols.index('Feature Encoding')))\n",
    "    combined = combined[cols]\n",
    "\n",
    "    # 6.1) Move 'UB odds ratio' to fifth column\n",
    "    cols = combined.columns.tolist()\n",
    "    cols.insert(4, cols.pop(cols.index('UB odds ratio')))\n",
    "    combined = combined[cols]\n",
    "\n",
    "    # 7) Export to CSV\n",
    "    out_fp_csv = os.path.join(save_dir, 'combined_sorted.csv')\n",
    "    combined.to_csv(out_fp_csv, index=False, sep=',')\n",
    "    print(f\"✅ Saved combined_sorted.csv for {base} → {out_fp_csv}\")\n",
    "\n",
    "    # 8) Export to LaTeX\n",
    "    out_fp_tex = os.path.join(save_dir, 'combined_sorted.tex')\n",
    "    def fmt_rule(x):\n",
    "        # wrap in \\detokenize{…} so TeX will not parse special chars\n",
    "        return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "    combined.to_latex(\n",
    "        out_fp_tex,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        float_format=\"%.2f\",\n",
    "        formatters={\n",
    "            \"Rule\": fmt_rule,\n",
    "            \"Feature Encoding\": fmt_rule\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved combined_sorted.tex for {base} → {out_fp_tex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb13b36",
   "metadata": {},
   "source": [
    "### Per Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory containing your experiment subfolders\n",
    "root_dir = '5_analysis/DHL/dhl/dhl_features'\n",
    "# Pattern to match all combined.csv files one level down (e.g., k1/combined.csv, k2/combined.csv)\n",
    "pattern = os.path.join(root_dir, '*', 'combined.csv')\n",
    "\n",
    "# Find all matching files\n",
    "file_paths = glob.glob(pattern)\n",
    "if not file_paths:\n",
    "    print(f\"🚨 No combined.csv files found under {root_dir}\")\n",
    "else:\n",
    "    # Read and concatenate all dataframes\n",
    "    df_list = [pd.read_csv(fp, sep=',') for fp in file_paths]\n",
    "    combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # --- Rename columns early so the rest uses the new names ---\n",
    "    rename_map = {\n",
    "        'Feature Encoding': 'Encoding',\n",
    "        'LB odds ratio': 'LB OR',\n",
    "        'UB odds ratio': 'UB OR',\n",
    "    }\n",
    "    combined = combined.rename(columns=rename_map)\n",
    "\n",
    "    # Sort on LB OR descending, then drop all where LB OR <= 1\n",
    "    combined = combined.sort_values(by='LB OR', ascending=False)\n",
    "    combined = combined[combined['LB OR'] > 1]\n",
    "\n",
    "    # Round non-OR float columns to 3 decimals\n",
    "    float_cols = combined.select_dtypes(include=['float64', 'float32']).columns.tolist()\n",
    "    or_cols = [c for c in ['LB OR', 'UB OR', 'odds ratio'] if c in combined.columns]\n",
    "    float_cols_wo_or = [c for c in float_cols if c not in or_cols]\n",
    "    if float_cols_wo_or:\n",
    "        combined[float_cols_wo_or] = combined[float_cols_wo_or].round(3)\n",
    "\n",
    "    # Make OR columns integers (nullable Int64 so it won't crash on NaNs)\n",
    "    for c in or_cols:\n",
    "        combined[c] = pd.to_numeric(combined[c], errors='coerce').round(0).astype('Int64')\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    drop_cols = [c for c in ['Support RHS', 'Filename', 'Runtime (seconds)'] if c in combined.columns]\n",
    "    if drop_cols:\n",
    "        combined = combined.drop(columns=drop_cols)\n",
    "\n",
    "    # Move 'Encoding' to second column\n",
    "    cols = combined.columns.tolist()\n",
    "    if 'Encoding' in cols:\n",
    "        cols.insert(1, cols.pop(cols.index('Encoding')))\n",
    "        combined = combined[cols]\n",
    "\n",
    "    # Move 'UB OR' to fifth column (if present)\n",
    "    cols = combined.columns.tolist()\n",
    "    if 'UB OR' in cols:\n",
    "        cols.insert(4, cols.pop(cols.index('UB OR')))\n",
    "        combined = combined[cols]\n",
    "\n",
    "    # Export to CSV at the top level directory\n",
    "    out_fp_csv = os.path.join(root_dir, 'combined_sorted.csv')\n",
    "    combined.to_csv(out_fp_csv, index=False, sep=',')\n",
    "    print(f\"✅ Saved combined_sorted.csv → {out_fp_csv}\")\n",
    "\n",
    "    # Export to LaTeX at the top level directory\n",
    "    out_fp_tex = os.path.join(root_dir, 'combined_sorted.tex')\n",
    "\n",
    "    def fmt_rule(x):\n",
    "        # wrap in \\detokenize{…} so TeX will not parse special chars\n",
    "        return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "    # drop the columns you don't want (order of the rest is preserved)\n",
    "    cols_to_drop = ['n12', 'n21', 'Fair set count', 'Stratified']\n",
    "    cols_keep = [c for c in combined.columns if c not in cols_to_drop]\n",
    "\n",
    "    combined.to_latex(\n",
    "        out_fp_tex,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        float_format=\"%.2f\",  # applies only to float columns (OR cols are Int64, so no decimals)\n",
    "        columns=cols_keep,\n",
    "        formatters={\n",
    "            \"Rule\": fmt_rule,\n",
    "            \"Encoding\": fmt_rule,  # updated name\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved combined_sorted.tex → {out_fp_tex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e528b3b",
   "metadata": {},
   "source": [
    "### Per log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory one level up (everything under sepsis)\n",
    "root_dir = '5_analysis/random/BPI15A'\n",
    "\n",
    "# Find all combined.csv files (two levels deep; switch to recursive ** if needed)\n",
    "pattern = os.path.join(root_dir, '*', '*', 'combined.csv')\n",
    "file_paths = sorted(glob.glob(pattern))\n",
    "\n",
    "def infer_labeling_from_path(fp: str, base: str) -> str:\n",
    "    \"\"\"\n",
    "    Infer labeling from the *top-level* subfolder under 'sepsis'.\n",
    "    Mapping:\n",
    "      - contains 'mr_tr'   -> 'sequential'\n",
    "      - contains 'decl'    -> 'declare'\n",
    "      - contains 'payload' -> 'payload'\n",
    "    \"\"\"\n",
    "    rel = os.path.relpath(fp, base)\n",
    "    parts = rel.split(os.sep)\n",
    "    top = parts[0].lower() if parts else \"\"\n",
    "    if 'mr_tr' in top:\n",
    "        return 'sequential'\n",
    "    if 'decl' in top:\n",
    "        return 'declare'\n",
    "    if 'payload' in top:\n",
    "        return 'payload'\n",
    "    return 'unknown'\n",
    "\n",
    "if not file_paths:\n",
    "    print(f\"🚨 No combined.csv files found under {root_dir} (looked for {pattern})\")\n",
    "else:\n",
    "    # Read & tag each df with 'labeling'\n",
    "    df_list = []\n",
    "    for fp in file_paths:\n",
    "        df = pd.read_csv(fp, sep=',')\n",
    "        labeling = infer_labeling_from_path(fp, root_dir)\n",
    "        df['labeling'] = labeling\n",
    "        df_list.append(df)\n",
    "\n",
    "    combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # --- Rename columns early so the rest uses the new names ---\n",
    "    rename_map = {\n",
    "        'Feature Encoding': 'Encoding',\n",
    "        'LB odds ratio': 'LB OR',\n",
    "        'UB odds ratio': 'UB OR',\n",
    "    }\n",
    "    combined = combined.rename(columns=rename_map)\n",
    "\n",
    "    # Sort on LB OR descending, then drop all where LB OR <= 1\n",
    "    if 'LB OR' in combined.columns:\n",
    "        combined = combined.sort_values(by='LB OR', ascending=False)\n",
    "        combined = combined[combined['LB OR'] > 1]\n",
    "\n",
    "    # Round non-OR float columns to 3 decimals\n",
    "    float_cols = combined.select_dtypes(include=['float64', 'float32']).columns.tolist()\n",
    "    or_cols = [c for c in ['LB OR', 'UB OR', 'odds ratio'] if c in combined.columns]\n",
    "    float_cols_wo_or = [c for c in float_cols if c not in or_cols]\n",
    "    if float_cols_wo_or:\n",
    "        combined[float_cols_wo_or] = combined[float_cols_wo_or].round(3)\n",
    "\n",
    "    # Make OR columns integers (nullable Int64 so it won't crash on NaNs)\n",
    "    for c in or_cols:\n",
    "        combined[c] = pd.to_numeric(combined[c], errors='coerce').round(0).astype('Int64')\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    drop_cols = [c for c in ['Support RHS', 'Filename', 'Runtime (seconds)'] if c in combined.columns]\n",
    "    if drop_cols:\n",
    "        combined = combined.drop(columns=drop_cols)\n",
    "\n",
    "    # Reorder a bit: place 'Encoding' second and keep new 'labeling' near the front\n",
    "    cols = combined.columns.tolist()\n",
    "    # ensure labeling is present and near the front\n",
    "    for desired, idx in [('Encoding', 1), ('labeling', 2)]:\n",
    "        if desired in cols:\n",
    "            cols.insert(idx, cols.pop(cols.index(desired)))\n",
    "    combined = combined[cols]\n",
    "\n",
    "    # Move 'UB OR' to fifth column (if present)\n",
    "    cols = combined.columns.tolist()\n",
    "    if 'UB OR' in cols:\n",
    "        cols.insert(4, cols.pop(cols.index('UB OR')))\n",
    "        combined = combined[cols]\n",
    "\n",
    "    # Export to CSV at the sepsis level\n",
    "    out_fp_csv = os.path.join(root_dir, 'combined_sorted.csv')\n",
    "    combined.to_csv(out_fp_csv, index=False, sep=',')\n",
    "    print(f\"✅ Saved combined_sorted.csv → {out_fp_csv}\")\n",
    "\n",
    "    # Export to LaTeX at the sepsis level\n",
    "    out_fp_tex = os.path.join(root_dir, 'combined_sorted.tex')\n",
    "\n",
    "    def fmt_rule(x):\n",
    "        # wrap in \\detokenize{…} so TeX will not parse special chars\n",
    "        return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "    cols_to_drop = ['n12', 'n21', 'Fair set count', 'Stratified']\n",
    "    cols_keep = [c for c in combined.columns if c not in cols_to_drop]\n",
    "\n",
    "    combined.to_latex(\n",
    "        out_fp_tex,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        float_format=\"%.2f\",\n",
    "        columns=cols_keep,\n",
    "        formatters={\n",
    "            \"Rule\": fmt_rule,\n",
    "            \"Encoding\": fmt_rule,\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved combined_sorted.tex → {out_fp_tex}\")\n",
    "\n",
    "    # Sanity check\n",
    "    print(\"Labelings found:\", sorted(combined['labeling'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a17f4",
   "metadata": {},
   "source": [
    "### For all crm experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '5_analysis/random'\n",
    "pattern = os.path.join(root_dir, '**', 'combined.csv')\n",
    "\n",
    "file_paths = glob.glob(pattern, recursive=True)\n",
    "\n",
    "if not file_paths:\n",
    "    print(f\"🚨 No combined.csv files found under {root_dir}\")\n",
    "else:\n",
    "    df_list = []\n",
    "    for fp in file_paths:\n",
    "        df = pd.read_csv(fp, sep=',')\n",
    "\n",
    "        # sanity check: we now trust 'Feature Encoding' from the file itself\n",
    "        if 'Feature Encoding' not in df.columns:\n",
    "            raise ValueError(f\"'Feature Encoding' column missing in {fp}\")\n",
    "\n",
    "        # derive Dataset and Labeling from path relative to root_dir\n",
    "        rel = Path(fp).relative_to(root_dir)\n",
    "        # expect: <dataset>/<labeling>_features/<...>/combined.csv\n",
    "        dataset  = rel.parts[0] if len(rel.parts) >= 1 else 'UNKNOWN'\n",
    "        labeling = rel.parts[1] if len(rel.parts) >= 2 else 'UNKNOWN'\n",
    "        labeling = labeling.replace('_features', '')\n",
    "\n",
    "        # add columns (do NOT overwrite 'Feature Encoding')\n",
    "        df.insert(0, 'Dataset', dataset)\n",
    "        df.insert(1, 'Labeling', labeling)\n",
    "\n",
    "        df_list.append(df)\n",
    "\n",
    "    combined_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # sort and filter as before\n",
    "    combined_all = combined_all.sort_values(by='LB odds ratio', ascending=False)\n",
    "    combined_all = combined_all[combined_all['LB odds ratio'] > 1]\n",
    "\n",
    "    # round only float columns\n",
    "    float_cols = combined_all.select_dtypes(include=[np.floating]).columns\n",
    "    combined_all[float_cols] = combined_all[float_cols].round(3)\n",
    "\n",
    "    # drop unwanted columns if present\n",
    "    drop_cols = [c for c in ['Support RHS', 'Filename', 'Runtime (seconds)'] if c in combined_all.columns]\n",
    "    if drop_cols:\n",
    "        combined_all = combined_all.drop(columns=drop_cols)\n",
    "\n",
    "    # ensure first three columns are Dataset, Labeling, Feature Encoding (in that order),\n",
    "    # then keep the rest in their existing order\n",
    "    cols = list(combined_all.columns)\n",
    "    for must in ['Dataset', 'Labeling', 'Feature Encoding']:\n",
    "        if must not in cols:\n",
    "            raise ValueError(f\"Required column '{must}' missing after assembly.\")\n",
    "\n",
    "    rest = [c for c in cols if c not in ['Dataset', 'Labeling', 'Feature Encoding']]\n",
    "    ordered_cols = ['Dataset', 'Labeling', 'Feature Encoding'] + rest\n",
    "    combined_all = combined_all[ordered_cols]\n",
    "\n",
    "    # sort by Dataset, Labeling, Feature Encoding, then LB odds ratio\n",
    "    combined_all = combined_all.sort_values(\n",
    "    by=['Dataset', 'Labeling', 'Feature Encoding', 'LB odds ratio'],\n",
    "    ascending=[True, True, True, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # save CSV\n",
    "    out_fp_csv = os.path.join(root_dir, 'combined_sorted_all.csv')\n",
    "    combined_all.to_csv(out_fp_csv, index=False)\n",
    "    print(f\"✅ Saved combined_sorted_all.csv → {out_fp_csv}\")\n",
    "\n",
    "    # save LaTeX\n",
    "    out_fp_tex = os.path.join(root_dir, 'combined_sorted_all.tex')\n",
    "\n",
    "    def fmt_rule(x):\n",
    "        return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "    combined_all.to_latex(\n",
    "        out_fp_tex,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        float_format=\"%.2f\",\n",
    "        formatters={\n",
    "            \"Rule\": fmt_rule,\n",
    "            \"Feature Encoding\": fmt_rule\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved combined_sorted_all.tex → {out_fp_tex}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84694b79",
   "metadata": {},
   "source": [
    "### Latex export for IMPresseD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Latex export for IMPresseD results\n",
    "#     # save LaTeX\n",
    "# # 1) Keep only the requested columns (in this order)\n",
    "# cols = [\"Dataset\", \"Labeling\", \"Rule\", \"LB odds ratio\"]\n",
    "# missing = [c for c in cols if c not in df.columns]\n",
    "# if missing:\n",
    "#     raise KeyError(f\"Missing expected column(s): {missing}\")\n",
    "# df_latex = combined_all[cols].copy()\n",
    "\n",
    "# # 2) Clean 'Labeling' values (case-insensitive):\n",
    "# #    any value containing 'decl' -> 'declare'\n",
    "# #    any value containing 'mr_tr' -> 'sequential'\n",
    "# #    any value containing 'payload' -> 'payload'\n",
    "# lab_lower = df_latex[\"Labeling\"].astype(str).str.lower()\n",
    "# conds = [\n",
    "#     lab_lower.str.contains(r\"decl\", na=False),\n",
    "#     lab_lower.str.contains(r\"mr_tr\", na=False),\n",
    "#     lab_lower.str.contains(r\"payload\", na=False),\n",
    "# ]\n",
    "# choices = [\"declare\", \"sequential\", \"payload\"]\n",
    "# df_latex[\"Labeling\"] = np.select(conds, choices, default=df_latex[\"Labeling\"])\n",
    "\n",
    "# # Ensure numeric for formatting step\n",
    "# df_latex[\"LB odds ratio\"] = pd.to_numeric(df_latex[\"LB odds ratio\"], errors=\"coerce\")\n",
    "\n",
    "# def fmt_rule(x):\n",
    "#     # Keep rules LaTeX-safe\n",
    "#     return r\"\\detokenize{\" + str(x) + \"}\"\n",
    "\n",
    "# def fmt_two_decimals(x):\n",
    "#     # 3) Format LB odds ratio to max 2 decimals\n",
    "#     return \"\" if pd.isna(x) else f\"{x:.2f}\"\n",
    "\n",
    "# # Export to LaTeX\n",
    "# out_fp_tex = os.path.join(root_dir, \"combined_sorted_all.tex\")\n",
    "# df_latex.to_latex(\n",
    "#     out_fp_tex,\n",
    "#     index=False,\n",
    "#     escape=False,\n",
    "#     longtable=True,\n",
    "#     float_format=None,               # don't apply a global float formatter\n",
    "#     formatters={\n",
    "#         \"Rule\": fmt_rule,\n",
    "#         \"LB odds ratio\": fmt_two_decimals,\n",
    "#     },\n",
    "# )\n",
    "# print(f\"✅ Saved {os.path.basename(out_fp_tex)} → {out_fp_tex}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4188406",
   "metadata": {},
   "source": [
    "### Load a specific csv (inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4802ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join('5_analysis', 'DHL', 'combined_sorted_all.csv')\n",
    "# df = pd.read_csv(path, sep=',')\n",
    "# df.sort_values(\n",
    "#     by=\"LB odds ratio\",\n",
    "#     ascending=False\n",
    "# ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #filter on payload feature encodings\n",
    "# path = os.path.join('5_analysis', 'random', 'traffic', 'traffic_decl3_features', 'combined_sorted.csv')\n",
    "# df = pd.read_csv(path, sep=',')\n",
    "# df = df[df['LB odds ratio'] <= 1]\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27740447",
   "metadata": {},
   "source": [
    "## 4. Collect results for dt and RipperK experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da64dd8",
   "metadata": {},
   "source": [
    "### Collect aggregated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"4_output\")\n",
    "metrics = (\"precision\", \"recall\", \"f1\", \"roc_auc\")\n",
    "# Drop rows where Feature Encoding is 'mr', 'mra', 'tr', or 'tra'\n",
    "exclude_encodings = [\"mr\", \"mra\", \"tr\", \"tra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13149efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_records = []\n",
    "ripperk_records = []\n",
    "\n",
    "for cls_dir in base_dir.iterdir():\n",
    "    if not cls_dir.is_dir():\n",
    "        continue\n",
    "    classifier = cls_dir.name\n",
    "\n",
    "    if classifier == \"dt\":\n",
    "        target_list = dt_records\n",
    "    elif classifier == \"ripperk\":\n",
    "        target_list = ripperk_records\n",
    "    else:\n",
    "        continue  # skip any other classifiers\n",
    "\n",
    "    for ds_dir in cls_dir.iterdir():\n",
    "        if not ds_dir.is_dir():\n",
    "            continue\n",
    "        dataset = ds_dir.name\n",
    "\n",
    "        for lab_dir in ds_dir.iterdir():\n",
    "            if not lab_dir.is_dir():\n",
    "                continue\n",
    "            labeling_raw = lab_dir.name\n",
    "\n",
    "            # Extract only the middle part (between first and last \"_\")\n",
    "            parts = labeling_raw.split(\"_\")\n",
    "            labeling = parts[1] if len(parts) > 2 else labeling_raw\n",
    "\n",
    "            for enc_dir in lab_dir.iterdir():\n",
    "                if not enc_dir.is_dir():\n",
    "                    continue\n",
    "                encoding = enc_dir.name\n",
    "\n",
    "                csv_files = sorted(enc_dir.glob(\"*.csv\"))\n",
    "                if not csv_files:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_files[0])\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "                # Read runtime from .txt file (if available)\n",
    "                runtime_file = next(enc_dir.glob(\"*.txt\"), None)\n",
    "                runtime_seconds = pd.NA\n",
    "                if runtime_file and runtime_file.is_file():\n",
    "                    try:\n",
    "                        with open(runtime_file, \"r\") as f:\n",
    "                            val = f.read().strip()\n",
    "                            runtime_seconds = round(float(val), 2)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                # Build record\n",
    "                row = {\n",
    "                    \"Dataset\": dataset,\n",
    "                    \"Labeling\": labeling,\n",
    "                    \"Feature Encoding\": encoding\n",
    "                }\n",
    "\n",
    "                if df.empty:\n",
    "                    for m in metrics:\n",
    "                        row[m] = pd.NA\n",
    "                else:\n",
    "                    for m in metrics:\n",
    "                        row[m] = round(df[m].iloc[0], 4) if m in df.columns else pd.NA\n",
    "\n",
    "                # Add runtime as last column\n",
    "                row[\"Runtime (Seconds)\"] = runtime_seconds\n",
    "\n",
    "                target_list.append(row)\n",
    "\n",
    "# Create and sort dataframes\n",
    "dt_df = pd.DataFrame.from_records(dt_records).sort_values(\n",
    "    by=[\"Dataset\", \"Labeling\", \"Feature Encoding\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "ripperk_df = pd.DataFrame.from_records(ripperk_records).sort_values(\n",
    "    by=[\"Dataset\", \"Labeling\", \"Feature Encoding\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Drop rows where Feature Encoding is 'mr', 'mra', 'tr', or 'tra'\n",
    "dt_df = dt_df[~dt_df[\"Feature Encoding\"].isin(exclude_encodings)].reset_index(drop=True)\n",
    "ripperk_df = ripperk_df[~ripperk_df[\"Feature Encoding\"].isin(exclude_encodings)].reset_index(drop=True)\n",
    "\n",
    "# --- Normalize Labeling values (substring-based) ---\n",
    "for _df in (dt_df, ripperk_df):\n",
    "    if \"Labeling\" in _df.columns:\n",
    "        low = _df[\"Labeling\"].astype(str).str.lower()\n",
    "        _df.loc[low.str.contains(\"decl\", na=False), \"Labeling\"] = \"declare\"\n",
    "        _df.loc[low.str.contains(\"payload\", na=False), \"Labeling\"] = \"payload\"\n",
    "        _df.loc[low.str.contains(\"mr\", na=False), \"Labeling\"] = \"sequential\"\n",
    "\n",
    "dt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f764b",
   "metadata": {},
   "source": [
    "### Collect aggregated metrics averaged over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b34130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_over_datasets(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    tmp = df.copy()\n",
    "\n",
    "    # 1) Harmonize labeling names\n",
    "    labs = tmp[\"Labeling\"].astype(str)\n",
    "    labs_clean = labs.str.lower().str.replace(r\"\\s+\", \"\", regex=True) \n",
    "    tmp.loc[labs_clean.isin({\"decl\", \"decl2\", \"decl3\"}), \"Labeling\"] = \"decl\"\n",
    "    tmp.loc[labs_clean.isin({\"payload\", \"payload2\"}), \"Labeling\"] = \"payload\"\n",
    "\n",
    "    # 2) Ensure numeric\n",
    "    numeric_cols = [c for c in [\"precision\", \"recall\", \"f1\", \"roc_auc\", \"Runtime (Seconds)\"] if c in tmp.columns]\n",
    "    for c in numeric_cols:\n",
    "        tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "\n",
    "    # 3) Group and average (NaNs ignored), count contributing datasets\n",
    "    grouped = (\n",
    "        tmp.groupby([\"Labeling\", \"Feature Encoding\"], as_index=False)\n",
    "           .agg({**{c: \"mean\" for c in numeric_cols}, \"Dataset\": \"nunique\"})\n",
    "           .rename(columns={\"Dataset\": \"#Datasets\"})\n",
    "           .sort_values([\"Labeling\", \"Feature Encoding\"])\n",
    "           .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # 4) Round\n",
    "    for c in [\"precision\", \"recall\", \"f1\", \"roc_auc\"]:\n",
    "        if c in grouped.columns:\n",
    "            grouped[c] = grouped[c].round(4)\n",
    "    if \"Runtime (Seconds)\" in grouped.columns:\n",
    "        grouped[\"Runtime (Seconds)\"] = grouped[\"Runtime (Seconds)\"].round(2)\n",
    "\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce69a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_avg = average_over_datasets(dt_df)\n",
    "ripperk_avg = average_over_datasets(ripperk_df)\n",
    "\n",
    "dt_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_rule(x):\n",
    "    # Wrap in \\detokenize{…} so TeX won't parse special chars\n",
    "    return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "def save_raw(df, out_dir, stem):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    csv_path = os.path.join(out_dir, f'{stem}.csv')\n",
    "    tex_path = os.path.join(out_dir, f'{stem}.tex')\n",
    "\n",
    "    df.to_csv(csv_path, index=False, sep=',')\n",
    "    df.to_latex(\n",
    "        tex_path,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        float_format=\"%.2f\",\n",
    "        formatters={\"Feature Encoding\": fmt_rule}\n",
    "    )\n",
    "    print(f\"✅ Saved {stem}.csv → {csv_path}\")\n",
    "    print(f\"✅ Saved {stem}.tex  → {tex_path}\")\n",
    "\n",
    "def save_avg(df_avg, out_dir, stem):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    csv_path = os.path.join(out_dir, f'{stem}.csv')\n",
    "    tex_path = os.path.join(out_dir, f'{stem}.tex')\n",
    "\n",
    "    df_avg.to_csv(csv_path, index=False, sep=',')\n",
    "    fmt4 = (lambda x: f\"{x:.4f}\" if pd.notna(x) else \"\")\n",
    "    fmt2 = (lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\")\n",
    "\n",
    "    df_avg.to_latex(\n",
    "        tex_path,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        formatters={\n",
    "            \"Feature Encoding\": fmt_rule,\n",
    "            \"precision\": fmt4, \"recall\": fmt4, \"f1\": fmt4, \"roc_auc\": fmt4,\n",
    "            \"Runtime (Seconds)\": fmt2\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved {stem}.csv → {csv_path}\")\n",
    "    print(f\"✅ Saved {stem}.tex  → {tex_path}\")\n",
    "\n",
    "# Run for both classifiers\n",
    "for name, df_raw, df_avg in [\n",
    "    (\"dt\", dt_df, dt_avg),\n",
    "    (\"ripperk\", ripperk_df, ripperk_avg),\n",
    "]:\n",
    "    out_dir = os.path.join('5_analysis', name)\n",
    "    save_raw(df_raw, out_dir, f'aggregated_sorted_{name}')\n",
    "    save_avg(df_avg, out_dir, f'aggregated_averaged_{name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9eb83e",
   "metadata": {},
   "source": [
    "### Collect aggregated rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac136f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"4_output\")\n",
    "\n",
    "dt_rule_records = []\n",
    "ripperk_rule_records = []\n",
    "\n",
    "for cls_dir in base_dir.iterdir():\n",
    "    if not cls_dir.is_dir():\n",
    "        continue\n",
    "    classifier = cls_dir.name\n",
    "\n",
    "    # Select which list to append to\n",
    "    if classifier == \"dt\":\n",
    "        target_list = dt_rule_records\n",
    "    elif classifier == \"ripperk\":\n",
    "        target_list = ripperk_rule_records\n",
    "    else:\n",
    "        continue  # skip any other classifiers\n",
    "\n",
    "    # Datasets\n",
    "    for ds_dir in cls_dir.iterdir():\n",
    "        if not ds_dir.is_dir():\n",
    "            continue\n",
    "        dataset = ds_dir.name\n",
    "\n",
    "        # Labelings\n",
    "        for lab_dir in ds_dir.iterdir():\n",
    "            if not lab_dir.is_dir():\n",
    "                continue\n",
    "            labeling_raw = lab_dir.name\n",
    "            parts = labeling_raw.split(\"_\")\n",
    "            labeling = parts[1] if len(parts) > 2 else labeling_raw  # keep middle part\n",
    "\n",
    "            # Encodings\n",
    "            for enc_dir in lab_dir.iterdir():\n",
    "                if not enc_dir.is_dir():\n",
    "                    continue\n",
    "                encoding = enc_dir.name\n",
    "\n",
    "                # Read the first CSV found in the encoding folder\n",
    "                csv_files = sorted(enc_dir.glob(\"*.csv\"))\n",
    "                if not csv_files:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_files[0])\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "                # Be robust to case differences: look for 'rule' case-insensitively\n",
    "                lower_map = {c.lower(): c for c in df.columns}\n",
    "                if \"rule\" not in lower_map:\n",
    "                    continue  # no rules in this CSV\n",
    "\n",
    "                rule_col = lower_map[\"rule\"]\n",
    "                rules_series = (\n",
    "                    df[rule_col]\n",
    "                    .dropna()\n",
    "                    .astype(str)\n",
    "                    .str.strip()\n",
    "                )\n",
    "\n",
    "                # Skip empties\n",
    "                rules_series = rules_series[rules_series != \"\"]\n",
    "\n",
    "                for rule in rules_series:\n",
    "                    target_list.append({\n",
    "                        \"Dataset\": dataset,\n",
    "                        \"Labeling\": labeling,\n",
    "                        \"Feature Encoding\": encoding,\n",
    "                        \"Rule\": rule\n",
    "                    })\n",
    "\n",
    "# Build dataframes (no classifier col), drop duplicates, sort\n",
    "dt_rules_df = (\n",
    "    pd.DataFrame.from_records(dt_rule_records)\n",
    "      .drop_duplicates()\n",
    "      .sort_values(by=[\"Dataset\", \"Labeling\", \"Feature Encoding\", \"Rule\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "ripperk_rules_df = (\n",
    "    pd.DataFrame.from_records(ripperk_rule_records)\n",
    "      .drop_duplicates()\n",
    "      .sort_values(by=[\"Dataset\", \"Labeling\", \"Feature Encoding\", \"Rule\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Drop rows where Feature Encoding is 'mr', 'mra', 'tr', or 'tra'\n",
    "dt_rules_df = dt_rules_df[~dt_rules_df[\"Feature Encoding\"].isin(exclude_encodings)].reset_index(drop=True)\n",
    "ripperk_rules_df = ripperk_rules_df[~ripperk_rules_df[\"Feature Encoding\"].isin(exclude_encodings)].reset_index(drop=True)\n",
    "\n",
    "# --- Normalize Labeling values (substring-based) ---\n",
    "for _df in (dt_rules_df, ripperk_rules_df):\n",
    "    if \"Labeling\" in _df.columns:\n",
    "        low = _df[\"Labeling\"].astype(str).str.lower()\n",
    "        _df.loc[low.str.contains(\"decl\", na=False), \"Labeling\"] = \"declare\"\n",
    "        _df.loc[low.str.contains(\"payload\", na=False), \"Labeling\"] = \"payload\"\n",
    "        _df.loc[low.str.contains(\"mr\", na=False), \"Labeling\"] = \"sequential\"\n",
    "\n",
    "dt_rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_detok(x):\n",
    "    # Prevent TeX from parsing special chars\n",
    "    return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "def save_rules(df, classifier):\n",
    "    out_dir = os.path.join('5_analysis', classifier)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    stem = f'rules_{classifier}'\n",
    "    csv_path = os.path.join(out_dir, f'{stem}.csv')\n",
    "    tex_path = os.path.join(out_dir, f'{stem}.tex')\n",
    "\n",
    "    # CSV\n",
    "    df.to_csv(csv_path, index=False, sep=',')\n",
    "    # LaTeX\n",
    "    df.to_latex(\n",
    "        tex_path,\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        longtable=True,\n",
    "        formatters={\n",
    "            \"Feature Encoding\": fmt_detok,\n",
    "            \"Rule\": fmt_detok\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved {stem}.csv → {csv_path}\")\n",
    "    print(f\"✅ Saved {stem}.tex  → {tex_path}\")\n",
    "\n",
    "# Run for both classifiers\n",
    "for name, df in [\n",
    "    (\"dt\", dt_rules_df),\n",
    "    (\"ripperk\", ripperk_rules_df),\n",
    "]:\n",
    "    save_rules(df, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6695d76",
   "metadata": {},
   "source": [
    "## 5. Comparison of Baseline with CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_rules_crm_path = os.path.join('5_analysis', 'random', 'combined_sorted_all.csv')\n",
    "# all_rules_crm = pd.read_csv(all_rules_crm_path, sep=',')\n",
    "\n",
    "all_rules_crm_path = os.path.join('5_analysis', 'DHL', 'combined_sorted_all.csv')\n",
    "all_rules_crm = pd.read_csv(all_rules_crm_path, sep=',')\n",
    "\n",
    "all_rules_dt_path = os.path.join('5_analysis', 'dt', 'rules_dt.csv')\n",
    "all_rules_dt = pd.read_csv(all_rules_dt_path, sep=',')\n",
    "\n",
    "all_metrics_dt_path = os.path.join('5_analysis', 'dt', 'aggregated_sorted_dt.csv')\n",
    "all_metrics_dt = pd.read_csv(all_metrics_dt_path, sep=',')\n",
    "\n",
    "all_rules_ripperk_path = os.path.join('5_analysis', 'ripperk', 'rules_ripperk.csv')\n",
    "all_rules_ripperk = pd.read_csv(all_rules_ripperk_path, sep=',')\n",
    "\n",
    "all_metrics_ripperk_path = os.path.join('5_analysis', 'ripperk', 'aggregated_sorted_ripperk.csv')\n",
    "all_metrics_ripperk = pd.read_csv(all_metrics_ripperk_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) Helpers --------------------------------------------------------------\n",
    "\n",
    "def _harmonize_and_filter(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Normalize encoding column name and drop excluded encodings\n",
    "    out = df.rename(columns={\n",
    "        'Feature Encoding': 'Encoding',\n",
    "        'Feature encoding': 'Encoding'\n",
    "    }).copy()\n",
    "    if 'Encoding' in out.columns:\n",
    "        enc_norm = out['Encoding'].astype(str).str.strip().str.lower()\n",
    "        out = out[~enc_norm.isin(exclude_encodings)].copy()\n",
    "    return out\n",
    "\n",
    "def _rule_counts(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    # Count rules per (Dataset, Labeling, Encoding)\n",
    "    return (\n",
    "        df.groupby(['Dataset', 'Labeling', 'Encoding'], as_index=False)\n",
    "          .agg(**{f'{name}_rule_count': ('Rule', 'count')})\n",
    "    )\n",
    "\n",
    "def _merge_with_crm(left_counts: pd.DataFrame, crm_counts: pd.DataFrame) -> pd.DataFrame:\n",
    "    # left_counts: dt or ripperk counts; merge with CRM counts\n",
    "    left_col = next(c for c in left_counts.columns if c.endswith('_rule_count') and c != 'crm_rule_count')\n",
    "    merged = (\n",
    "        pd.merge(left_counts, crm_counts, on=['Dataset', 'Labeling', 'Encoding'], how='outer')\n",
    "          .fillna({left_col: 0, 'crm_rule_count': 0})\n",
    "          .astype({left_col: int, 'crm_rule_count': int})\n",
    "          .sort_values(by=['Dataset', 'Labeling', 'Encoding'])\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "# --- 1) Harmonize + filter inputs -------------------------------------------\n",
    "\n",
    "rules_crm_f      = _harmonize_and_filter(all_rules_crm)\n",
    "rules_dt_f       = _harmonize_and_filter(all_rules_dt)\n",
    "rules_ripperk_f  = _harmonize_and_filter(all_rules_ripperk)\n",
    "\n",
    "# --- 2) Counts and initial comparisons --------------------------------------\n",
    "\n",
    "crm_counts      = _rule_counts(rules_crm_f,     'crm')\n",
    "dt_counts       = _rule_counts(rules_dt_f,      'dt')\n",
    "ripperk_counts  = _rule_counts(rules_ripperk_f, 'ripperk')\n",
    "\n",
    "dt_comparison       = _merge_with_crm(dt_counts, crm_counts)\n",
    "ripperk_comparison  = _merge_with_crm(ripperk_counts, crm_counts)\n",
    "\n",
    "# Optional: consistent column order\n",
    "_dt_cols = ['Dataset', 'Labeling', 'Encoding', 'dt_rule_count', 'crm_rule_count']\n",
    "_rk_cols = ['Dataset', 'Labeling', 'Encoding', 'ripperk_rule_count', 'crm_rule_count']\n",
    "dt_comparison = dt_comparison.reindex(columns=[c for c in _dt_cols if c in dt_comparison.columns])\n",
    "ripperk_comparison = ripperk_comparison.reindex(columns=[c for c in _rk_cols if c in ripperk_comparison.columns])\n",
    "\n",
    "# --- 3) CRM summary stats (LB odds ratio > 1) and merge into both -----------\n",
    "\n",
    "# Ensure numeric types for needed CRM metrics\n",
    "crm_stats_df = rules_crm_f.copy()\n",
    "for col in ['LB odds ratio', 'Confidence', 'Support LHS']:\n",
    "    crm_stats_df[col] = pd.to_numeric(crm_stats_df[col], errors='coerce')\n",
    "\n",
    "# Filter to \"interesting\" CRM rules, then aggregate\n",
    "crm_filtered = crm_stats_df[crm_stats_df['LB odds ratio'] > 1].copy()\n",
    "\n",
    "crm_all_agg = (\n",
    "    crm_filtered\n",
    "    .groupby(['Dataset', 'Labeling', 'Encoding'], as_index=False)\n",
    "    .agg(\n",
    "        crm_conf_median=('Confidence', 'median'),\n",
    "        crm_conf_max=('Confidence', 'max'),\n",
    "        crm_support_lhs_median=('Support LHS', 'median'),\n",
    "        crm_support_lhs_max=('Support LHS', 'max')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Merge aggregated CRM metrics into both comparisons\n",
    "dt_comparison = dt_comparison.merge(\n",
    "    crm_all_agg, on=['Dataset', 'Labeling', 'Encoding'], how='left'\n",
    ")\n",
    "ripperk_comparison = ripperk_comparison.merge(\n",
    "    crm_all_agg, on=['Dataset', 'Labeling', 'Encoding'], how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814eeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Robustly attach precision/recall, then rename/reorder/round for DT & RIPPERk ---\n",
    "\n",
    "# 0) Prep: harmonize 'Encoding' for both metrics tables\n",
    "dt_metrics = all_metrics_dt.copy()\n",
    "if 'Encoding' not in dt_metrics.columns and 'Feature Encoding' in dt_metrics.columns:\n",
    "    dt_metrics = dt_metrics.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "\n",
    "rk_metrics = all_metrics_ripperk.copy()\n",
    "if 'Encoding' not in rk_metrics.columns and 'Feature Encoding' in rk_metrics.columns:\n",
    "    rk_metrics = rk_metrics.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "\n",
    "# Build a set of known dataset-prefix tokens to strip from Labeling (case-insensitive)\n",
    "def _collect_prefixes(*dfs) -> set:\n",
    "    prefixes = set()\n",
    "    for df in dfs:\n",
    "        if df is None or not isinstance(df, pd.DataFrame):\n",
    "            continue\n",
    "        if 'Dataset' in df.columns:\n",
    "            s = pd.Series(df['Dataset']).astype(str).str.strip().str.lower()\n",
    "            prefixes.update(s.str.replace(r'\\s+', '', regex=True).unique().tolist())\n",
    "    # Add common aliases you might encounter\n",
    "    prefixes |= {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "    return {p for p in prefixes if p and p != 'nan'}\n",
    "\n",
    "KNOWN_PREFIXES = _collect_prefixes(dt_comparison, ripperk_comparison, dt_metrics, rk_metrics)\n",
    "\n",
    "def _normalize_side(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # Harmonize column names and coerce to clean strings\n",
    "    out = out.rename(columns={'Feature encoding': 'Encoding', 'Feature Encoding': 'Encoding'})\n",
    "    for c in ['Dataset', 'Labeling', 'Encoding']:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].astype(str).str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "    def norm_dataset(s: str) -> str:\n",
    "        return str(s).strip().lower()\n",
    "\n",
    "    def norm_encoding(s: str) -> str:\n",
    "        return str(s).strip().lower()\n",
    "\n",
    "    def norm_labeling(lbl: str) -> str:\n",
    "        s = str(lbl).strip().lower()\n",
    "\n",
    "        # Drop suffixes like \"_feature\" / \"_features\"\n",
    "        s = re.sub(r'(_features?)$', '', s)\n",
    "\n",
    "        # Normalize whitespace/underscores\n",
    "        s = s.replace(' ', '_')\n",
    "\n",
    "        # Repeatedly strip known dataset prefixes (you already have KNOWN_PREFIXES)\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "                if s.startswith(p + '_'):\n",
    "                    s = s[len(p) + 1:]\n",
    "                    changed = True\n",
    "\n",
    "        # --- Canonicalize labeling families so merge keys match across tables ---\n",
    "        # payload, payload2, payload_*, etc. -> \"payload\"\n",
    "        if re.search(r'\\bpayload\\b|\\bpayload\\d+\\b', s):\n",
    "            return 'payload'\n",
    "\n",
    "        # decl, decl2, decl3, declare, declare2, etc. -> \"declare\"\n",
    "        if re.fullmatch(r'(decl(are)?\\d*)', s):\n",
    "            return 'declare'\n",
    "\n",
    "        # anything containing token \"mr\" (e.g., mr, mr_tr, mr-anything) -> \"sequential\"\n",
    "        # use token-ish boundaries to avoid accidental matches inside other words\n",
    "        if re.search(r'(^|[^a-z])mr([^a-z]|$)', s):\n",
    "            return 'sequential'\n",
    "\n",
    "        # If none matched, return cleaned label\n",
    "        return s\n",
    "\n",
    "    out['Dataset_norm']  = out['Dataset'].apply(norm_dataset)   if 'Dataset' in out.columns else ''\n",
    "    out['Encoding_norm'] = out['Encoding'].apply(norm_encoding) if 'Encoding' in out.columns else ''\n",
    "    out['Labeling_norm'] = out['Labeling'].apply(norm_labeling) if 'Labeling' in out.columns else ''\n",
    "    out['__merge_key__'] = (out['Dataset_norm'].astype(str) + '|' +\n",
    "                            out['Labeling_norm'].astype(str) + '|' +\n",
    "                            out['Encoding_norm'].astype(str))\n",
    "    return out\n",
    "\n",
    "def _find_col(df: pd.DataFrame, candidates):\n",
    "    cand_norm = [c.casefold() for c in candidates]\n",
    "    for col in df.columns:\n",
    "        if col.casefold() in cand_norm:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def _attach_metrics(comp_df: pd.DataFrame, metrics_df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    # Normalize both sides\n",
    "    comp_n = _normalize_side(comp_df)\n",
    "    metr_n = _normalize_side(metrics_df)\n",
    "\n",
    "    # Locate metric columns (case-insensitive)\n",
    "    prec_col = _find_col(metr_n, ['precision', 'prec'])\n",
    "    rec_col  = _find_col(metr_n, ['recall', 'rec'])\n",
    "    if prec_col is None or rec_col is None:\n",
    "        raise ValueError(\n",
    "            f\"Could not locate precision/recall in metrics for {prefix}. \"\n",
    "            f\"Columns present: {list(metrics_df.columns)}\"\n",
    "        )\n",
    "\n",
    "    # Keep only key + metrics, rename to prefixed names, and make numeric\n",
    "    subset = (\n",
    "        metr_n[['__merge_key__', prec_col, rec_col]]\n",
    "        .rename(columns={prec_col: f'{prefix}_precision', rec_col: f'{prefix}_recall'})\n",
    "    )\n",
    "    subset[f'{prefix}_precision'] = pd.to_numeric(subset[f'{prefix}_precision'], errors='coerce')\n",
    "    subset[f'{prefix}_recall']    = pd.to_numeric(subset[f'{prefix}_recall'],    errors='coerce')\n",
    "\n",
    "    # Aggregate (mean) by merge key in case of duplicates\n",
    "    subset = (\n",
    "        subset.groupby('__merge_key__', as_index=False)\n",
    "              .agg({f'{prefix}_precision': 'mean', f'{prefix}_recall': 'mean'})\n",
    "    )\n",
    "\n",
    "    # Merge back onto the comparison df (keeping original row order/cols)\n",
    "    merged = comp_n[['__merge_key__']].merge(subset, on='__merge_key__', how='left')\n",
    "    out = comp_df.copy()\n",
    "    out[f'{prefix}_precision'] = pd.to_numeric(merged[f'{prefix}_precision'], errors='coerce').round(3)\n",
    "    out[f'{prefix}_recall']    = pd.to_numeric(merged[f'{prefix}_recall'],    errors='coerce').round(3)\n",
    "    return out\n",
    "\n",
    "# 1) Attach metrics to both comparisons\n",
    "dt_comparison       = _attach_metrics(dt_comparison, dt_metrics, prefix='dt')\n",
    "ripperk_comparison  = _attach_metrics(ripperk_comparison, rk_metrics, prefix='ripperk')\n",
    "\n",
    "# 2) Rename, reorder, round (column-wise to avoid shape mismatch)\n",
    "def _rename_reorder_round(df: pd.DataFrame, rename_map: dict, final_order: list) -> pd.DataFrame:\n",
    "    out = df.rename(columns=rename_map).copy()\n",
    "\n",
    "    # Reorder columns (keep any others at the end)\n",
    "    ordered = [c for c in final_order if c in out.columns]\n",
    "    tail    = [c for c in out.columns if c not in ordered]\n",
    "    out = out[ordered + tail]\n",
    "\n",
    "    # Identify count columns (by name suffix \" Rules\" after renaming)\n",
    "    count_cols = [c for c in out.columns if c.endswith(' Rules')]\n",
    "\n",
    "    # Ensure counts are Int64 and *not* rounded\n",
    "    for c in count_cols:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Round all other numeric columns to 3 d.p., one-by-one to avoid assignment shape issues\n",
    "    for c in out.columns:\n",
    "        if c in count_cols:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(out[c]):\n",
    "            out[c] = pd.to_numeric(out[c], errors='coerce').round(3)\n",
    "\n",
    "    return out\n",
    "\n",
    "# DT rename/reorder\n",
    "dt_rename_map = {\n",
    "    'dt_rule_count': 'DT Rules',\n",
    "    'crm_rule_count': 'CRM Rules',\n",
    "    'crm_conf_median': 'CRM Confidence Median',\n",
    "    'crm_conf_max': 'CRM Confidence Max',\n",
    "    'dt_precision': 'DT Precision',\n",
    "    'dt_recall': 'DT Recall',\n",
    "    'crm_support_lhs_median': 'CRM LHS Support Median',\n",
    "    'crm_support_lhs_max': 'CRM LHS Support Max'\n",
    "}\n",
    "dt_final_order = [\n",
    "    'Dataset', 'Labeling', 'Encoding',\n",
    "    'DT Rules', 'CRM Rules',\n",
    "    'CRM Confidence Median', 'CRM Confidence Max',\n",
    "    'DT Precision',\n",
    "    'CRM LHS Support Median', 'CRM LHS Support Max',\n",
    "    'DT Recall'\n",
    "]\n",
    "dt_comparison = _rename_reorder_round(dt_comparison, dt_rename_map, dt_final_order)\n",
    "\n",
    "# RIPPERk rename/reorder\n",
    "rk_rename_map = {\n",
    "    'ripperk_rule_count': 'RIPPERk Rules',\n",
    "    'crm_rule_count': 'CRM Rules',\n",
    "    'crm_conf_median': 'CRM Confidence Median',\n",
    "    'crm_conf_max': 'CRM Confidence Max',\n",
    "    'ripperk_precision': 'RIPPERk Precision',\n",
    "    'ripperk_recall': 'RIPPERk Recall',\n",
    "    'crm_support_lhs_median': 'CRM LHS Support Median',\n",
    "    'crm_support_lhs_max': 'CRM LHS Support Max'\n",
    "}\n",
    "rk_final_order = [\n",
    "    'Dataset', 'Labeling', 'Encoding',\n",
    "    'RIPPERk Rules', 'CRM Rules',\n",
    "    'CRM Confidence Median', 'CRM Confidence Max',\n",
    "    'RIPPERk Precision',\n",
    "    'CRM LHS Support Median', 'CRM LHS Support Max',\n",
    "    'RIPPERk Recall'\n",
    "]\n",
    "ripperk_comparison = _rename_reorder_round(ripperk_comparison, rk_rename_map, rk_final_order)\n",
    "\n",
    "# --- Normalize Labeling values (substring-based) ---\n",
    "for _df in (dt_comparison, ripperk_comparison):\n",
    "    if \"Labeling\" in _df.columns:\n",
    "        low = _df[\"Labeling\"].astype(str).str.lower()\n",
    "        _df.loc[low.str.contains(\"decl\", na=False), \"Labeling\"] = \"declare\"\n",
    "        _df.loc[low.str.contains(\"payload\", na=False), \"Labeling\"] = \"payload\"\n",
    "        _df.loc[low.str.contains(\"mr\", na=False), \"Labeling\"] = \"sequential\"\n",
    "\n",
    "\n",
    "# Display\n",
    "dt_comparison\n",
    "# ripperk_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb233001",
   "metadata": {},
   "source": [
    "## 6. Calculating Rule Redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794b212",
   "metadata": {},
   "source": [
    "### 6.1. Subsumption-Based Redundancy (Structural Overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a27cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CRM rules → expand LHS features (excluding MR/MRA/TR/TRA encodings) ----------\n",
    "# Fallback in case it's not defined earlier\n",
    "try:\n",
    "    exclude_encodings\n",
    "except NameError:\n",
    "    exclude_encodings = [\"mr\", \"mra\", \"tr\", \"tra\"]\n",
    "\n",
    "# ---------- 0) Load rules ----------\n",
    "if 'all_rules_crm' in globals() and isinstance(all_rules_crm, pd.DataFrame):\n",
    "    crm_df = all_rules_crm.copy()\n",
    "else:\n",
    "    raise ValueError(\"all_rules_crm is not available as a DataFrame.\")\n",
    "\n",
    "# Harmonize encoding column name\n",
    "if 'Encoding' not in crm_df.columns and 'Feature Encoding' in crm_df.columns:\n",
    "    crm_df = crm_df.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "\n",
    "# Exclude encodings (case/whitespace-insensitive)\n",
    "if 'Encoding' in crm_df.columns:\n",
    "    excl = {e.lower().strip() for e in exclude_encodings}\n",
    "    enc_norm = crm_df['Encoding'].astype(str).str.strip().str.lower()\n",
    "    crm_df = crm_df[~enc_norm.isin(excl)].copy()\n",
    "\n",
    "# Ensure Odds ratio is numeric and filter OR > 1\n",
    "crm_df['Odds ratio'] = pd.to_numeric(crm_df['Odds ratio'], errors='coerce')\n",
    "crm_df = crm_df[crm_df['Odds ratio'] > 1].copy()\n",
    "\n",
    "# ---------- Normalize Labeling (mirror your other DFs; robust to payload_* etc.) ----------\n",
    "if 'Labeling' in crm_df.columns:\n",
    "    # Build KNOWN_PREFIXES once\n",
    "    try:\n",
    "        KNOWN_PREFIXES\n",
    "    except NameError:\n",
    "        KNOWN_PREFIXES = set(\n",
    "            crm_df.get('Dataset', pd.Series([], dtype=str))\n",
    "                  .astype(str).str.strip().str.lower()\n",
    "                  .str.replace(r'\\s+', '', regex=True)\n",
    "                  .unique().tolist()\n",
    "        ) | {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "\n",
    "    def _strip_prefix_suffix(x: str) -> str:\n",
    "        s = str(x)\n",
    "        s = re.sub(r'(_features?)$', '', s, flags=re.I)  # drop trailing \"_features\"\n",
    "        s = s.strip().lower().replace(' ', '_')\n",
    "        # remove known dataset prefixes repeatedly\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "                if s.startswith(p + '_'):\n",
    "                    s = s[len(p) + 1:]\n",
    "                    changed = True\n",
    "        return s\n",
    "\n",
    "    # 1) If a helper exists, use it to get a first pass; else, strip suffixes/prefixes ourselves\n",
    "    base_series = crm_df['Labeling']\n",
    "    if '_normalize_side' in globals() and callable(globals()['_normalize_side']):\n",
    "        try:\n",
    "            tmp = _normalize_side(crm_df)\n",
    "            if isinstance(tmp, pd.DataFrame):\n",
    "                if 'Labeling_norm' in tmp.columns:\n",
    "                    base_series = tmp['Labeling_norm']\n",
    "                elif 'Labeling' in tmp.columns:\n",
    "                    base_series = tmp['Labeling']\n",
    "        except Exception:\n",
    "            pass  # fall back to original base_series\n",
    "\n",
    "    crm_df['Labeling'] = base_series.apply(_strip_prefix_suffix)\n",
    "\n",
    "    # 2) Final override mapping — exactly like your other DataFrames\n",
    "    low = crm_df['Labeling'].astype(str).str.lower()\n",
    "    crm_df.loc[low.str.contains('decl', na=False),    'Labeling'] = 'declare'\n",
    "    crm_df.loc[low.str.contains('payload', na=False), 'Labeling'] = 'payload'      # catches \"payload_pay36\"\n",
    "    crm_df.loc[low.str.contains('mr', na=False),      'Labeling'] = 'sequential'\n",
    "\n",
    "# ---------- 1) Extract exact LHS and RHS ----------\n",
    "def extract_lhs_exact(rule_str: str) -> str:\n",
    "    \"\"\"Everything before the arrow '-->' (preserve quotes/brackets exactly).\"\"\"\n",
    "    m = re.search(r\"^(.*?)(?=\\s*-->)\", str(rule_str))\n",
    "    return m.group(1) if m else str(rule_str)\n",
    "\n",
    "def parse_rhs_label(rule_str: str):\n",
    "    \"\"\"Return 1 for 'Label', 0 for '!Label', or None if not found.\"\"\"\n",
    "    m = re.search(r\"-->\\s*(Label|!Label)\", str(rule_str))\n",
    "    if not m:\n",
    "        return None\n",
    "    return 1 if m.group(1) == \"Label\" else 0\n",
    "\n",
    "crm_df['LHS_features'] = crm_df['Rule'].apply(extract_lhs_exact)\n",
    "crm_df['RHS_label']    = crm_df['Rule'].apply(parse_rhs_label)\n",
    "\n",
    "# ---------- 2) Split LHS into up to 3 features ----------\n",
    "def _find_outer_brackets_span(text: str):\n",
    "    \"\"\"Return (start_idx, end_idx) of the outermost [...] in `text`.\"\"\"\n",
    "    s = str(text)\n",
    "    start = s.find('[')\n",
    "    if start < 0:\n",
    "        return None, None\n",
    "\n",
    "    depth = 0\n",
    "    in_s = in_d = esc = False\n",
    "    end = None\n",
    "    for i, ch in enumerate(s[start:], start):\n",
    "        if esc:\n",
    "            esc = False\n",
    "            continue\n",
    "        if ch == '\\\\':\n",
    "            esc = True\n",
    "            continue\n",
    "\n",
    "        if in_s:\n",
    "            if ch == \"'\":\n",
    "                in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            if ch == '\"':\n",
    "                in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\":\n",
    "            in_s = True\n",
    "            continue\n",
    "        if ch == '\"':\n",
    "            in_d = True\n",
    "            continue\n",
    "\n",
    "        if ch == '[':\n",
    "            depth += 1\n",
    "            continue\n",
    "        if ch == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                end = i\n",
    "                break\n",
    "    return (start, end)\n",
    "\n",
    "def _split_top_level_commas(content: str):\n",
    "    \"\"\"Split `content` on commas that are outside quotes.\"\"\"\n",
    "    parts, curr = [], \"\"\n",
    "    in_s = in_d = esc = False\n",
    "    for ch in content:\n",
    "        if esc:\n",
    "            curr += ch\n",
    "            esc = False\n",
    "            continue\n",
    "        if ch == '\\\\':\n",
    "            curr += ch\n",
    "            esc = True\n",
    "            continue\n",
    "\n",
    "        if in_s:\n",
    "            curr += ch\n",
    "            if ch == \"'\":\n",
    "                in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            curr += ch\n",
    "            if ch == '\"':\n",
    "                in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\":\n",
    "            curr += ch\n",
    "            in_s = True\n",
    "            continue\n",
    "        if ch == '\"':\n",
    "            curr += ch\n",
    "            in_d = True\n",
    "            continue\n",
    "\n",
    "        if ch == ',':\n",
    "            parts.append(curr.strip())\n",
    "            curr = \"\"\n",
    "        else:\n",
    "            curr += ch\n",
    "    parts.append(curr.strip())\n",
    "    return parts\n",
    "\n",
    "def _strip_one_layer_quotes(s: str):\n",
    "    \"\"\"Remove a single layer of outer quotes if present; keep inner brackets intact.\"\"\"\n",
    "    s = s.strip()\n",
    "    if len(s) >= 2 and ((s[0] == s[-1] == \"'\") or (s[0] == s[-1] == '\"')):\n",
    "        return s[1:-1]\n",
    "    return s\n",
    "\n",
    "def split_lhs_items(lhs_text: str):\n",
    "    \"\"\"\n",
    "    lhs_text is exactly what's before '-->', e.g. \"['A', 'B', 'C']\" or \"['A']\".\n",
    "    Return list like ['A','B','C'] (no outer quotes/brackets).\n",
    "    \"\"\"\n",
    "    s = str(lhs_text)\n",
    "    start, end = _find_outer_brackets_span(s)\n",
    "    if start is None or end is None:\n",
    "        return []\n",
    "    inner = s[start+1:end]  # inside [...]\n",
    "    raw_items = _split_top_level_commas(inner)\n",
    "    return [_strip_one_layer_quotes(x).strip() for x in raw_items if x != \"\"]\n",
    "\n",
    "def _pad3(items):\n",
    "    items = items[:3]\n",
    "    return items + [\"\"] * (3 - len(items))\n",
    "\n",
    "lhs_split = crm_df['LHS_features'].apply(split_lhs_items).apply(_pad3)\n",
    "lhs_df = pd.DataFrame(lhs_split.tolist(), columns=['feature_1_lhs','feature_2_lhs','feature_3_lhs'])\n",
    "\n",
    "# ---------- 3) Final table ----------\n",
    "crm_rules_all_expanded = pd.concat(\n",
    "    [crm_df[['Dataset','Labeling','Encoding','Rule','LHS_features','RHS_label']].reset_index(drop=True),\n",
    "     lhs_df.reset_index(drop=True)],\n",
    "    axis=1\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Optional: sort for readability\n",
    "crm_rules_all_expanded = crm_rules_all_expanded.sort_values(\n",
    "    by=['Dataset','Labeling','Encoding'], ascending=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Show result\n",
    "crm_rules_all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Subsumption-based redundancy (structural overlap) ---\n",
    "\n",
    "# CONFIG: relative tolerance (e.g., 0.05 => ±5%)\n",
    "SUBSUMPTION_TOL = 0.05\n",
    "\n",
    "# 0) Ensure we have Odds ratio in crm_rules_all_expanded\n",
    "rules_src = crm_rules_all_expanded.copy()\n",
    "#rules_src = all_rules_crm.copy()\n",
    "\n",
    "if 'LB odds ratio' not in rules_src.columns:\n",
    "    # Merge it from the original all_rules_crm by (Dataset, Labeling, Encoding, Rule)\n",
    "    # Assumes `all_rules_crm` is already loaded in memory\n",
    "    or_src = all_rules_crm.copy()\n",
    "    if 'Encoding' not in or_src.columns and 'Feature Encoding' in or_src.columns:\n",
    "        or_src = or_src.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "    or_src['LB odds ratio'] = pd.to_numeric(or_src['LB odds ratio'], errors='coerce')\n",
    "    rules_src = rules_src.merge(\n",
    "        or_src[['Dataset','Labeling','Encoding','Rule','LB odds ratio']],\n",
    "        on=['Dataset','Labeling','Encoding','Rule'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# 1) Build antecedent lists/sets and sizes\n",
    "def _collect_feats(row):\n",
    "    feats = []\n",
    "    for c in ('feature_1_lhs','feature_2_lhs','feature_3_lhs'):\n",
    "        v = row.get(c, \"\")\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            feats.append(v.strip())\n",
    "    return tuple(feats)  # order as given in rule (we compare as sets for subset check)\n",
    "\n",
    "rules_src['antecedent_items'] = rules_src.apply(_collect_feats, axis=1)\n",
    "rules_src['antecedent_size']  = rules_src['antecedent_items'].apply(lambda t: len([x for x in t if x]))\n",
    "\n",
    "# Safety: numeric OR only\n",
    "rules_src['LB odds ratio'] = pd.to_numeric(rules_src['LB odds ratio'], errors='coerce')\n",
    "\n",
    "# 2) For each group, check subsumption\n",
    "results = []\n",
    "\n",
    "group_cols = ['Dataset','Labeling','Encoding','RHS_label']\n",
    "for gkey, g in rules_src.groupby(group_cols, dropna=False):\n",
    "    g = g.reset_index(drop=True).copy()\n",
    "\n",
    "    # Index conveniences\n",
    "    sizes = g['antecedent_size'].values\n",
    "    ors   = g['LB odds ratio'].values\n",
    "    items = g['antecedent_items'].values\n",
    "    rules = g['Rule'].values\n",
    "\n",
    "    # Pre-bucket indices by antecedent size for quick lookup\n",
    "    from collections import defaultdict\n",
    "    by_size = defaultdict(list)\n",
    "    for idx, s in enumerate(sizes):\n",
    "        by_size[int(s)].append(idx)\n",
    "\n",
    "    n = len(g)\n",
    "    n_subsumers = np.zeros(n, dtype=int)\n",
    "    is_subsumed = np.zeros(n, dtype=bool)\n",
    "    subsumed_by = [[] for _ in range(n)]\n",
    "\n",
    "    for i in range(n):\n",
    "        Xi = set(items[i])\n",
    "        si = sizes[i]\n",
    "        oi = ors[i]\n",
    "\n",
    "        if si <= 0 or np.isnan(oi):\n",
    "            continue  # nothing to compare or missing OR\n",
    "\n",
    "        # Candidates: strictly smaller antecedents\n",
    "        candidates = []\n",
    "        for s in range(1, int(si)):  # only sizes 1..(si-1)\n",
    "            candidates.extend(by_size.get(s, []))\n",
    "\n",
    "        for j in candidates:\n",
    "            Xj = set(items[j])\n",
    "            oj = ors[j]\n",
    "\n",
    "            if np.isnan(oj):\n",
    "                continue\n",
    "\n",
    "            # same consequent is guaranteed by grouping on RHS_label\n",
    "            # subset check: Xj ⊆ Xi\n",
    "            if not Xj.issubset(Xi):\n",
    "                continue\n",
    "\n",
    "            # relative effect size difference within tolerance:\n",
    "            # |oi - oj| / max(oj, tiny) <= SUBSUMPTION_TOL\n",
    "            denom = max(abs(oj), 1e-12)\n",
    "            rel_diff = abs(oi - oj) / denom\n",
    "            if rel_diff <= SUBSUMPTION_TOL:\n",
    "                n_subsumers[i] += 1\n",
    "                is_subsumed[i] = True\n",
    "                subsumed_by[i].append(rules[j])\n",
    "\n",
    "    g['n_subsumers']      = n_subsumers\n",
    "    g['is_subsumed']      = is_subsumed\n",
    "    g['subsumed_by_rules']= subsumed_by\n",
    "    results.append(g)\n",
    "\n",
    "crm_subsumption = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 3) Tidy output columns (you can adjust ordering as you like)\n",
    "crm_subsumption = crm_subsumption[[\n",
    "    'Dataset','Labeling','Encoding','Rule','RHS_label',\n",
    "    'LB odds ratio','antecedent_size','antecedent_items',\n",
    "    'feature_1_lhs','feature_2_lhs','feature_3_lhs',\n",
    "    'n_subsumers','is_subsumed','subsumed_by_rules'\n",
    "]].sort_values(['Dataset','Labeling','Encoding','RHS_label','antecedent_size'])\n",
    "\n",
    "# Display tweaks\n",
    "crm_subsumption.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Quick summary per experiment:\n",
    "subsumed_summary = (\n",
    "    crm_subsumption\n",
    "    .groupby(['Dataset','Labeling','Encoding','RHS_label'], as_index=False)\n",
    "    .agg(\n",
    "        n_rules=('Rule','count'),\n",
    "        n_subsumed=('is_subsumed','sum'),\n",
    "        pct_subsumed=('is_subsumed', lambda x: round(100.0 * x.mean(), 2))\n",
    "    )\n",
    ").sort_values(['Dataset','Labeling','Encoding','RHS_label'])\n",
    "\n",
    "# Display results\n",
    "display(crm_subsumption)\n",
    "display(subsumed_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242eb5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export subsumed_summary with cleaned Labeling and renamed columns (CSV + LaTeX) ---\n",
    "if 'subsumed_summary' not in globals() or not isinstance(subsumed_summary, pd.DataFrame):\n",
    "    raise ValueError(\"subsumed_summary is not available as a DataFrame.\")\n",
    "\n",
    "# 1) Collect dataset tokens to strip from Labeling (case/whitespace-insensitive)\n",
    "def _collect_prefixes(series: pd.Series) -> set:\n",
    "    s = series.astype(str).str.strip().str.lower().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    prefixes = set(s.unique().tolist())\n",
    "    # Common aliases you might encounter\n",
    "    prefixes |= {\"sepsis\", \"traffic\", \"bpi15a\"}\n",
    "    return {p for p in prefixes if p and p != \"nan\"}\n",
    "\n",
    "# 2) Strip dataset prefix from Labeling while preserving the rest of the string's case\n",
    "def _strip_dataset_prefix(label: str, prefixes: set) -> str:\n",
    "    s = str(label)\n",
    "    while True:\n",
    "        if \"_\" not in s:\n",
    "            return s\n",
    "        head, tail = s.split(\"_\", 1)\n",
    "        head_norm = head.strip().lower().replace(\" \", \"\")\n",
    "        if head_norm in prefixes:\n",
    "            s = tail\n",
    "        else:\n",
    "            return s\n",
    "\n",
    "# 3) Prepare a detokenizer for LaTeX\n",
    "def _fmt_detok(x):\n",
    "    return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "# Build export DataFrame\n",
    "prefixes = _collect_prefixes(subsumed_summary[\"Dataset\"]) if \"Dataset\" in subsumed_summary.columns else set()\n",
    "subsumed_export = subsumed_summary.copy()\n",
    "\n",
    "# Clean Labeling: remove dataset prefix\n",
    "if \"Labeling\" in subsumed_export.columns:\n",
    "    subsumed_export[\"Labeling\"] = subsumed_export[\"Labeling\"].map(lambda v: _strip_dataset_prefix(v, prefixes))\n",
    "\n",
    "# Rename columns\n",
    "rename_map = {\n",
    "    \"RHS_label\": \"RHS Label\",\n",
    "    \"n_rules\": \"n rules\",\n",
    "    \"n_subsumed\": \"n sumbsumed\",\n",
    "    \"pct_subsumed\": \"pct subsumed\"\n",
    "}\n",
    "subsumed_export = subsumed_export.rename(columns=rename_map)\n",
    "\n",
    "# Paths\n",
    "out_dir = os.path.join(\"5_analysis\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "csv_path = os.path.join(out_dir, \"redundancy_subsumed.csv\")\n",
    "tex_path = os.path.join(out_dir, \"redundancy_subsumed.tex\")\n",
    "\n",
    "# CSV\n",
    "subsumed_export.to_csv(csv_path, index=False)\n",
    "print(f\"✅ Saved redundancy_subsumed.csv → {csv_path}\")\n",
    "\n",
    "# LaTeX: make column headers LaTeX-safe and detokenize 'Labeling' values\n",
    "latex_safe_map = {c: str(c).replace(\"#\", r\"\\#\").replace(\"%\", r\"\\%\").replace(\"_\", r\"\\_\")\n",
    "                  for c in subsumed_export.columns}\n",
    "subsumed_export_tex = subsumed_export.rename(columns=latex_safe_map)\n",
    "\n",
    "formatters = {\"Labeling\": _fmt_detok} if \"Labeling\" in subsumed_export_tex.columns else None\n",
    "\n",
    "subsumed_export_tex.to_latex(\n",
    "    tex_path,\n",
    "    index=False,\n",
    "    escape=False,       \n",
    "    longtable=True,\n",
    "    float_format=\"%.2f\",\n",
    "    formatters=formatters\n",
    ")\n",
    "print(f\"✅ Saved redundancy_subsumed.tex  → {tex_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556a08b",
   "metadata": {},
   "source": [
    "### 6.2. Coverage-Based Redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CRM rules → expand LHS features and compute per-rule coverage (excluding MR/MRA/TR/TRA) ----------\n",
    "\n",
    "# Fallback if not defined earlier\n",
    "try:\n",
    "    exclude_encodings\n",
    "except NameError:\n",
    "    exclude_encodings = [\"mr\", \"mra\", \"tr\", \"tra\"]\n",
    "\n",
    "# ---------- 0) Start from all_rules_crm ----------\n",
    "if 'all_rules_crm' not in globals() or not isinstance(all_rules_crm, pd.DataFrame):\n",
    "    raise ValueError(\"all_rules_crm is not available as a DataFrame.\")\n",
    "crm_df = all_rules_crm.copy()\n",
    "\n",
    "# Harmonize encoding column name\n",
    "crm_df = crm_df.rename(columns={\n",
    "    'Feature Encoding': 'Encoding',\n",
    "    'Feature encoding': 'Encoding'\n",
    "})\n",
    "\n",
    "# Exclude encodings (case/whitespace-insensitive)\n",
    "if 'Encoding' in crm_df.columns:\n",
    "    _excl = {e.strip().lower() for e in exclude_encodings}\n",
    "    enc_norm = crm_df['Encoding'].astype(str).str.strip().str.lower()\n",
    "    crm_df = crm_df[~enc_norm.isin(_excl)].copy()\n",
    "\n",
    "# Filter on LB odds ratio > 1\n",
    "crm_df['LB odds ratio'] = pd.to_numeric(crm_df['LB odds ratio'], errors='coerce')\n",
    "crm_df = crm_df[crm_df['LB odds ratio'] > 1].copy()\n",
    "\n",
    "# ---------- normalize Labeling exactly like earlier ----------\n",
    "def _build_known_prefixes(df_list):\n",
    "    prefixes = set()\n",
    "    for df in df_list:\n",
    "        if isinstance(df, pd.DataFrame) and 'Dataset' in df.columns:\n",
    "            s = pd.Series(df['Dataset']).astype(str).str.strip().str.lower()\n",
    "            prefixes.update(s.str.replace(r'\\s+', '', regex=True).unique().tolist())\n",
    "    prefixes |= {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "    return {p for p in prefixes if p and p != 'nan'}\n",
    "\n",
    "try:\n",
    "    KNOWN_PREFIXES\n",
    "except NameError:\n",
    "    KNOWN_PREFIXES = _build_known_prefixes([crm_df])\n",
    "\n",
    "def _canon_label(lbl: str) -> str:\n",
    "    s = str(lbl).strip().lower()\n",
    "    s = re.sub(r'(_features?)$', '', s)   # drop suffix\n",
    "    s = s.replace(' ', '_')\n",
    "    # strip dataset prefixes repeatedly\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "            if s.startswith(p + '_'):\n",
    "                s = s[len(p) + 1:]\n",
    "                changed = True\n",
    "    if re.search(r'\\bpayload(\\d+)?\\b', s):\n",
    "        return 'payload'\n",
    "    if re.fullmatch(r'(decl(are)?\\d*)', s):\n",
    "        return 'declare'\n",
    "    if re.search(r'(^|[^a-z])mr([^a-z]|$)', s):\n",
    "        return 'sequential'\n",
    "    return s\n",
    "\n",
    "if 'Labeling' in crm_df.columns:\n",
    "    crm_df['Labeling'] = crm_df['Labeling'].apply(_canon_label)\n",
    "\n",
    "# ---------- 1) Extract exact LHS and RHS ----------\n",
    "def extract_lhs_exact(rule_str: str) -> str:\n",
    "    m = re.search(r\"^(.*?)(?=\\s*-->)\", str(rule_str))\n",
    "    return m.group(1) if m else str(rule_str)\n",
    "\n",
    "def parse_rhs_label(rule_str: str):\n",
    "    m = re.search(r\"-->\\s*(Label|!Label)\", str(rule_str))\n",
    "    if not m:\n",
    "        return None\n",
    "    return 1 if m.group(1) == \"Label\" else 0\n",
    "\n",
    "crm_df['LHS_features'] = crm_df['Rule'].apply(extract_lhs_exact)\n",
    "crm_df['RHS_label']    = crm_df['Rule'].apply(parse_rhs_label)\n",
    "\n",
    "# ---------- 2) Robustly split LHS into up to 3 features (paren-aware) ----------\n",
    "def _find_outer_brackets_span(text: str):\n",
    "    s = str(text)\n",
    "    start = s.find('[')\n",
    "    if start < 0:\n",
    "        return None, None\n",
    "    depth = 0; in_s = in_d = esc = False; end = None\n",
    "    for i, ch in enumerate(s[start:], start):\n",
    "        if esc: esc = False; continue\n",
    "        if ch == '\\\\': esc = True; continue\n",
    "        if in_s:\n",
    "            if ch == \"'\": in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            if ch == '\"': in_d = False\n",
    "            continue\n",
    "        if ch == \"'\": in_s = True; continue\n",
    "        if ch == '\"': in_d = True; continue\n",
    "        if ch == '[': depth += 1; continue\n",
    "        if ch == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0: end = i; break\n",
    "    return (start, end)\n",
    "\n",
    "def _split_commas_outside_quotes_and_parens(content: str):\n",
    "    \"\"\"Split on commas that are outside quotes AND outside parentheses.\"\"\"\n",
    "    parts, curr = [], \"\"\n",
    "    in_s = in_d = esc = False\n",
    "    paren_depth = 0\n",
    "    for ch in content:\n",
    "        if esc: curr += ch; esc = False; continue\n",
    "        if ch == '\\\\': curr += ch; esc = True; continue\n",
    "\n",
    "        if in_s:\n",
    "            curr += ch\n",
    "            if ch == \"'\": in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            curr += ch\n",
    "            if ch == '\"': in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\": curr += ch; in_s = True; continue\n",
    "        if ch == '\"': curr += ch; in_d = True; continue\n",
    "\n",
    "        if ch == '(':\n",
    "            paren_depth += 1; curr += ch; continue\n",
    "        if ch == ')':\n",
    "            paren_depth = max(0, paren_depth - 1); curr += ch; continue\n",
    "\n",
    "        if ch == ',' and paren_depth == 0:\n",
    "            parts.append(curr.strip()); curr = \"\"\n",
    "        else:\n",
    "            curr += ch\n",
    "    parts.append(curr.strip())\n",
    "    return parts\n",
    "\n",
    "def _strip_one_layer_quotes(s: str):\n",
    "    s = s.strip()\n",
    "    if len(s) >= 2 and ((s[0] == s[-1] == \"'\") or (s[0] == s[-1] == '\"')):\n",
    "        return s[1:-1]\n",
    "    return s\n",
    "\n",
    "def split_lhs_items(lhs_text: str):\n",
    "    s = str(lhs_text)\n",
    "    start, end = _find_outer_brackets_span(s)\n",
    "    if start is None or end is None:\n",
    "        return []\n",
    "    inner = s[start+1:end]          # inside [...]\n",
    "    raw_items = _split_commas_outside_quotes_and_parens(inner)\n",
    "    return [_strip_one_layer_quotes(x).strip() for x in raw_items if x != \"\"]\n",
    "\n",
    "def _pad3(items):\n",
    "    items = items[:3]\n",
    "    return items + [\"\"] * (3 - len(items))\n",
    "\n",
    "lhs_split = crm_df['LHS_features'].apply(split_lhs_items).apply(_pad3)\n",
    "lhs_df = pd.DataFrame(lhs_split.tolist(), columns=['feature_1_lhs','feature_2_lhs','feature_3_lhs'])\n",
    "\n",
    "# ---------- 3) Final rules table (expanded) ----------\n",
    "crm_rules_all_expanded = pd.concat(\n",
    "    [crm_df[['Dataset','Labeling','Encoding','Rule','LHS_features','RHS_label']].reset_index(drop=True),\n",
    "     lhs_df.reset_index(drop=True)],\n",
    "    axis=1\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# ---------- 4) Per-rule coverage over 3.2_binned_logs ----------\n",
    "base_dir = \"3.2_binned_features\"\n",
    "\n",
    "def _infer_case_col(df: pd.DataFrame) -> str:\n",
    "    for c in [\"Case_ID\", \"case:concept:name\", \"Case ID\", \"case_id\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(\"No Case ID column found (tried: Case_ID, case:concept:name, Case ID, case_id)\")\n",
    "\n",
    "def _norm_numeric(col: pd.Series) -> pd.Series:\n",
    "    if col.dtype == bool:\n",
    "        return col.astype(int)\n",
    "    out = pd.to_numeric(col, errors='coerce')\n",
    "    if out.isna().all() and col.dtype == object:\n",
    "        return col\n",
    "    return out\n",
    "\n",
    "NUM_SUFFIX_RE = re.compile(r\"_(\\-?\\d+(?:\\.\\d+)?)$\")  # _1, _1.0, _0, _-1, etc.\n",
    "\n",
    "def _match_single_feature(df: pd.DataFrame, feat: str) -> pd.Series:\n",
    "    feat = str(feat).strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    # A) exact one-hot column\n",
    "    if feat in df.columns:\n",
    "        col = _norm_numeric(df[feat])\n",
    "        return (col == 1) if pd.api.types.is_numeric_dtype(col) else (col.astype(str) == \"1\")\n",
    "\n",
    "    # B) general numeric suffix at end: base_<num>\n",
    "    m = NUM_SUFFIX_RE.search(feat)\n",
    "    if m:\n",
    "        base_col = feat[:m.start()]\n",
    "        desired_str = m.group(1)\n",
    "        desired = float(desired_str)\n",
    "        if base_col in df.columns:\n",
    "            col = _norm_numeric(df[base_col])\n",
    "            if pd.api.types.is_numeric_dtype(col):\n",
    "                return (col == desired).fillna(False)\n",
    "            else:\n",
    "                return (col.astype(str) == desired_str).fillna(False)\n",
    "        # rare: indicator named with suffix\n",
    "        if feat in df.columns:\n",
    "            col = _norm_numeric(df[feat])\n",
    "            return ((col == 1) if pd.api.types.is_numeric_dtype(col) else (col.astype(str) == \"1\")).fillna(False)\n",
    "\n",
    "    # C) binned: base_(...) or base_[...]\n",
    "    pos1 = feat.rfind(\"_(\")\n",
    "    pos2 = feat.rfind(\"_[\")\n",
    "    split_pos = max(pos1, pos2)\n",
    "    if split_pos != -1:\n",
    "        base_col = feat[:split_pos]\n",
    "        bin_val  = feat[split_pos+1:]  # drop underscore before bracket\n",
    "        if base_col in df.columns:\n",
    "            return (df[base_col].astype(str) == bin_val).fillna(False)\n",
    "\n",
    "    # fallback: no matches\n",
    "    return pd.Series(False, index=df.index)\n",
    "\n",
    "def _match_rule(df: pd.DataFrame, features: list, rhs_label: int) -> pd.Series:\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    for f in features:\n",
    "        if f:\n",
    "            mask &= _match_single_feature(df, f)\n",
    "            if not mask.any():\n",
    "                break\n",
    "    # enforce RHS label\n",
    "    if rhs_label in (0, 1):\n",
    "        mask &= (pd.to_numeric(df[\"Label\"], errors=\"coerce\") == rhs_label)\n",
    "    else:\n",
    "        mask &= False\n",
    "    return mask\n",
    "\n",
    "# ---------- robust path resolution using canonicalized labeling ----------\n",
    "def _canon_from_folder(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r'(_features?)$', '', s)\n",
    "    s = s.replace(' ', '_')\n",
    "    # strip dataset prefixes\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "            if s.startswith(p + '_'):\n",
    "                s = s[len(p) + 1:]\n",
    "                changed = True\n",
    "    if re.search(r'\\bpayload(\\d+)?\\b', s):\n",
    "        return 'payload'\n",
    "    if re.fullmatch(r'(decl(are)?\\d*)', s):\n",
    "        return 'declare'\n",
    "    if re.search(r'(^|[^a-z])mr([^a-z]|$)', s):\n",
    "        return 'sequential'\n",
    "    return s\n",
    "\n",
    "def _find_ci_subdir(parent: str, target: str) -> str | None:\n",
    "    \"\"\"Case-insensitive lookup of subdir 'target' inside 'parent'.\"\"\"\n",
    "    t = target.lower()\n",
    "    try:\n",
    "        for d in os.listdir(parent):\n",
    "            full = os.path.join(parent, d)\n",
    "            if os.path.isdir(full) and d.lower() == t:\n",
    "                return full\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def _resolve_enc_path(ds: str, lab_canon: str, enc: str, base_dir: str) -> str | None:\n",
    "    ds_dir = os.path.join(base_dir, ds)\n",
    "    if not os.path.isdir(ds_dir):\n",
    "        return None\n",
    "    candidates = []\n",
    "    for d in sorted(os.listdir(ds_dir)):\n",
    "        full = os.path.join(ds_dir, d)\n",
    "        if not os.path.isdir(full):\n",
    "            continue\n",
    "        if not d.lower().endswith(\"_features\"):\n",
    "            continue\n",
    "        if _canon_from_folder(d) == lab_canon:\n",
    "            # exact encoding dir?\n",
    "            enc_path = os.path.join(full, enc)\n",
    "            if os.path.isdir(enc_path):\n",
    "                return enc_path\n",
    "            # try case-insensitive encoding match\n",
    "            ci = _find_ci_subdir(full, enc)\n",
    "            if ci:\n",
    "                return ci\n",
    "            candidates.append(full)\n",
    "    # If we found labeling folder(s) but no encoding subdir, return None\n",
    "    return None\n",
    "\n",
    "crm_rules_all_with_coverage = crm_rules_all_expanded.copy()\n",
    "crm_rules_all_with_coverage[\"covered_case_ids\"] = [[] for _ in range(len(crm_rules_all_with_coverage))]\n",
    "crm_rules_all_with_coverage[\"n_covered_cases\"] = 0\n",
    "\n",
    "# Iterate once per experiment; load CSV and evaluate each rule in that group\n",
    "for (ds, lab, enc), g in crm_rules_all_with_coverage.groupby([\"Dataset\", \"Labeling\", \"Encoding\"]):\n",
    "    enc_path = _resolve_enc_path(ds, lab, enc, base_dir)\n",
    "    if enc_path is None:\n",
    "        continue\n",
    "\n",
    "    csv_files = [f for f in os.listdir(enc_path) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        continue\n",
    "    csv_path = os.path.join(enc_path, csv_files[0])\n",
    "\n",
    "    df_enc = pd.read_csv(csv_path)\n",
    "    if \"Label\" not in df_enc.columns:\n",
    "        raise KeyError(f\"No 'Label' column in: {csv_path}\")\n",
    "    case_col = _infer_case_col(df_enc)\n",
    "\n",
    "    for idx, row in g.iterrows():\n",
    "        feats = [row.get(\"feature_1_lhs\",\"\"), row.get(\"feature_2_lhs\",\"\"), row.get(\"feature_3_lhs\",\"\")]\n",
    "        feats = [f for f in feats if isinstance(f, str) and f.strip() != \"\"]\n",
    "        rhs   = row[\"RHS_label\"]\n",
    "\n",
    "        rule_mask = _match_rule(df_enc, feats, rhs)\n",
    "        case_ids = df_enc.loc[rule_mask, case_col].dropna().astype(str).unique().tolist()\n",
    "\n",
    "        crm_rules_all_with_coverage.at[idx, \"covered_case_ids\"] = case_ids\n",
    "        crm_rules_all_with_coverage.at[idx, \"n_covered_cases\"] = len(case_ids)\n",
    "\n",
    "# Sort for readability\n",
    "crm_rules_all_with_coverage = crm_rules_all_with_coverage.sort_values(\n",
    "    by=[\"Dataset\",\"Labeling\",\"Encoding\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "crm_rules_all_with_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Config ----\n",
    "JACCARD_THR = 0.95 \n",
    "\n",
    "def _to_case_set(x):\n",
    "    if isinstance(x, list):\n",
    "        try:\n",
    "            return set(map(str, x))\n",
    "        except Exception:\n",
    "            return set()\n",
    "    return set()\n",
    "\n",
    "def _jaccard(a: set, b: set) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "pairs_rows = []\n",
    "\n",
    "# Pairwise Jaccard *within* each experiment & RHS_label (only compare rules for the same consequent)\n",
    "group_cols = [\"Dataset\", \"Labeling\", \"Encoding\", \"RHS_label\"]\n",
    "for gkey, g in crm_rules_all_with_coverage.groupby(group_cols, dropna=False):\n",
    "    g = g.reset_index(drop=True)\n",
    "    # Precompute sets\n",
    "    sets = [ _to_case_set(x) for x in g[\"covered_case_ids\"].tolist() ]\n",
    "    rules = g[\"Rule\"].tolist()\n",
    "\n",
    "    for (i, j) in itertools.combinations(range(len(g)), 2):\n",
    "        A, B = sets[i], sets[j]\n",
    "        jac = _jaccard(A, B)\n",
    "        pairs_rows.append({\n",
    "            \"Dataset\":   gkey[0],\n",
    "            \"Labeling\":  gkey[1],\n",
    "            \"Encoding\":  gkey[2],\n",
    "            \"RHS_label\": gkey[3],\n",
    "            \"Rule_i\":    rules[i],\n",
    "            \"Rule_j\":    rules[j],\n",
    "            \"n_i\":       len(A),\n",
    "            \"n_j\":       len(B),\n",
    "            \"n_inter\":   len(A & B),\n",
    "            \"n_union\":   len(A | B),\n",
    "            \"jaccard\":   round(jac, 4),\n",
    "            \"redundant_pair\": jac >= JACCARD_THR\n",
    "        })\n",
    "\n",
    "crm_cov_jaccard_pairs = pd.DataFrame(pairs_rows).sort_values(\n",
    "    [\"Dataset\",\"Labeling\",\"Encoding\",\"RHS_label\",\"jaccard\"], ascending=[True,True,True,True,False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Pairs flagged as redundant (Jaccard >= threshold)\n",
    "crm_cov_redundant_pairs = crm_cov_jaccard_pairs[crm_cov_jaccard_pairs[\"redundant_pair\"]].reset_index(drop=True)\n",
    "\n",
    "# ---- Per-rule summary: max overlap & count of redundant partners ----\n",
    "def _summarize_for_rules(df_pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Construct a long table of (rule, partner, jaccard)\n",
    "    long_i = df_pairs.rename(columns={\"Rule_i\":\"Rule\", \"Rule_j\":\"partner\", \"n_i\":\"n_rule\", \"n_j\":\"n_partner\"})[\n",
    "        [\"Dataset\",\"Labeling\",\"Encoding\",\"RHS_label\",\"Rule\",\"partner\",\"jaccard\",\"redundant_pair\",\"n_rule\",\"n_partner\"]\n",
    "    ]\n",
    "    long_j = df_pairs.rename(columns={\"Rule_j\":\"Rule\", \"Rule_i\":\"partner\", \"n_j\":\"n_rule\", \"n_i\":\"n_partner\"})[\n",
    "        [\"Dataset\",\"Labeling\",\"Encoding\",\"RHS_label\",\"Rule\",\"partner\",\"jaccard\",\"redundant_pair\",\"n_rule\",\"n_partner\"]\n",
    "    ]\n",
    "    long_all = pd.concat([long_i, long_j], ignore_index=True)\n",
    "\n",
    "    # Aggregate per rule\n",
    "    summary = (\n",
    "        long_all\n",
    "        .groupby([\"Dataset\",\"Labeling\",\"Encoding\",\"RHS_label\",\"Rule\"], as_index=False)\n",
    "        .agg(\n",
    "            n_partners=(\"partner\",\"nunique\"),\n",
    "            max_jaccard=(\"jaccard\",\"max\"),\n",
    "            n_redundant_partners=(\"redundant_pair\",\"sum\")\n",
    "        )\n",
    "    )\n",
    "    summary[\"is_redundant\"] = summary[\"n_redundant_partners\"] > 0\n",
    "    return summary\n",
    "\n",
    "crm_cov_redundancy_summary = _summarize_for_rules(crm_cov_jaccard_pairs).sort_values(\n",
    "    [\"Dataset\",\"Labeling\",\"Encoding\",\"RHS_label\",\"max_jaccard\"], ascending=[True,True,True,True,False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "crm_cov_redundancy_summary = crm_cov_redundancy_summary.drop(columns=[\"RHS_label\", \"n_partners\", \"is_redundant\"])\n",
    "crm_cov_redundancy_summary = crm_cov_redundancy_summary[crm_cov_redundancy_summary[\"n_redundant_partners\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(crm_cov_jaccard_pairs)\n",
    "display(crm_cov_redundant_pairs)\n",
    "display(crm_cov_redundancy_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d74b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Coverage-based redundancy: per-experiment summary ----------\n",
    "\n",
    "# Safety checks\n",
    "if 'crm_rules_all_with_coverage' not in globals():\n",
    "    raise RuntimeError(\"crm_rules_all_with_coverage not found. Run the previous cell first.\")\n",
    "if 'crm_cov_jaccard_pairs' not in globals():\n",
    "    raise RuntimeError(\"crm_cov_jaccard_pairs not found. Run the Jaccard computation cell first.\")\n",
    "if 'crm_cov_redundant_pairs' not in globals():\n",
    "    raise RuntimeError(\"crm_cov_redundant_pairs not found. Run the Jaccard computation cell first.\")\n",
    "\n",
    "# --- Base experiments and rule counts ---\n",
    "exp_rules = (\n",
    "    crm_rules_all_with_coverage\n",
    "    .groupby(['Dataset','Labeling','Encoding'], as_index=False)\n",
    "    .agg(n_rules_total=('Rule','nunique'),\n",
    "         n_rules_z=('RHS_label', lambda s: (s==1).sum()),\n",
    "         n_rules_notz=('RHS_label', lambda s: (s==0).sum()))\n",
    ")\n",
    "\n",
    "# --- Pairwise stats (all pairs) ---\n",
    "if not crm_cov_jaccard_pairs.empty:\n",
    "    exp_pairs_all = (\n",
    "        crm_cov_jaccard_pairs\n",
    "        .groupby(['Dataset','Labeling','Encoding'], as_index=False)\n",
    "        .agg(n_pairs_total=('jaccard','size'),\n",
    "             mean_jaccard_all=('jaccard','mean'),\n",
    "             max_jaccard_all=('jaccard','max'))\n",
    "    )\n",
    "else:\n",
    "    exp_pairs_all = pd.DataFrame(columns=['Dataset','Labeling','Encoding','n_pairs_total','mean_jaccard_all','max_jaccard_all'])\n",
    "\n",
    "# --- Redundant pairs only ---\n",
    "if not crm_cov_redundant_pairs.empty:\n",
    "    exp_pairs_redundant = (\n",
    "        crm_cov_redundant_pairs\n",
    "        .groupby(['Dataset','Labeling','Encoding'], as_index=False)\n",
    "        .agg(n_pairs_redundant=('jaccard','size'),\n",
    "             mean_jaccard_redundant=('jaccard','mean'))\n",
    "    )\n",
    "else:\n",
    "    exp_pairs_redundant = pd.DataFrame(columns=['Dataset','Labeling','Encoding','n_pairs_redundant','mean_jaccard_redundant'])\n",
    "\n",
    "# --- Redundant rules (unique nodes that appear in any redundant pair) ---\n",
    "if not crm_cov_redundant_pairs.empty:\n",
    "    nodes_i = crm_cov_redundant_pairs[['Dataset','Labeling','Encoding','RHS_label','Rule_i']].rename(columns={'Rule_i':'Rule'})\n",
    "    nodes_j = crm_cov_redundant_pairs[['Dataset','Labeling','Encoding','RHS_label','Rule_j']].rename(columns={'Rule_j':'Rule'})\n",
    "    red_nodes = pd.concat([nodes_i, nodes_j], ignore_index=True).drop_duplicates()\n",
    "    exp_rules_redundant = (\n",
    "        red_nodes\n",
    "        .groupby(['Dataset','Labeling','Encoding'], as_index=False)\n",
    "        .agg(n_rules_redundant=('Rule','nunique'))\n",
    "    )\n",
    "else:\n",
    "    exp_rules_redundant = pd.DataFrame(columns=['Dataset','Labeling','Encoding','n_rules_redundant'])\n",
    "\n",
    "# --- Build redundancy clusters (connected components) within each (exp, RHS_label) ---\n",
    "class DSU:\n",
    "    def __init__(self): self.p={}; self.r={}\n",
    "    def find(self,x):\n",
    "        if self.p.get(x,x)!=x: self.p[x]=self.find(self.p[x])\n",
    "        return self.p.get(x,x)\n",
    "    def union(self,a,b):\n",
    "        ra,rb=self.find(a),self.find(b)\n",
    "        if ra==rb: return\n",
    "        self.p.setdefault(ra,ra); self.p.setdefault(rb,rb)\n",
    "        self.r.setdefault(ra,0);  self.r.setdefault(rb,0)\n",
    "        if self.r[ra]<self.r[rb]: self.p[ra]=rb\n",
    "        elif self.r[ra]>self.r[rb]: self.p[rb]=ra\n",
    "        else: self.p[rb]=ra; self.r[ra]+=1\n",
    "\n",
    "def cluster_counts_per_exp(pairs_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    if pairs_df.empty:\n",
    "        return pd.DataFrame(columns=['Dataset','Labeling','Encoding','n_clusters','avg_cluster_size','max_cluster_size'])\n",
    "    for (ds,lab,enc,rhs), g in pairs_df.groupby(['Dataset','Labeling','Encoding','RHS_label'], dropna=False):\n",
    "        nodes = set(g['Rule_i']).union(set(g['Rule_j']))\n",
    "        if not nodes:\n",
    "            continue\n",
    "        dsu=DSU()\n",
    "        for _,r in g.iterrows():\n",
    "            dsu.union(('R',r['Rule_i']), ('R',r['Rule_j']))\n",
    "        from collections import defaultdict as _dd\n",
    "        parent_sizes=_dd(int)\n",
    "        for ru in nodes:\n",
    "            parent_sizes[dsu.find(('R',ru))]+=1\n",
    "        rows.append({\n",
    "            'Dataset': ds, 'Labeling': lab, 'Encoding': enc,\n",
    "            'RHS_label': rhs,\n",
    "            'n_clusters_rhs': len(parent_sizes),\n",
    "            'avg_cluster_size_rhs': float(np.mean(list(parent_sizes.values()))) if parent_sizes else 0.0,\n",
    "            'max_cluster_size_rhs': max(parent_sizes.values()) if parent_sizes else 0\n",
    "        })\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=['Dataset','Labeling','Encoding','n_clusters','avg_cluster_size','max_cluster_size'])\n",
    "    df = pd.DataFrame(rows)\n",
    "    out = (\n",
    "        df.groupby(['Dataset','Labeling','Encoding'], as_index=False)\n",
    "          .agg(n_clusters=('n_clusters_rhs','sum'),\n",
    "               avg_cluster_size=('avg_cluster_size_rhs','mean'),\n",
    "               max_cluster_size=('max_cluster_size_rhs','max'))\n",
    "    )\n",
    "    return out\n",
    "\n",
    "exp_clusters = cluster_counts_per_exp(crm_cov_redundant_pairs)\n",
    "\n",
    "# --- Assemble summary ---\n",
    "summary = (\n",
    "    exp_rules\n",
    "    .merge(exp_pairs_all, on=['Dataset','Labeling','Encoding'], how='left')\n",
    "    .merge(exp_pairs_redundant, on=['Dataset','Labeling','Encoding'], how='left')\n",
    "    .merge(exp_rules_redundant, on=['Dataset','Labeling','Encoding'], how='left')\n",
    "    .merge(exp_clusters, on=['Dataset','Labeling','Encoding'], how='left')\n",
    ")\n",
    "\n",
    "# Fill NaNs\n",
    "for c in ['n_pairs_total','n_pairs_redundant','n_rules_redundant','n_clusters',\n",
    "          'max_cluster_size']:\n",
    "    if c in summary.columns:\n",
    "        summary[c] = summary[c].fillna(0).astype(int)\n",
    "for c in ['mean_jaccard_all','mean_jaccard_redundant','max_jaccard_all','avg_cluster_size']:\n",
    "    if c in summary.columns:\n",
    "        summary[c] = summary[c].fillna(0.0)\n",
    "\n",
    "# Derived metrics\n",
    "summary['pct_pairs_redundant']  = np.where(summary['n_pairs_total']>0,\n",
    "                                           100.0*summary['n_pairs_redundant']/summary['n_pairs_total'], 0.0)\n",
    "summary['pct_rules_redundant']  = np.where(summary['n_rules_total']>0,\n",
    "                                           100.0*summary['n_rules_redundant']/summary['n_rules_total'], 0.0)\n",
    "\n",
    "# Order columns\n",
    "cols_order = [\n",
    "    'Dataset','Labeling','Encoding',\n",
    "    'n_rules_total','n_rules_z','n_rules_notz',\n",
    "    'n_rules_redundant','pct_rules_redundant',\n",
    "    'n_clusters','avg_cluster_size','max_cluster_size',\n",
    "    'n_pairs_total','n_pairs_redundant','pct_pairs_redundant',\n",
    "    'mean_jaccard_all','max_jaccard_all','mean_jaccard_redundant'\n",
    "]\n",
    "crm_cov_redundancy_exp_summary = summary[[c for c in cols_order if c in summary.columns]].sort_values(\n",
    "    ['Dataset','Labeling','Encoding']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# ---------- Rename and slim the coverage redundancy summary ----------\n",
    "\n",
    "if 'crm_cov_redundancy_exp_summary' not in globals():\n",
    "    raise RuntimeError(\"crm_cov_redundancy_exp_summary not found. Run the previous summary cell first.\")\n",
    "\n",
    "keep_raw = [\n",
    "    'Dataset', 'Labeling', 'Encoding',\n",
    "    'n_rules_total', 'n_rules_redundant', 'n_clusters'\n",
    "]\n",
    "keep_present = [c for c in keep_raw if c in crm_cov_redundancy_exp_summary.columns]\n",
    "\n",
    "crm_cov_redundancy_exp_summary_pretty = crm_cov_redundancy_exp_summary[keep_present].copy()\n",
    "\n",
    "rename_map = {\n",
    "    'n_rules_total': 'Total Rules',\n",
    "    'n_rules_redundant': 'Number of Redundant Rules',\n",
    "    'n_clusters': 'Number of Clusters'\n",
    "}\n",
    "crm_cov_redundancy_exp_summary_pretty = crm_cov_redundancy_exp_summary_pretty.rename(columns=rename_map)\n",
    "\n",
    "final_order = [c for c in [\n",
    "    'Dataset', 'Labeling', 'Encoding',\n",
    "    'Total Rules', 'Number of Redundant Rules', 'Number of Clusters'\n",
    "] if c in crm_cov_redundancy_exp_summary_pretty.columns]\n",
    "\n",
    "crm_cov_redundancy_exp_summary = (\n",
    "    crm_cov_redundancy_exp_summary_pretty[final_order]\n",
    "    .sort_values(['Dataset', 'Labeling', 'Encoding'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "crm_cov_redundancy_exp_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c59714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rules number of redundant rules per dataset\n",
    "# Calculate average redundant rules per dataset\n",
    "# Sum rules redundant per dataset\n",
    "sum_rules = (\n",
    "    crm_cov_redundancy_exp_summary.groupby(\"Dataset\")[\"Total Rules\"]\n",
    "      .sum()\n",
    "      .reset_index(name=\"Total Rules\")\n",
    ")\n",
    "print(sum_rules)\n",
    "\n",
    "avg_redundant_rules = (\n",
    "    crm_cov_redundancy_exp_summary.groupby(\"Dataset\")[\"Number of Redundant Rules\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"Avg Redundant Rules\")\n",
    ")\n",
    "print(avg_redundant_rules)\n",
    "\n",
    "# # Sum rules dropped per dataset\n",
    "# sum_rules_dropped = (\n",
    "#     crm_cov_redundancy_exp_summary.groupby(\"Dataset\")[\"Rules dropped\"]\n",
    "#       .sum()\n",
    "#       .reset_index(name=\"Total Rules Dropped\")\n",
    "# )\n",
    "# print(sum_rules_dropped)\n",
    "\n",
    "# Sum rules redundant per dataset\n",
    "sum_rules_redundant = (\n",
    "    crm_cov_redundancy_exp_summary.groupby(\"Dataset\")[\"Number of Redundant Rules\"]\n",
    "      .sum()\n",
    "      .reset_index(name=\"Total Redundant Rules\")\n",
    ")\n",
    "print(sum_rules_redundant)\n",
    "\n",
    "# rules_after = (\n",
    "#     sum_rules\n",
    "#     .merge(sum_rules_dropped, on=\"Dataset\", how=\"outer\")\n",
    "#     .fillna(0)\n",
    "# )\n",
    "# rules_after[\"Rules After Dropping\"] = (\n",
    "#     rules_after[\"Total Rules\"] - rules_after[\"Total Rules Dropped\"]\n",
    "# )\n",
    "\n",
    "# # (optional) cast to int if these are counts\n",
    "# cols = [\"Total Rules\", \"Total Rules Dropped\", \"Rules After Dropping\"]\n",
    "# rules_after[cols] = rules_after[cols].astype(int)\n",
    "\n",
    "# print(rules_after[[\"Dataset\"] + cols])\n",
    "# Total number of clusters per dataset\n",
    "total_clusters = (\n",
    "    crm_cov_redundancy_exp_summary.groupby(\"Dataset\")[\"Number of Clusters\"]\n",
    "      .sum()\n",
    "      .reset_index(name=\"Total Clusters\")\n",
    ")\n",
    "print(total_clusters)\n",
    "\n",
    "# overall total across all datasets\n",
    "overall_total_clusters = int(crm_cov_redundancy_exp_summary[\"Number of Clusters\"].sum())\n",
    "print(f\"Overall total clusters across datasets: {overall_total_clusters}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c595db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join('5_analysis')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path_exp_summary = os.path.join(out_dir, 'redundancy_coverage_experiment_summary.csv')\n",
    "tex_path_exp_summary = os.path.join(out_dir, 'redundancy_coverage_experiment_summary.tex')\n",
    "crm_cov_redundancy_exp_summary.to_csv(csv_path_exp_summary, index=False)\n",
    "\n",
    "crm_cov_redundancy_exp_summary.to_latex(\n",
    "    tex_path_exp_summary,\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    longtable=True,\n",
    "    formatters={\n",
    "        \"Encoding\": fmt_detok,\n",
    "        \"Labeling\": fmt_detok\n",
    "    }\n",
    ")\n",
    "\n",
    "csv_path_summary = os.path.join(out_dir, 'redundancy_coverage_rule_summary.csv')\n",
    "tex_path_summary = os.path.join(out_dir, 'redundancy_coverage_rule_summary.tex')\n",
    "crm_cov_redundancy_summary.to_csv(csv_path_summary, index=False)\n",
    "\n",
    "crm_cov_redundancy_summary.to_latex(\n",
    "    tex_path_summary,\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    longtable=True,\n",
    "    formatters={\n",
    "        \"Encoding\": fmt_detok,\n",
    "        \"Labeling\": fmt_detok,\n",
    "        \"Rule\": fmt_detok,\n",
    "        \"max_jaccard\": lambda x: f\"{x:.3f}\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"✅ Saved redundancy_coverage_redundant_pairs.csv → {csv_path_exp_summary}\")\n",
    "print(f\"✅ Saved redundancy_coverage_rule_summary.csv → {csv_path_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef8757",
   "metadata": {},
   "source": [
    "### fix Labeling of all_rules_crm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helpers ---\n",
    "def _build_known_prefixes_from_fs(base_dir: str = \"3.2_binned_features\") -> set:\n",
    "    prefixes = set()\n",
    "    try:\n",
    "        for d in os.listdir(base_dir):\n",
    "            full = os.path.join(base_dir, d)\n",
    "            if os.path.isdir(full):\n",
    "                prefixes.add(str(d).strip().lower().replace(\" \", \"\"))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    for _name in (\"dt_comparison\", \"ripperk_comparison\", \"all_rules_crm\"):\n",
    "        _df = globals().get(_name)\n",
    "        if isinstance(_df, pd.DataFrame) and \"Dataset\" in _df.columns:\n",
    "            prefixes |= set(\n",
    "                _df[\"Dataset\"].astype(str).str.strip().str.lower()\n",
    "                  .str.replace(r\"\\s+\", \"\", regex=True).unique().tolist()\n",
    "            )\n",
    "    prefixes |= {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "    return {p for p in prefixes if p and p != \"nan\"}\n",
    "\n",
    "try:\n",
    "    KNOWN_PREFIXES\n",
    "except NameError:\n",
    "    KNOWN_PREFIXES = _build_known_prefixes_from_fs(\"3.2_binned_features\")\n",
    "\n",
    "def _strip_label_suffix(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.replace(r\"_features?$\", \"\", regex=True)\n",
    "\n",
    "# --- helpers ---\n",
    "import os, re\n",
    "\n",
    "def _build_known_prefixes_from_fs(base_dir: str = \"3.2_binned_features\") -> set:\n",
    "    prefixes = set()\n",
    "    try:\n",
    "        for d in os.listdir(base_dir):\n",
    "            full = os.path.join(base_dir, d)\n",
    "            if os.path.isdir(full):\n",
    "                prefixes.add(str(d).strip().lower().replace(\" \", \"\"))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    for _name in (\"dt_comparison\", \"ripperk_comparison\", \"all_rules_crm\"):\n",
    "        _df = globals().get(_name)\n",
    "        if isinstance(_df, pd.DataFrame) and \"Dataset\" in _df.columns:\n",
    "            prefixes |= set(\n",
    "                _df[\"Dataset\"].astype(str).str.strip().str.lower()\n",
    "                  .str.replace(r\"\\s+\", \"\", regex=True).unique().tolist()\n",
    "            )\n",
    "    prefixes |= {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "    return {p for p in prefixes if p and p != \"nan\"}\n",
    "\n",
    "try:\n",
    "    KNOWN_PREFIXES\n",
    "except NameError:\n",
    "    KNOWN_PREFIXES = _build_known_prefixes_from_fs(\"3.2_binned_features\")\n",
    "\n",
    "def _strip_label_suffix(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.replace(r\"_features?$\", \"\", regex=True)\n",
    "\n",
    "def _canon_label(name: str) -> str:\n",
    "    # Robust canonicalizer\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r'(_features?)$', '', s, flags=re.I)   # drop trailing \"_features\"\n",
    "    s = s.replace(' ', '_')\n",
    "\n",
    "    # strip known dataset prefixes repeatedly\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "            if s.startswith(p + \"_\"):\n",
    "                s = s[len(p) + 1:]\n",
    "                changed = True\n",
    "\n",
    "    # final mapping (contains-based; catches \"payload_pay36\", \"decl3\", etc.)\n",
    "    if \"decl\" in s:\n",
    "        return \"declare\"\n",
    "    if \"payload\" in s:\n",
    "        return \"payload\"\n",
    "    if \"mr\" in s:\n",
    "        return \"sequential\"\n",
    "    return s\n",
    "\n",
    "# --- normalize Labeling in all_rules_crm ---\n",
    "if \"Labeling\" in all_rules_crm.columns:\n",
    "    all_rules_crm = all_rules_crm.copy()\n",
    "    all_rules_crm[\"Labeling\"] = all_rules_crm[\"Labeling\"].map(_canon_label)\n",
    "    all_rules_crm[\"Labeling\"] = _strip_label_suffix(all_rules_crm[\"Labeling\"])\n",
    "else:\n",
    "    raise KeyError(\"all_rules_crm has no 'Labeling' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"Dataset\", \"Labeling\", \"Encoding\", \"Rule\"]\n",
    "\n",
    "def _harmonize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.rename(columns={\n",
    "        \"Feature Encoding\": \"Encoding\",\n",
    "        \"Feature encoding\": \"Encoding\",\n",
    "    }).copy()\n",
    "    # exact match, but trim stray whitespace to avoid false mismatches\n",
    "    for c in key_cols:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"Missing column '{c}' in dataframe\")\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "all_rules_norm = _harmonize_cols(all_rules_crm)\n",
    "\n",
    "all_rules_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c6ffc5",
   "metadata": {},
   "source": [
    "## 7. Calculating Coverage CRM rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb13620",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    exclude_encodings\n",
    "except NameError:\n",
    "    exclude_encodings = [\"mr\", \"mra\", \"tr\", \"tra\"]\n",
    "\n",
    "base_dir = \"3.2_binned_features\"  # root folder\n",
    "\n",
    "def _norm_enc(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.strip().str.lower()\n",
    "\n",
    "def _strip_label_suffix(s: pd.Series) -> pd.Series:\n",
    "    # drop trailing \"_features\" if present\n",
    "    return s.astype(str).str.replace(r\"_features$\", \"\", regex=True)\n",
    "\n",
    "# --- Canonicalize Labeling helpers ---\n",
    "def _build_known_prefixes_from_fs(base_dir: str) -> set:\n",
    "    prefixes = set()\n",
    "    # dataset folder names\n",
    "    try:\n",
    "        for d in os.listdir(base_dir):\n",
    "            full = os.path.join(base_dir, d)\n",
    "            if os.path.isdir(full):\n",
    "                prefixes.add(str(d).strip().lower().replace(\" \", \"\"))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # also take from any existing comparison frames if present\n",
    "    for _name in (\"dt_comparison\", \"ripperk_comparison\"):\n",
    "        _df = globals().get(_name)\n",
    "        if isinstance(_df, pd.DataFrame) and \"Dataset\" in _df.columns:\n",
    "            prefixes |= set(\n",
    "                _df[\"Dataset\"].astype(str).str.strip().str.lower()\n",
    "                   .str.replace(r\"\\s+\", \"\", regex=True).unique().tolist()\n",
    "            )\n",
    "    prefixes |= {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "    return {p for p in prefixes if p and p != \"nan\"}\n",
    "\n",
    "KNOWN_PREFIXES = _build_known_prefixes_from_fs(base_dir)\n",
    "\n",
    "def _canon_label(name: str) -> str:\n",
    "    s = str(name).strip().lower()\n",
    "    s = re.sub(r'(_features?)$', '', s)   # drop suffix\n",
    "    s = s.replace(' ', '_')\n",
    "    # strip dataset prefixes repeatedly (e.g., \"sepsis_\", \"bpi15a_\")\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "            if s.startswith(p + \"_\"):\n",
    "                s = s[len(p) + 1:]\n",
    "                changed = True\n",
    "    # family mapping\n",
    "    if re.search(r'\\bpayload(\\d+)?\\b', s):\n",
    "        return 'payload'\n",
    "    if re.fullmatch(r'(decl(are)?\\d*)', s):\n",
    "        return 'declare'\n",
    "    if re.search(r'(^|[^a-z])mr([^a-z]|$)', s):\n",
    "        return 'sequential'\n",
    "    return s\n",
    "\n",
    "# 1) Walk the directory tree and compute coverage per (Dataset, Labeling, Encoding)\n",
    "coverage_records = []\n",
    "for dataset in os.listdir(base_dir):\n",
    "    dataset_path = os.path.join(base_dir, dataset)\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        continue\n",
    "\n",
    "    for labeling in os.listdir(dataset_path):\n",
    "        labeling_path = os.path.join(dataset_path, labeling)\n",
    "        if not os.path.isdir(labeling_path):\n",
    "            continue\n",
    "\n",
    "        for encoding in os.listdir(labeling_path):\n",
    "            encoding_path = os.path.join(labeling_path, encoding)\n",
    "            if not os.path.isdir(encoding_path):\n",
    "                continue\n",
    "\n",
    "            # Skip excluded encodings (case-insensitive)\n",
    "            if _norm_enc(pd.Series([encoding])).iloc[0] in set(map(str.lower, exclude_encodings)):\n",
    "                continue\n",
    "\n",
    "            # Expect a single CSV file in this folder\n",
    "            csv_files = [f for f in os.listdir(encoding_path) if f.endswith(\".csv\")]\n",
    "            if not csv_files:\n",
    "                continue\n",
    "\n",
    "            csv_path = os.path.join(encoding_path, csv_files[0])\n",
    "            try:\n",
    "                df = pd.read_csv(csv_path)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if \"Label\" not in df.columns:\n",
    "                continue\n",
    "\n",
    "            # Make sure Label is numeric\n",
    "            df[\"Label\"] = pd.to_numeric(df[\"Label\"], errors=\"coerce\")\n",
    "\n",
    "            total = len(df)\n",
    "            num_normal  = int((df[\"Label\"] == 0).sum())\n",
    "            num_deviant = int((df[\"Label\"] == 1).sum())\n",
    "\n",
    "            if total == 0:\n",
    "                pct_normal = pct_deviant = 0.0\n",
    "            else:\n",
    "                pct_normal  = num_normal / total * 100.0\n",
    "                pct_deviant = num_deviant / total * 100.0\n",
    "\n",
    "            # Canonicalize labeling right here so downstream merges match\n",
    "            labeling_canon = _canon_label(labeling)\n",
    "\n",
    "            coverage_records.append({\n",
    "                \"Dataset\": dataset,\n",
    "                \"Labeling\": labeling_canon,\n",
    "                \"Encoding\": encoding,\n",
    "                \"#_normal\": num_normal,\n",
    "                \"#_deviant\": num_deviant,\n",
    "                \"%_normal\": pct_normal,\n",
    "                \"%_deviant\": pct_deviant\n",
    "            })\n",
    "\n",
    "crm_coverage = pd.DataFrame(coverage_records)\n",
    "\n",
    "# 2) Normalize columns\n",
    "if not crm_coverage.empty:\n",
    "    crm_coverage[\"Labeling\"] = _strip_label_suffix(crm_coverage[\"Labeling\"])\n",
    "    crm_coverage[\"%_normal\"]  = pd.to_numeric(crm_coverage[\"%_normal\"], errors=\"coerce\").round(2)\n",
    "    crm_coverage[\"%_deviant\"] = pd.to_numeric(crm_coverage[\"%_deviant\"], errors=\"coerce\").round(2)\n",
    "    crm_coverage[\"#_normal\"]  = pd.to_numeric(crm_coverage[\"#_normal\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    crm_coverage[\"#_deviant\"] = pd.to_numeric(crm_coverage[\"#_deviant\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 3) Compute CRM Rules from ALL rules\n",
    "key_cols = [\"Dataset\", \"Labeling\", \"Encoding\"]\n",
    "rule_key_cols = key_cols + [\"Rule\"]\n",
    "\n",
    "# --- Harmonize & canonicalize base rules (all_rules_crm) ---\n",
    "if 'all_rules_crm' in globals() and isinstance(all_rules_crm, pd.DataFrame) and 'Rule' in all_rules_crm.columns:\n",
    "    base = all_rules_crm.copy()\n",
    "\n",
    "    # Normalize column names\n",
    "    if 'Encoding' not in base.columns and 'Feature Encoding' in base.columns:\n",
    "        base = base.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "\n",
    "    # Canonicalize labeling\n",
    "    if 'Labeling' in base.columns:\n",
    "        base['Labeling'] = base['Labeling'].apply(_canon_label)\n",
    "        base['Labeling'] = _strip_label_suffix(base['Labeling'])\n",
    "\n",
    "    # Exclude encodings\n",
    "    if 'exclude_encodings' in globals():\n",
    "        base = base[_norm_enc(base['Encoding']).isin(set(map(str.lower, exclude_encodings))) == False]\n",
    "\n",
    "    # Count ALL unique rules per (Dataset, Labeling, Encoding)\n",
    "    cc_rules = (\n",
    "        base.groupby(key_cols, dropna=False)['Rule']\n",
    "            .nunique()\n",
    "            .reset_index(name='CRM Rules')\n",
    "    )\n",
    "else:\n",
    "    # Fallback: try existing comparison frames\n",
    "    cc_frames = []\n",
    "    for _name in (\"dt_comparison\", \"ripperk_comparison\"):\n",
    "        _df = globals().get(_name)\n",
    "        if isinstance(_df, pd.DataFrame) and all(c in _df.columns for c in key_cols + [\"CRM Rules\"]):\n",
    "            tmp = _df.loc[:, key_cols + [\"CRM Rules\"]].copy()\n",
    "            tmp[\"Labeling\"] = tmp[\"Labeling\"].apply(_canon_label)\n",
    "            tmp[\"Labeling\"] = _strip_label_suffix(tmp[\"Labeling\"])\n",
    "            if 'exclude_encodings' in globals():\n",
    "                tmp = tmp[_norm_enc(tmp[\"Encoding\"]).isin(set(map(str.lower, exclude_encodings))) == False]\n",
    "            cc_frames.append(tmp)\n",
    "    if cc_frames:\n",
    "        cc_rules = (\n",
    "            pd.concat(cc_frames, ignore_index=True)\n",
    "              .groupby(key_cols, as_index=False)[\"CRM Rules\"].max()\n",
    "        )\n",
    "    else:\n",
    "        cc_rules = pd.DataFrame(columns=key_cols + [\"CRM Rules\"])\n",
    "\n",
    "# 4) Merge CRM Rules into coverage (fill missing with 0)\n",
    "crm_coverage = crm_coverage.merge(cc_rules, on=key_cols, how=\"left\")\n",
    "crm_coverage[\"CRM Rules\"] = pd.to_numeric(crm_coverage[\"CRM Rules\"], errors=\"coerce\").fillna(0).astype(\"Int64\")\n",
    "\n",
    "# 5) Sort for readability\n",
    "if not crm_coverage.empty:\n",
    "    crm_coverage = crm_coverage.sort_values(key_cols).reset_index(drop=True)\n",
    "\n",
    "crm_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum CRM Rules\n",
    "sum_crm_rules = (\n",
    "    crm_coverage[\"CRM Rules\"]\n",
    "      .sum()\n",
    ")\n",
    "\n",
    "print(sum_crm_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Harmonize column names\n",
    "crm_df = all_rules_crm.copy()\n",
    "if 'Encoding' not in crm_df.columns and 'Feature Encoding' in crm_df.columns:\n",
    "    crm_df = crm_df.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "\n",
    "# Ensure numeric types we sort/filter on\n",
    "crm_df['LB odds ratio'] = pd.to_numeric(crm_df['LB odds ratio'], errors='coerce')\n",
    "if 'Confidence' in crm_df.columns:\n",
    "    crm_df['Confidence'] = pd.to_numeric(crm_df['Confidence'], errors='coerce')\n",
    "\n",
    "# --- Canonicalize Labeling (payload*→payload, decl/declare*→declare, mr*→sequential)\n",
    "def _build_known_prefixes(df_list):\n",
    "    prefixes = set()\n",
    "    for df in df_list:\n",
    "        if isinstance(df, pd.DataFrame) and 'Dataset' in df.columns:\n",
    "            s = pd.Series(df['Dataset']).astype(str).str.strip().str.lower()\n",
    "            prefixes.update(s.str.replace(r'\\s+', '', regex=True).unique().tolist())\n",
    "    prefixes |= {'sepsis', 'traffic', 'bpi15a', 'bpic15a', 'bpic2015', 'bpi2015', 'bpi15'}\n",
    "    return {p for p in prefixes if p and p != 'nan'}\n",
    "\n",
    "try:\n",
    "    KNOWN_PREFIXES  # reuse if already defined\n",
    "except NameError:\n",
    "    KNOWN_PREFIXES = _build_known_prefixes([crm_df])\n",
    "\n",
    "def _canon_label(lbl: str) -> str:\n",
    "    s = str(lbl).strip().lower()\n",
    "    s = re.sub(r'(_features?)$', '', s)   # drop _feature/_features if present\n",
    "    s = s.replace(' ', '_')\n",
    "    # strip dataset prefixes repeatedly\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "            if s.startswith(p + '_'):\n",
    "                s = s[len(p) + 1:]\n",
    "                changed = True\n",
    "    if re.search(r'\\bpayload(\\d+)?\\b', s):\n",
    "        return 'payload'\n",
    "    if re.fullmatch(r'(decl(are)?\\d*)', s):\n",
    "        return 'declare'\n",
    "    if re.search(r'(^|[^a-z])mr([^a-z]|$)', s):\n",
    "        return 'sequential'\n",
    "    return s\n",
    "\n",
    "if 'Labeling' in crm_df.columns:\n",
    "    crm_df['Labeling'] = crm_df['Labeling'].apply(_canon_label)\n",
    "\n",
    "# 2) Filter for LB odds ratio > 1\n",
    "crm_filtered = crm_df[crm_df['LB odds ratio'] > 1].copy()\n",
    "\n",
    "# 3) Sort & select top-5 per experiment\n",
    "crm_filtered = crm_filtered.sort_values(\n",
    "    by=['Dataset', 'Labeling', 'Encoding', 'LB odds ratio', 'Confidence'],\n",
    "    ascending=[True, True, True, False, False]\n",
    ")\n",
    "top5_rules_df = (\n",
    "    crm_filtered\n",
    "    .groupby(['Dataset', 'Labeling', 'Encoding'], group_keys=False)\n",
    "    .head(5)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 4) Exact LHS and RHS extraction (no processing of LHS)\n",
    "def extract_lhs_exact(rule_str: str) -> str:\n",
    "    s = str(rule_str)\n",
    "    m = re.search(r\"^(.*?)(?=\\s*-->)\", s)\n",
    "    return m.group(1) if m else s\n",
    "\n",
    "def parse_rhs_label(rule_str: str):\n",
    "    s = str(rule_str)\n",
    "    m = re.search(r\"-->\\s*(Label|!Label)\", s)\n",
    "    if not m:\n",
    "        return None\n",
    "    return 1 if m.group(1) == \"Label\" else 0\n",
    "\n",
    "top5_rules_df['LHS_features'] = top5_rules_df['Rule'].apply(extract_lhs_exact)\n",
    "top5_rules_df['RHS_label']    = top5_rules_df['Rule'].apply(parse_rhs_label)\n",
    "\n",
    "# 5) Final table\n",
    "top5_crm_rules_expanded = top5_rules_df[\n",
    "    ['Dataset', 'Labeling', 'Encoding', 'Rule', 'LHS_features', 'RHS_label', 'LB odds ratio']\n",
    "].reset_index(drop=True)\n",
    "\n",
    "top5_crm_rules_expanded.sort_values(\n",
    "    by=\"LB odds ratio\",\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78631e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helpers  ---\n",
    "\n",
    "def _find_outer_brackets_span(text: str):\n",
    "    \"\"\"Return (start_idx, end_idx) of the outermost [...] in `text`.\"\"\"\n",
    "    start = text.find('[')\n",
    "    if start < 0:\n",
    "        return None, None\n",
    "\n",
    "    depth = 0\n",
    "    in_s = in_d = esc = False\n",
    "    end = None\n",
    "    for i, ch in enumerate(text[start:], start):\n",
    "        if esc:\n",
    "            esc = False\n",
    "            continue\n",
    "        if ch == '\\\\':\n",
    "            esc = True\n",
    "            continue\n",
    "\n",
    "        if in_s:\n",
    "            if ch == \"'\":\n",
    "                in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            if ch == '\"':\n",
    "                in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\":\n",
    "            in_s = True\n",
    "            continue\n",
    "        if ch == '\"':\n",
    "            in_d = True\n",
    "            continue\n",
    "\n",
    "        if ch == '[':\n",
    "            depth += 1\n",
    "            continue\n",
    "        if ch == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                end = i\n",
    "                break\n",
    "    return (start, end)\n",
    "\n",
    "def _split_top_level_commas(content: str):\n",
    "    \"\"\"Split `content` on commas that are outside quotes.\"\"\"\n",
    "    parts, curr = [], \"\"\n",
    "    in_s = in_d = esc = False\n",
    "    for ch in content:\n",
    "        if esc:\n",
    "            curr += ch\n",
    "            esc = False\n",
    "            continue\n",
    "        if ch == '\\\\':\n",
    "            curr += ch\n",
    "            esc = True\n",
    "            continue\n",
    "\n",
    "        if in_s:\n",
    "            curr += ch\n",
    "            if ch == \"'\":\n",
    "                in_s = False\n",
    "            continue\n",
    "        if in_d:\n",
    "            curr += ch\n",
    "            if ch == '\"':\n",
    "                in_d = False\n",
    "            continue\n",
    "\n",
    "        if ch == \"'\":\n",
    "            curr += ch\n",
    "            in_s = True\n",
    "            continue\n",
    "        if ch == '\"':\n",
    "            curr += ch\n",
    "            in_d = True\n",
    "            continue\n",
    "\n",
    "        if ch == ',':\n",
    "            parts.append(curr.strip())\n",
    "            curr = \"\"\n",
    "        else:\n",
    "            curr += ch\n",
    "    parts.append(curr.strip())\n",
    "    return parts\n",
    "\n",
    "def _strip_one_layer_quotes(s: str):\n",
    "    s = s.strip()\n",
    "    if len(s) >= 2 and ((s[0] == s[-1] == \"'\") or (s[0] == s[-1] == '\"')):\n",
    "        return s[1:-1]\n",
    "    return s\n",
    "\n",
    "def split_lhs_items(lhs_text: str):\n",
    "    \"\"\"\n",
    "    lhs_text is exactly what's before '-->', e.g. \"['A', 'B', 'C']\" or \"['A']\".\n",
    "    Return a list like ['A','B','C'] (no outer quotes/brackets).\n",
    "    \"\"\"\n",
    "    if not isinstance(lhs_text, str):\n",
    "        return []\n",
    "    start, end = _find_outer_brackets_span(lhs_text)\n",
    "    if start is None or end is None:\n",
    "        return []\n",
    "\n",
    "    inner = lhs_text[start+1:end]  # content inside [...]\n",
    "    raw_items = _split_top_level_commas(inner)\n",
    "    # remove one layer of quotes from each item, keep everything else intact\n",
    "    return [_strip_one_layer_quotes(x).strip() for x in raw_items if x != \"\"]\n",
    "\n",
    "def _pad3(items):\n",
    "    items = items[:3]\n",
    "    return items + [\"\"] * (3 - len(items))\n",
    "\n",
    "# --- apply to dataframe ---\n",
    "\n",
    "# top5_crm_rules_expanded['LHS_features'] contains strings like \"['A', 'B']\"\n",
    "lhs_split_series = top5_crm_rules_expanded['LHS_features'].apply(split_lhs_items).apply(_pad3)\n",
    "lhs_df = pd.DataFrame(lhs_split_series.tolist(), columns=['feature_1_lhs','feature_2_lhs','feature_3_lhs'])\n",
    "\n",
    "top5_crm_rules_expanded = pd.concat([top5_crm_rules_expanded, lhs_df], axis=1)\n",
    "\n",
    "top5_crm_rules_expanded.sort_values(\n",
    "    by=\"LB odds ratio\",\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SUFFIX_RE = re.compile(r\"_(\\-?\\d+(?:\\.\\d+)?)$\")  # matches _1, _1.0, _0, _0.0, _-1, _-1.0 at the end\n",
    "\n",
    "LABEL_FOLDER_MAP = {\n",
    "    \"sepsis\": {\n",
    "        \"declare\":    \"sepsis_decl_features\",\n",
    "        \"sequential\": \"sepsis_mr_tr_features\",\n",
    "        \"payload\":    \"sepsis_payload2_features\",\n",
    "    },\n",
    "    \"BPI15A\": {\n",
    "        \"declare\":    \"BPI15A_decl2_features\",\n",
    "        \"sequential\": \"BPI15A_mr_tr_features\",\n",
    "        \"payload\":    \"BPI15A_payload_560925_features\",\n",
    "    },\n",
    "    \"traffic\": {\n",
    "        \"declare\":    \"traffic_decl3_features\",\n",
    "        \"sequential\": \"traffic_mr_tr_features\",\n",
    "        \"payload\":    \"traffic_payload_Pay36_features\",\n",
    "    },\n",
    "}\n",
    "\n",
    "base_dir = \"3.2_binned_features\"\n",
    "\n",
    "# --- matching helpers ---\n",
    "\n",
    "def _norm_numeric(col: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Normalize a column for reliable numeric comparisons:\n",
    "    - bool -> 0/1\n",
    "    - strings like '1','0','-1.0' -> numeric (where possible)\n",
    "    - if coercion yields all NaN and original is object, return original for string compares\n",
    "    \"\"\"\n",
    "    if col.dtype == bool:\n",
    "        return col.astype(int)\n",
    "    out = pd.to_numeric(col, errors='coerce')\n",
    "    if out.isna().all() and col.dtype == object:\n",
    "        return col  # keep as strings for string equality checks\n",
    "    return out\n",
    "\n",
    "def _infer_case_col(df: pd.DataFrame) -> str:\n",
    "    for c in [\"Case_ID\", \"case:concept:name\", \"Case ID\", \"case_id\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(\"No Case ID column found (tried: Case_ID, case:concept:name, Case ID, case_id)\")\n",
    "\n",
    "def _match_single_feature(df: pd.DataFrame, feat: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return a boolean mask of rows matching a *single* LHS feature.\n",
    "\n",
    "    Cases handled:\n",
    "      1) Exact one-hot column: feat equals a column name -> column == 1\n",
    "      2) Binned value: base_col_(...) or base_col_[...] -> df[base_col] == \"(...]\" or \"[...]\"\n",
    "      3) Suffix _0/_1: base column exists with 0/1 value\n",
    "    Fallback -> no rows match.\n",
    "    \"\"\"\n",
    "    # 1) Exact column match (treat as one-hot)\n",
    "    if feat in df.columns:\n",
    "        col = _norm_numeric(df[feat])\n",
    "        return (col == 1) if pd.api.types.is_numeric_dtype(col) else (col.astype(str) == \"1\")\n",
    "\n",
    "    # 2) Binned pattern: split at last \"_(\" or \"_[\"\n",
    "    pos1 = feat.rfind(\"_(\")\n",
    "    pos2 = feat.rfind(\"_[\")\n",
    "    split_pos = max(pos1, pos2)\n",
    "    if split_pos != -1:\n",
    "        base_col = feat[:split_pos]\n",
    "        bin_val  = feat[split_pos+1:]  # drop the underscore before bracket\n",
    "        if base_col in df.columns:\n",
    "            return (df[base_col].astype(str) == bin_val)\n",
    "\n",
    "    # 3) General numeric suffix: ..._<number> at the END (e.g., _1.0, _0, _-1.0)\n",
    "    m = NUM_SUFFIX_RE.search(feat)\n",
    "    if m:\n",
    "        base_col = feat[:m.start()]\n",
    "        desired_str = m.group(1)        # e.g., \"1.0\", \"0\", \"-1.0\"\n",
    "        desired = float(desired_str)    # numeric compare works for 1 vs 1.0, -1 vs -1.0\n",
    "\n",
    "        # Case: base column exists -> compare its value to the numeric suffix\n",
    "        if base_col in df.columns:\n",
    "            col = _norm_numeric(df[base_col])\n",
    "            if pd.api.types.is_numeric_dtype(col):\n",
    "                mask = (col == desired)\n",
    "            else:\n",
    "                # fallback to string comparison if column is non-numeric\n",
    "                mask = (col.astype(str) == desired_str)\n",
    "            return mask.fillna(False)\n",
    "\n",
    "        # Rare fallback: indicator column named with the full suffix exists\n",
    "        # Treat as one-hot (==1)\n",
    "        if feat in df.columns:\n",
    "            col = _norm_numeric(df[feat])\n",
    "            if pd.api.types.is_numeric_dtype(col):\n",
    "                mask = (col == 1)\n",
    "            else:\n",
    "                mask = (col.astype(str) == \"1\")\n",
    "            return mask.fillna(False)\n",
    "\n",
    "    # No match strategy -> False\n",
    "    return pd.Series(False, index=df.index)\n",
    "\n",
    "def _match_rule(df: pd.DataFrame, features: list, rhs_label: int) -> pd.Series:\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    for f in features:\n",
    "        if f:  # skip empty slots\n",
    "            mask &= _match_single_feature(df, f)\n",
    "            if not mask.any():\n",
    "                break\n",
    "    if rhs_label in (0, 1):\n",
    "        mask &= (pd.to_numeric(df[\"Label\"], errors=\"coerce\") == rhs_label)\n",
    "    else:\n",
    "        mask &= False\n",
    "    return mask\n",
    "\n",
    "# --- helper: map free-form labeling -> {'declare','sequential','payload'} ---\n",
    "def _label_category(labeling: str) -> str | None:\n",
    "    s = str(labeling).lower().strip()\n",
    "    if \"mr_tr\" in s or \"mrtr\" in s or s.startswith(\"seq\") or \"sequen\" in s:\n",
    "        return \"sequential\"\n",
    "    if s.startswith(\"decl\") or \"declare\" in s:\n",
    "        return \"declare\"\n",
    "    if \"payload\" in s:\n",
    "        return \"payload\"\n",
    "    if s in {\"declare\",\"sequential\",\"payload\"}:\n",
    "        return s\n",
    "    return None\n",
    "\n",
    "# --- helper: find full path using explicit per-dataset mapping with light fallbacks ---\n",
    "def find_encoding_path(base_dir: str, dataset: str, labeling: str, encoding: str):\n",
    "    cat = _label_category(labeling)\n",
    "    # 1) explicit mapping\n",
    "    folder = LABEL_FOLDER_MAP.get(dataset, {}).get(cat, None)\n",
    "    if folder:\n",
    "        path = os.path.join(base_dir, dataset, folder, encoding)\n",
    "        if os.path.isdir(path):\n",
    "            return path\n",
    "    # 2) common literal fallbacks\n",
    "    dataset_dir = os.path.join(base_dir, dataset)\n",
    "    candidates = []\n",
    "    if cat:\n",
    "        candidates += [f\"{dataset}_{cat}_features\", f\"{cat}_features\"]\n",
    "    candidates += [f\"{dataset}_{labeling}_features\", f\"{labeling}_features\"]\n",
    "    for lf in candidates:\n",
    "        lf_path = os.path.join(dataset_dir, lf)\n",
    "        if os.path.isdir(lf_path):\n",
    "            enc_path = os.path.join(lf_path, encoding)\n",
    "            if os.path.isdir(enc_path):\n",
    "                return enc_path\n",
    "    return None\n",
    "\n",
    "# ---------- PASS 1: per-rule covered cases ----------\n",
    "# Ensure output columns exist\n",
    "if \"covered_case_ids\" not in top5_crm_rules_expanded.columns:\n",
    "    top5_crm_rules_expanded[\"covered_case_ids\"] = [[] for _ in range(len(top5_crm_rules_expanded))]\n",
    "if \"n_covered_cases\" not in top5_crm_rules_expanded.columns:\n",
    "    top5_crm_rules_expanded[\"n_covered_cases\"] = 0\n",
    "\n",
    "for (dataset, labeling, encoding), rules_df in top5_crm_rules_expanded.groupby([\"Dataset\", \"Labeling\", \"Encoding\"]):\n",
    "    enc_path = find_encoding_path(base_dir, dataset, labeling, encoding)\n",
    "    if enc_path is None:\n",
    "        continue\n",
    "\n",
    "    csv_files = [f for f in os.listdir(enc_path) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        continue\n",
    "    csv_path = os.path.join(enc_path, csv_files[0])\n",
    "\n",
    "    df_enc = pd.read_csv(csv_path)\n",
    "    if \"Label\" not in df_enc.columns:\n",
    "        raise KeyError(f\"No 'Label' column found in: {csv_path}\")\n",
    "    case_col = _infer_case_col(df_enc)\n",
    "\n",
    "    for idx, row in rules_df.iterrows():\n",
    "        feats = [row.get(\"feature_1_lhs\",\"\"), row.get(\"feature_2_lhs\",\"\"), row.get(\"feature_3_lhs\",\"\")]\n",
    "        feats = [f for f in feats if isinstance(f, str) and f.strip() != \"\"]\n",
    "        rhs   = row[\"RHS_label\"]\n",
    "\n",
    "        rule_mask = _match_rule(df_enc, feats, rhs)\n",
    "        case_ids = df_enc.loc[rule_mask, case_col].dropna().astype(str).unique().tolist()\n",
    "\n",
    "        top5_crm_rules_expanded.at[idx, \"covered_case_ids\"] = case_ids\n",
    "        top5_crm_rules_expanded.at[idx, \"n_covered_cases\"]  = len(case_ids)\n",
    "\n",
    "# ---------- PASS 2: percentage of class covered ----------\n",
    "if \"pct_of_class_covered\" not in top5_crm_rules_expanded.columns:\n",
    "    top5_crm_rules_expanded[\"pct_of_class_covered\"] = 0.0\n",
    "\n",
    "for (dataset, labeling, encoding), rules_df in top5_crm_rules_expanded.groupby([\"Dataset\", \"Labeling\", \"Encoding\"]):\n",
    "    enc_path = find_encoding_path(base_dir, dataset, labeling, encoding)\n",
    "    if enc_path is None:\n",
    "        continue\n",
    "\n",
    "    csv_files = [f for f in os.listdir(enc_path) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        continue\n",
    "    csv_path = os.path.join(enc_path, csv_files[0])\n",
    "\n",
    "    df_enc = pd.read_csv(csv_path)\n",
    "    if \"Label\" not in df_enc.columns:\n",
    "        raise KeyError(f\"No 'Label' column found in: {csv_path}\")\n",
    "\n",
    "    labels_num = pd.to_numeric(df_enc[\"Label\"], errors=\"coerce\")\n",
    "    total_normal  = int((labels_num == 0).sum())\n",
    "    total_deviant = int((labels_num == 1).sum())\n",
    "\n",
    "    case_col = _infer_case_col(df_enc)\n",
    "\n",
    "    for idx, row in rules_df.iterrows():\n",
    "        feats = [row.get(\"feature_1_lhs\",\"\"), row.get(\"feature_2_lhs\",\"\"), row.get(\"feature_3_lhs\",\"\")]\n",
    "        feats = [f for f in feats if isinstance(f, str) and f.strip() != \"\"]\n",
    "        rhs   = row[\"RHS_label\"]\n",
    "\n",
    "        rule_mask = _match_rule(df_enc, feats, rhs)\n",
    "        case_ids = df_enc.loc[rule_mask, case_col].dropna().astype(str).unique().tolist()\n",
    "\n",
    "        top5_crm_rules_expanded.at[idx, \"covered_case_ids\"] = case_ids\n",
    "        top5_crm_rules_expanded.at[idx, \"n_covered_cases\"]  = len(case_ids)\n",
    "\n",
    "        denom = total_deviant if rhs == 1 else total_normal\n",
    "        pct = (len(case_ids) / denom * 100.0) if denom > 0 else 0.0\n",
    "        top5_crm_rules_expanded.at[idx, \"pct_of_class_covered\"] = round(pct, 2)\n",
    "\n",
    "top5_crm_rules_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build the export frame ---\n",
    "required_cols = ['Dataset', 'Labeling', 'Encoding', 'Rule', 'LB odds ratio', 'pct_of_class_covered']\n",
    "missing = [c for c in required_cols if c not in top5_crm_rules_expanded.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"top5_crm_rules_expanded is missing columns: {missing}\")\n",
    "\n",
    "export_df = top5_crm_rules_expanded[required_cols].copy()\n",
    "\n",
    "# --- Output paths ---\n",
    "out_dir = os.path.join('5_analysis')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(out_dir, 'top5_rule_coverage.csv')\n",
    "tex_path = os.path.join(out_dir, 'top5_rule_coverage.tex')\n",
    "\n",
    "# --- Save CSV (raw values) ---\n",
    "export_df.to_csv(csv_path, index=False)\n",
    "\n",
    "export_df.to_latex(\n",
    "    tex_path,\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    longtable=True,\n",
    "    formatters={\n",
    "        \"Encoding\": fmt_detok,\n",
    "        \"Rule\": fmt_detok,\n",
    "        \"pct_of_class_covered\": lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\",\n",
    "        \"LB odds ratio\": lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ Saved top5_rule_coverage.csv → {csv_path}\")\n",
    "print(f\"✅ Saved top5_rule_coverage.tex → {tex_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Top-5 union coverage per experiment (normal vs deviant) ---\n",
    "\n",
    "# 1) Build union of covered cases per class for each (Dataset, Labeling, Encoding)\n",
    "try:\n",
    "    LABEL_FOLDER_MAP\n",
    "except NameError:\n",
    "    LABEL_FOLDER_MAP = {\"mr_tr\":\"sequential\", \"decl\":\"declare\", \"payload\":\"payload\"}\n",
    "\n",
    "def _strip_dataset_prefix(label: str, dataset: str) -> str:\n",
    "    if not isinstance(label, str) or not isinstance(dataset, str):\n",
    "        return label\n",
    "    pref = f\"{dataset}_\"\n",
    "    return label[len(pref):] if label.lower().startswith(pref.lower()) else label\n",
    "\n",
    "def _label_key(label: str, dataset: str) -> str:\n",
    "    \"\"\"Normalize a labeling to the folder key used for joining.\"\"\"\n",
    "    if not isinstance(label, str):\n",
    "        return label\n",
    "    s = label.strip()\n",
    "    s = re.sub(r\"_features$\", \"\", s, flags=re.I)   # drop trailing _features\n",
    "    s = _strip_dataset_prefix(s, dataset)          # drop leading '<dataset>_'\n",
    "    key = s.lower().replace(\" \", \"\")\n",
    "    # dataset-specific mapping has priority\n",
    "    if isinstance(LABEL_FOLDER_MAP.get(dataset), dict):\n",
    "        return LABEL_FOLDER_MAP[dataset].get(key, key)\n",
    "    return LABEL_FOLDER_MAP.get(key, key)\n",
    "\n",
    "# --- Top-5 union coverage per experiment (normal vs deviant) ---\n",
    "\n",
    "# 1) Build union of covered cases per class for each (Dataset, Labeling, Encoding)\n",
    "union_rows = []\n",
    "\n",
    "for (ds, lab, enc), g in top5_crm_rules_expanded.groupby([\"Dataset\", \"Labeling\", \"Encoding\"]):\n",
    "    # Resolve path exactly like earlier code\n",
    "    enc_path = find_encoding_path(base_dir, ds, lab, enc)\n",
    "    if enc_path is None:\n",
    "        # couldn't resolve; skip this (Dataset, Labeling, Encoding)\n",
    "        continue\n",
    "\n",
    "    # Load the encoded CSV used for this experiment\n",
    "    csv_files = [f for f in os.listdir(enc_path) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        continue\n",
    "    csv_path = os.path.join(enc_path, csv_files[0])\n",
    "    df_enc = pd.read_csv(csv_path)\n",
    "\n",
    "    if \"Label\" not in df_enc.columns:\n",
    "        raise KeyError(f\"No 'Label' column found in: {csv_path}\")\n",
    "\n",
    "    # Denominators from the same file (consistent with earlier passes)\n",
    "    labels_num = pd.to_numeric(df_enc[\"Label\"], errors=\"coerce\")\n",
    "    total_normal  = int((labels_num == 0).sum())\n",
    "    total_deviant = int((labels_num == 1).sum())\n",
    "\n",
    "    # Case ID column detection\n",
    "    case_col = _infer_case_col(df_enc)\n",
    "\n",
    "    # Build unions by recomputing coverage with the matcher\n",
    "    normal_union  = set()\n",
    "    deviant_union = set()\n",
    "\n",
    "    for _, r in g.iterrows():\n",
    "        feats = [r.get(\"feature_1_lhs\",\"\"), r.get(\"feature_2_lhs\",\"\"), r.get(\"feature_3_lhs\",\"\")]\n",
    "        feats = [f for f in feats if isinstance(f, str) and f.strip() != \"\"]\n",
    "        rhs   = r.get(\"RHS_label\", None)\n",
    "\n",
    "        rule_mask = _match_rule(df_enc, feats, rhs)\n",
    "        case_ids = df_enc.loc[rule_mask, case_col].dropna().astype(str).tolist()\n",
    "\n",
    "        if rhs == 0:\n",
    "            normal_union.update(case_ids)\n",
    "        elif rhs == 1:\n",
    "            deviant_union.update(case_ids)\n",
    "\n",
    "    # Row for this experiment\n",
    "    n_normal_union  = len(normal_union)\n",
    "    n_deviant_union = len(deviant_union)\n",
    "\n",
    "    union_rows.append({\n",
    "        \"Dataset\": ds,\n",
    "        \"Labeling\": lab,\n",
    "        \"Encoding\": enc,\n",
    "        \"#_normal\": total_normal,\n",
    "        \"#_deviant\": total_deviant,\n",
    "        \"top5_cov_normal_n\":  n_normal_union,\n",
    "        \"top5_cov_deviant_n\": n_deviant_union,\n",
    "        \"top5_cov_normal_pct\":  round((n_normal_union  / total_normal)  * 100.0, 2) if total_normal  > 0 else 0.0,\n",
    "        \"top5_cov_deviant_pct\": round((n_deviant_union / total_deviant) * 100.0, 2) if total_deviant > 0 else 0.0,\n",
    "    })\n",
    "\n",
    "crm_top5_union_coverage = pd.DataFrame(union_rows)\n",
    "\n",
    "try:\n",
    "    crm_coverage = crm_coverage.merge(\n",
    "        crm_top5_union_coverage[[\"Dataset\", \"Labeling\", \"Encoding\",\n",
    "                                 \"top5_cov_normal_pct\", \"top5_cov_deviant_pct\"]],\n",
    "        on=[\"Dataset\", \"Labeling\", \"Encoding\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "crm_top5_union_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b542ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Final coverage + top-5 composition per experiment (robust join) ----------\n",
    "\n",
    "# Safety checks\n",
    "if 'crm_top5_union_coverage' not in globals():\n",
    "    raise RuntimeError(\"crm_top5_union_coverage not found. Run the union-coverage step first.\")\n",
    "if 'top5_crm_rules_expanded' not in globals():\n",
    "    raise RuntimeError(\"top5_crm_rules_expanded not found. Run the top-5 extraction step first.\")\n",
    "\n",
    "def _strip_dataset_prefix(label: str, dataset: str) -> str:\n",
    "    if not isinstance(label, str) or not isinstance(dataset, str):\n",
    "        return str(label)\n",
    "    pref = f\"{dataset}_\"\n",
    "    s = label\n",
    "    if s.lower().startswith(pref.lower()):\n",
    "        s = s[len(pref):]\n",
    "    return s\n",
    "\n",
    "def _normalize_label_for_join(label: str, dataset: str) -> str:\n",
    "    \"\"\"Normalize labeling to a stable category key for joining.\"\"\"\n",
    "    s = str(label).strip()\n",
    "    s = re.sub(r\"_features$\", \"\", s, flags=re.I)\n",
    "    s = _strip_dataset_prefix(s, dataset)\n",
    "    s_low = s.lower()\n",
    "\n",
    "    # same categorization as earlier\n",
    "    if (\"mr_tr\" in s_low) or (\"mrtr\" in s_low) or s_low.startswith(\"seq\") or (\"sequen\" in s_low):\n",
    "        return \"sequential\"\n",
    "    if s_low.startswith(\"decl\") or (\"declare\" in s_low):\n",
    "        return \"declare\"\n",
    "    if \"payload\" in s_low:\n",
    "        return \"payload\"\n",
    "    # fallback: return cleaned token\n",
    "    return s_low.replace(\" \", \"\")\n",
    "\n",
    "# 1) Start from the union-coverage table (computed with find_encoding_path + _match_rule)\n",
    "need_cols = ['Dataset', 'Labeling', 'Encoding', 'top5_cov_normal_pct', 'top5_cov_deviant_pct']\n",
    "missing = [c for c in need_cols if c not in crm_top5_union_coverage.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"crm_top5_union_coverage is missing columns: {missing}\")\n",
    "\n",
    "final_df = crm_top5_union_coverage[need_cols].copy()\n",
    "\n",
    "# Build a normalized join key\n",
    "final_df[\"LabelKey\"] = final_df.apply(lambda r: _normalize_label_for_join(r[\"Labeling\"], r[\"Dataset\"]), axis=1)\n",
    "\n",
    "# 2) Count how many of the top-5 rules per (Dataset, Labeling, Encoding) target deviant vs normal\n",
    "top5_tmp = top5_crm_rules_expanded.copy()\n",
    "top5_tmp[\"LabelKey\"] = top5_tmp.apply(lambda r: _normalize_label_for_join(r[\"Labeling\"], r[\"Dataset\"]), axis=1)\n",
    "\n",
    "top5_counts = (\n",
    "    top5_tmp\n",
    "    .groupby(['Dataset', 'Encoding', 'LabelKey'], as_index=False)\n",
    "    .agg(\n",
    "        top5_rules_deviant=('RHS_label', lambda s: int((s == 1).sum())),\n",
    "        top5_rules_normal =('RHS_label', lambda s: int((s == 0).sum())),\n",
    "        top5_rules_total  =('RHS_label', 'size')\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3) Merge counts into coverage percentages on the robust key\n",
    "final_df = final_df.merge(\n",
    "    top5_counts[['Dataset','Encoding','LabelKey','top5_rules_deviant','top5_rules_normal']],\n",
    "    on=['Dataset','Encoding','LabelKey'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 4) Fill missing with zeros and set integer dtype; also replace Labeling with the normalized category\n",
    "for c in ['top5_rules_deviant','top5_rules_normal']:\n",
    "    if c in final_df.columns:\n",
    "        final_df[c] = pd.to_numeric(final_df[c], errors='coerce').fillna(0).astype('Int64')\n",
    "\n",
    "# Use the normalized category as the reporting label\n",
    "final_df[\"Labeling\"] = final_df[\"LabelKey\"]\n",
    "final_df = final_df.drop(columns=[\"LabelKey\"])\n",
    "\n",
    "# 5) Pretty names + ordering\n",
    "rename_map = {\n",
    "    'top5_cov_normal_pct': 'Top5 !Z Coverage',\n",
    "    'top5_cov_deviant_pct': 'Top5 Z Coverage',\n",
    "    'top5_rules_deviant':  'Top5 Z Rules',\n",
    "    'top5_rules_normal':   'Top5 !Z Rules',\n",
    "}\n",
    "final_pretty = final_df.rename(columns=rename_map)\n",
    "\n",
    "desired_order = [\n",
    "    'Dataset', 'Labeling', 'Encoding',\n",
    "    'Top5 Z Rules', 'Top5 Z Coverage',\n",
    "    'Top5 !Z Rules', 'Top5 !Z Coverage'\n",
    "]\n",
    "final_pretty = (\n",
    "    final_pretty[[c for c in desired_order if c in final_pretty.columns]]\n",
    "    if (set(desired_order) - set(final_pretty.columns))\n",
    "    else final_pretty[desired_order]\n",
    ")\n",
    "\n",
    "# 6) Sort for readability and expose as coverage_crm\n",
    "coverage_crm = final_pretty.sort_values(['Dataset','Labeling','Encoding']).reset_index(drop=True)\n",
    "\n",
    "coverage_crm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join('5_analysis')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path_coverage_crm = os.path.join(out_dir, 'coverage_crm_summary.csv')\n",
    "tex_path_coverage_crm = os.path.join(out_dir, 'coverage_crm_summary.tex')\n",
    "coverage_crm.to_csv(csv_path_coverage_crm, index=False)\n",
    "\n",
    "coverage_crm.to_latex(\n",
    "    tex_path_coverage_crm,\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    longtable=True,\n",
    "    formatters={\n",
    "        \"Encoding\": fmt_detok,\n",
    "        \"Labeling\": fmt_detok,\n",
    "        \"Top5 Z Coverage\":    lambda x: f\"{x:.2f}%\",\n",
    "        \"Top5 !Z Coverage\":   lambda x: f\"{x:.2f}%\",\n",
    "        \"Top5 Z Coverage\":    fmt_detok,\n",
    "        \"Top5 !Z Coverage\":   fmt_detok\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ Saved coverage_crm_summary.csv → {csv_path_coverage_crm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb231fb",
   "metadata": {},
   "source": [
    "## 80% coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b414b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Minimal rule set to reach target coverage (greedy set cover) ---\n",
    "\n",
    "TARGET_COVERAGE = 0.80  # 80% threshold\n",
    "MODES = (\"overall\", \"pos\", \"neg\")  # overall = all cases, pos = RHS=1, neg = RHS=0\n",
    "\n",
    "# Sanity checks\n",
    "needed_cols = {\"Dataset\",\"Labeling\",\"Encoding\",\"RHS_label\",\"covered_case_ids\"}\n",
    "missing = needed_cols - set(top5_crm_rules_expanded.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"top5_crm_rules_expanded is missing columns: {missing}. \"\n",
    "                     f\"Run your pass that computes 'covered_case_ids' first.\")\n",
    "\n",
    "def _tie_break_score(row):\n",
    "    \"\"\"\n",
    "    Higher is better. Used when two rules add the same # of new cases.\n",
    "    Prefers LB odds ratio, then Precision, then Recall if present.\n",
    "    \"\"\"\n",
    "    def _g(col): \n",
    "        return float(row[col]) if col in row and pd.notna(row[col]) else float(\"-inf\")\n",
    "    return (_g(\"LB odds ratio\"), _g(\"Precision\"), _g(\"Recall\"))\n",
    "\n",
    "def _greedy_cover_for_mode(rules_subset_df, target_case_ids, prefer_cols=True):\n",
    "    \"\"\"\n",
    "    Greedy set cover:\n",
    "    - rules_subset_df must have index (carry it through to reference selected rows)\n",
    "    - 'covered_case_ids' column contains list of case ids per rule\n",
    "    - target_case_ids: set of case ids we aim to cover\n",
    "    Returns dict with selection and coverage stats.\n",
    "    \"\"\"\n",
    "    target = set(map(str, target_case_ids))\n",
    "    if not target:\n",
    "        return {\n",
    "            \"selected_rule_indices\": [],\n",
    "            \"selected_rules_step_gain\": [],\n",
    "            \"covered_cases\": set(),\n",
    "            \"coverage_frac\": 0.0,\n",
    "            \"achievable_frac\": 0.0,\n",
    "        }\n",
    "\n",
    "    # Precompute each rule's case set (as strings)\n",
    "    rule_cases = {}\n",
    "    for idx, row in rules_subset_df.iterrows():\n",
    "        rule_cases[idx] = set(map(str, row.get(\"covered_case_ids\", []) or []))\n",
    "\n",
    "    # Upper bound (achievable) coverage if we use all rules\n",
    "    achievable = set().union(*rule_cases.values()) if rule_cases else set()\n",
    "    achievable_on_target = achievable & target\n",
    "    achievable_frac = len(achievable_on_target) / len(target)\n",
    "\n",
    "    selected = []\n",
    "    step_gain = []\n",
    "    covered = set()\n",
    "\n",
    "    # Working pool of candidates\n",
    "    remaining = set(rule_cases.keys())\n",
    "\n",
    "    while len(covered) / len(target) < TARGET_COVERAGE and remaining:\n",
    "        # Pick rule with max marginal gain; break ties by _tie_break_score\n",
    "        best_idx = None\n",
    "        best_gain = -1\n",
    "        best_score = tuple()\n",
    "\n",
    "        for idx in remaining:\n",
    "            new_gain = len((rule_cases[idx] & target) - covered)\n",
    "            if new_gain > best_gain:\n",
    "                best_idx = idx\n",
    "                best_gain = new_gain\n",
    "                best_score = _tie_break_score(rules_subset_df.loc[idx])\n",
    "            elif new_gain == best_gain and best_gain > 0:\n",
    "                # Tie-break on quality metrics\n",
    "                score = _tie_break_score(rules_subset_df.loc[idx])\n",
    "                if score > best_score:\n",
    "                    best_idx = idx\n",
    "                    best_score = score\n",
    "\n",
    "        # No rule adds anything new -> stop\n",
    "        if best_idx is None or best_gain <= 0:\n",
    "            break\n",
    "\n",
    "        selected.append(best_idx)\n",
    "        step_gain.append(best_gain)\n",
    "        covered |= (rule_cases[best_idx] & target)\n",
    "        remaining.remove(best_idx)\n",
    "\n",
    "    coverage_frac = len(covered) / len(target)\n",
    "\n",
    "    return {\n",
    "        \"selected_rule_indices\": selected,\n",
    "        \"selected_rules_step_gain\": step_gain,\n",
    "        \"covered_cases\": covered,\n",
    "        \"coverage_frac\": coverage_frac,\n",
    "        \"achievable_frac\": achievable_frac,\n",
    "    }\n",
    "\n",
    "# Containers for outputs\n",
    "min_cover_rows = []\n",
    "# Optional markers on the original DF\n",
    "for col in [\"in_min_cover_overall\",\"in_min_cover_pos\",\"in_min_cover_neg\"]:\n",
    "    top5_crm_rules_expanded[col] = False\n",
    "\n",
    "# Iterate per experiment\n",
    "for (dataset, labeling, encoding), rules_df in top5_crm_rules_expanded.groupby([\"Dataset\",\"Labeling\",\"Encoding\"]):\n",
    "    # Load the encoding CSV once to get the universe of cases + per-class targets\n",
    "    enc_path = find_encoding_path(base_dir, dataset, labeling, encoding)\n",
    "    if enc_path is None:\n",
    "        min_cover_rows.append({\n",
    "            \"Dataset\": dataset, \"Labeling\": labeling, \"Encoding\": encoding,\n",
    "            \"Mode\": \"overall\", \"Threshold\": TARGET_COVERAGE,\n",
    "            \"Selected Rules\": 0, \"Coverage (%)\": 0.0, \"Achievable (%)\": 0.0,\n",
    "            \"Covered / Total\": \"0 / 0\", \"Selected Indexes\": [],\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    csv_files = [f for f in os.listdir(enc_path) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        continue\n",
    "    df_enc = pd.read_csv(os.path.join(enc_path, csv_files[0]))\n",
    "    case_col = _infer_case_col(df_enc)\n",
    "\n",
    "    # Targets\n",
    "    total_cases_all = set(df_enc[case_col].dropna().astype(str).unique().tolist())\n",
    "    labels_num = pd.to_numeric(df_enc[\"Label\"], errors=\"coerce\").fillna(-999).astype(int)\n",
    "    total_cases_pos = set(df_enc.loc[labels_num==1, case_col].dropna().astype(str).unique().tolist())\n",
    "    total_cases_neg = set(df_enc.loc[labels_num==0, case_col].dropna().astype(str).unique().tolist())\n",
    "\n",
    "    # Modes: overall / pos / neg\n",
    "    for mode in MODES:\n",
    "        if mode == \"overall\":\n",
    "            sub = rules_df\n",
    "            target = total_cases_all\n",
    "        elif mode == \"pos\":\n",
    "            sub = rules_df[rules_df[\"RHS_label\"] == 1]\n",
    "            target = total_cases_pos\n",
    "        else:  # \"neg\"\n",
    "            sub = rules_df[rules_df[\"RHS_label\"] == 0]\n",
    "            target = total_cases_neg\n",
    "\n",
    "        if sub.empty:\n",
    "            min_cover_rows.append({\n",
    "                \"Dataset\": dataset, \"Labeling\": labeling, \"Encoding\": encoding,\n",
    "                \"Mode\": mode, \"Threshold\": TARGET_COVERAGE,\n",
    "                \"Selected Rules\": 0, \"Coverage (%)\": 0.0, \"Achievable (%)\": 0.0,\n",
    "                \"Covered / Total\": f\"0 / {len(target)}\", \"Selected Indexes\": [],\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        res = _greedy_cover_for_mode(sub, target)\n",
    "        selected = res[\"selected_rule_indices\"]\n",
    "        coverage = res[\"coverage_frac\"]\n",
    "        achievable = res[\"achievable_frac\"]\n",
    "\n",
    "        # Mark selections on the original DF\n",
    "        mark_col = {\n",
    "            \"overall\": \"in_min_cover_overall\",\n",
    "            \"pos\": \"in_min_cover_pos\",\n",
    "            \"neg\": \"in_min_cover_neg\",\n",
    "        }[mode]\n",
    "        top5_crm_rules_expanded.loc[selected, mark_col] = True\n",
    "\n",
    "        min_cover_rows.append({\n",
    "            \"Dataset\": dataset,\n",
    "            \"Labeling\": labeling,\n",
    "            \"Encoding\": encoding,\n",
    "            \"Mode\": mode,\n",
    "            \"Threshold\": TARGET_COVERAGE,\n",
    "            \"Selected Rules\": len(selected),\n",
    "            \"Coverage (%)\": round(coverage*100, 2),\n",
    "            \"Achievable (%)\": round(achievable*100, 2),\n",
    "            \"Covered / Total\": f\"{len(res['covered_cases'])} / {len(target)}\",\n",
    "            \"Selected Indexes\": selected,\n",
    "        })\n",
    "\n",
    "# Summary DataFrame with one row per (experiment, mode)\n",
    "min_cover_summary = pd.DataFrame(min_cover_rows).sort_values(\n",
    "    [\"Dataset\",\"Labeling\",\"Encoding\",\"Mode\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Nice view of the actually selected rules per experiment/mode\n",
    "def selected_rules_view(df_rules, summary_row):\n",
    "    \"\"\"\n",
    "    Return a small DataFrame showing the selected rules for a summary row.\n",
    "    \"\"\"\n",
    "    dataset, labeling, encoding = summary_row[\"Dataset\"], summary_row[\"Labeling\"], summary_row[\"Encoding\"]\n",
    "    mode = summary_row[\"Mode\"]\n",
    "    selected = summary_row[\"Selected Indexes\"]\n",
    "\n",
    "    sub = df_rules[\n",
    "        (df_rules[\"Dataset\"]==dataset) &\n",
    "        (df_rules[\"Labeling\"]==labeling) &\n",
    "        (df_rules[\"Encoding\"]==encoding)\n",
    "    ].loc[selected]\n",
    "\n",
    "    keep_cols = [c for c in [\n",
    "        \"Rule\",\"RHS_label\",\"feature_1_lhs\",\"feature_2_lhs\",\"feature_3_lhs\",\n",
    "        \"n_covered_cases\",\"pct_of_class_covered\",\"LB odds ratio\",\"Precision\",\"Recall\"\n",
    "    ] if c in sub.columns]\n",
    "\n",
    "    return sub[keep_cols].copy()\n",
    "\n",
    "min_cover_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Keep only Mode == 'neg' ---\n",
    "neg = min_cover_summary[min_cover_summary[\"Mode\"] == \"neg\"].copy()\n",
    "\n",
    "# --- 2) Drop columns (only if present) ---\n",
    "to_drop = [\"Mode\", \"Threshold\", \"Achievable (%)\", \"Covered / Total\", \"Selected Indexes\"]\n",
    "neg = neg.drop(columns=[c for c in to_drop if c in neg.columns])\n",
    "\n",
    "# --- 3) Build formatters ---\n",
    "def fmt_detok(x):\n",
    "    return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "formatters = {}\n",
    "for col in (\"Encoding\", \"Rule\"): \n",
    "    if col in neg.columns:\n",
    "        formatters[col] = fmt_detok\n",
    "\n",
    "# --- 4) Save to LaTeX ---\n",
    "root_dir = locals().get(\"root_dir\", \".\")\n",
    "out_fp_tex = os.path.join(root_dir, \"min_cover_summary_neg.tex\")\n",
    "\n",
    "neg.to_latex(\n",
    "    out_fp_tex,\n",
    "    index=False,\n",
    "    escape=False,     # preserve \\detokenize\n",
    "    longtable=True,  \n",
    "    float_format=\"%.2f\",\n",
    "    formatters=formatters\n",
    ")\n",
    "\n",
    "print(f\"✅ Saved min_cover_summary_neg.tex → {out_fp_tex}\")\n",
    "neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf5f98",
   "metadata": {},
   "source": [
    "### Metric Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Comparison of Baseline with CRM (Top 5 rules)\n",
    "try:\n",
    "    _ = all_rules_crm\n",
    "except NameError:\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    all_rules_crm_path = os.path.join('5_analysis', 'random', 'combined_sorted_all.csv')\n",
    "    all_rules_crm = pd.read_csv(all_rules_crm_path, sep=',')\n",
    "\n",
    "# Harmonize/filter CRM rules like before (if helper exists)\n",
    "try:\n",
    "    rules_crm_f = _harmonize_and_filter(all_rules_crm)\n",
    "except NameError:\n",
    "    rules_crm_f = all_rules_crm.copy()\n",
    "\n",
    "required_cols = ['Dataset', 'Labeling', 'Encoding']\n",
    "missing = [c for c in required_cols if c not in rules_crm_f.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in CRM rules: {missing}\")\n",
    "\n",
    "# Select the Top 5 rules per (Dataset, Labeling, Encoding) based on existing sorted order\n",
    "rules_crm_top5 = (\n",
    "    rules_crm_f\n",
    "    .groupby(required_cols, as_index=False, sort=False)\n",
    "    .head(5)\n",
    " )\n",
    "\n",
    "# Count rules per group using the same helper (keep 'crm' prefix so merge util works unchanged)\n",
    "crm_counts_top5 = _rule_counts(rules_crm_top5, 'crm')\n",
    "\n",
    "# Build comparisons analogous to earlier ones, but with CRM limited to Top 5\n",
    "dt_comparison_top5 = _merge_with_crm(dt_counts, crm_counts_top5)\n",
    "ripperk_comparison_top5 = _merge_with_crm(ripperk_counts, crm_counts_top5)\n",
    "\n",
    "# Order columns\n",
    "try:\n",
    "    dt_comparison_top5 = dt_comparison_top5.reindex(columns=[c for c in _dt_cols if c in dt_comparison_top5.columns])\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    ripperk_comparison_top5 = ripperk_comparison_top5.reindex(columns=[c for c in _rk_cols if c in ripperk_comparison_top5.columns])\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "#  Attach metrics if present\n",
    "try:\n",
    "    dt_comparison_top5 = _attach_metrics(dt_comparison_top5, dt_metrics, prefix='dt')\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    ripperk_comparison_top5 = _attach_metrics(ripperk_comparison_top5, rk_metrics, prefix='ripperk')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print('dt_comparison_top5 shape:', dt_comparison_top5.shape)\n",
    "print('ripperk_comparison_top5 shape:', ripperk_comparison_top5.shape)\n",
    "display(dt_comparison_top5)\n",
    "display(ripperk_comparison_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33360cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Mean/Median Confidence of Top-5 CRM rules, joined next to precision\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure we have the Top-5 CRM rules available\n",
    "try:\n",
    "    _ = rules_crm_top5\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = rules_crm_f\n",
    "    except NameError:\n",
    "        # Load all CRM rules if not present\n",
    "        all_rules_crm_path = os.path.join('5_analysis', 'random', 'combined_sorted_all.csv')\n",
    "        all_rules_crm = pd.read_csv(all_rules_crm_path, sep=',')\n",
    "        try:\n",
    "            rules_crm_f = _harmonize_and_filter(all_rules_crm)\n",
    "        except NameError:\n",
    "            rules_crm_f = all_rules_crm.copy()\n",
    "    # Derive Top-5 per (Dataset, Labeling, Encoding) assuming input is already sorted by quality\n",
    "    rules_crm_top5 = (\n",
    "        rules_crm_f.groupby(['Dataset','Labeling','Encoding'], as_index=False, sort=False)\n",
    "                    .head(5)\n",
    "    )\n",
    "\n",
    "# Identify the confidence column in CRM rules\n",
    "possible_conf_cols = [\n",
    "    'Confidence','confidence','conf','confidence_score','Conf',\n",
    "    'Rule Confidence','rule_confidence'\n",
    " ]\n",
    "conf_col = next((c for c in possible_conf_cols if c in rules_crm_top5.columns), None)\n",
    "if conf_col is None:\n",
    "    raise ValueError(f\"Could not find a CRM confidence column among {possible_conf_cols}. Available: {list(rules_crm_top5.columns)}\")\n",
    "\n",
    "# Aggregate mean/median confidence for Top-5 per group\n",
    "crm_conf_stats = (\n",
    "    rules_crm_top5\n",
    "    .groupby(['Dataset','Labeling','Encoding'])[conf_col]\n",
    "    .agg(['mean','median'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean':'crm_conf_mean_top5','median':'crm_conf_median_top5'})\n",
    " )\n",
    "\n",
    "# Helper to place new columns right after an anchor column, if present\n",
    "def _insert_after(df: pd.DataFrame, anchor: str, cols_to_place: list[str]) -> pd.DataFrame:\n",
    "    if anchor not in df.columns:\n",
    "        return df\n",
    "    cols = list(df.columns)\n",
    "    # Remove to reinsert\n",
    "    for c in cols_to_place:\n",
    "        if c in cols:\n",
    "            cols.remove(c)\n",
    "    idx = cols.index(anchor) + 1\n",
    "    for i, c in enumerate(cols_to_place):\n",
    "        if c in df.columns:\n",
    "            cols.insert(idx + i, c)\n",
    "    return df.reindex(columns=cols)\n",
    "\n",
    "# Merge into dt_comparison_top5 and ripperk_comparison_top5\n",
    "try:\n",
    "    dt_comparison_top5 = dt_comparison_top5.merge(crm_conf_stats, on=['Dataset','Labeling','Encoding'], how='left')\n",
    "    # Try to place next to dt precision if present\n",
    "    for anchor_name in ['dt_precision','precision_dt','dt_prec','precision']:\n",
    "        if anchor_name in dt_comparison_top5.columns:\n",
    "            dt_comparison_top5 = _insert_after(dt_comparison_top5, anchor_name, ['crm_conf_mean_top5','crm_conf_median_top5'])\n",
    "            break\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    ripperk_comparison_top5 = ripperk_comparison_top5.merge(crm_conf_stats, on=['Dataset','Labeling','Encoding'], how='left')\n",
    "    # Try to place next to ripperk precision if present\n",
    "    for anchor_name in ['ripperk_precision','precision_ripperk','rk_precision','precision']:\n",
    "        if anchor_name in ripperk_comparison_top5.columns:\n",
    "            ripperk_comparison_top5 = _insert_after(ripperk_comparison_top5, anchor_name, ['crm_conf_mean_top5','crm_conf_median_top5'])\n",
    "            break\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print(f\"Used CRM confidence column: {conf_col}\")\n",
    "try:\n",
    "    print('dt_comparison_top5 with CRM confidence stats:', dt_comparison_top5.shape)\n",
    "    display(dt_comparison_top5)\n",
    "except NameError:\n",
    "    print('dt_comparison_top5 not found in scope.')\n",
    "try:\n",
    "    print('ripperk_comparison_top5 with CRM confidence stats:', ripperk_comparison_top5.shape)\n",
    "    display(ripperk_comparison_top5)\n",
    "except NameError:\n",
    "    print('ripperk_comparison_top5 not found in scope.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653febb",
   "metadata": {},
   "source": [
    "### Rule comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6768daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Expand DT and RIPPERK rules to per-rule rows with LHS feature parts (1..7)\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "FEATURE_SLOTS = 10  # how many feature_*_lhs columns to emit\n",
    "\n",
    "# Helper: find rule text column in a given DF\n",
    "def _detect_rule_col(df: pd.DataFrame) -> str | None:\n",
    "    candidates = ['Rule','rule','Rule_Text','rule_text','RuleString','Antecedent','rule_str']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    # fallback: find first column whose sample values look like rule strings\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            sample = df[c].dropna().astype(str).head(20)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not len(sample):\n",
    "            continue\n",
    "        if sample.str.contains(r\"\\[\", regex=True).any() or sample.str.contains('-->', regex=True).any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Helper: extract antecedent inner text and RHS label, robust to nested [...] inside features\n",
    "def _split_rule(rule_str: str) -> tuple[str, str | None, str]:\n",
    "    s = str(rule_str)\n",
    "\n",
    "    # RHS label: anything after -->\n",
    "    m_rhs = re.search(r\"-->\\s*(.+)$\", s)\n",
    "    rhs_label = m_rhs.group(1).strip() if m_rhs else None\n",
    "\n",
    "    # LHS full: everything before -->\n",
    "    lhs_full = s.split('-->', 1)[0].strip()\n",
    "\n",
    "    # Extract inner content of the OUTERMOST [...] only (handle nested brackets inside feature names)\n",
    "    antecedent_inner = lhs_full\n",
    "    if lhs_full.startswith('['):\n",
    "        depth = 0\n",
    "        end_idx = None\n",
    "        for i, ch in enumerate(lhs_full):\n",
    "            if ch == '[':\n",
    "                depth += 1\n",
    "            elif ch == ']':\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    end_idx = i\n",
    "                    break\n",
    "        if end_idx is not None and end_idx == len(lhs_full) - 1:\n",
    "            antecedent_inner = lhs_full[1:end_idx].strip()\n",
    "        else:\n",
    "            if lhs_full.startswith('[') and lhs_full.endswith(']'):\n",
    "                antecedent_inner = lhs_full[1:-1].strip()\n",
    "            else:\n",
    "                antecedent_inner = lhs_full\n",
    "\n",
    "    return antecedent_inner, rhs_label, lhs_full\n",
    "\n",
    "# Helper: split LHS into full clause strings by the ∧ sign (only)\n",
    "def _split_lhs_clauses(antecedent_inner: str) -> list[str]:\n",
    "    if not antecedent_inner:\n",
    "        return []\n",
    "    parts = [p.strip() for p in re.split(r\"\\s*∧\\s*\", antecedent_inner) if p.strip()]\n",
    "    return parts\n",
    "\n",
    "# Build a per-rule dataframe with up to the first seven LHS clauses as feature_1..7\n",
    "def _expand_rules(df: pd.DataFrame, model_name: str) -> pd.DataFrame:\n",
    "    if df is None or len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rule_col = _detect_rule_col(df)\n",
    "    if rule_col is None:\n",
    "        raise ValueError(f\"Could not detect rule column in {model_name} rules. Available columns: {list(df.columns)}\")\n",
    "\n",
    "    # keys to keep if present\n",
    "    meta_cols = [c for c in ['Dataset','Labeling','Encoding'] if c in df.columns]\n",
    "    # carry common quality columns if present\n",
    "    keep_qual_cols = [c for c in ['Confidence','confidence','Precision','precision','Support','support','Lift','lift'] if c in df.columns]\n",
    "\n",
    "    feature_cols = [f'feature_{i}_lhs' for i in range(1, FEATURE_SLOTS + 1)]\n",
    "\n",
    "    out_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        rule_str = row[rule_col]\n",
    "        antecedent_inner, rhs_label_raw, lhs_full = _split_rule(rule_str)\n",
    "\n",
    "        # Map RHS_label: 'Label'->1, '!Label'->0; otherwise keep as-is\n",
    "        rhs_label_norm = None if rhs_label_raw is None else rhs_label_raw.strip()\n",
    "        rhs_label_mapped = {'Label': 1, '!Label': 0}.get(rhs_label_norm, rhs_label_norm)\n",
    "\n",
    "        # Split the antecedent into full clause strings (no parsing)\n",
    "        lhs_clauses = _split_lhs_clauses(antecedent_inner)\n",
    "\n",
    "        base = {c: row[c] for c in meta_cols}\n",
    "        for qc in keep_qual_cols:\n",
    "            base[qc] = row[qc]\n",
    "\n",
    "        base.update({\n",
    "            'Rule': rule_str,\n",
    "            'LHS_features': lhs_full,           # full text before -->\n",
    "            'RHS_label': rhs_label_mapped,\n",
    "        })\n",
    "        # Fill feature_1_lhs .. feature_7_lhs\n",
    "        for i, col in enumerate(feature_cols):\n",
    "            base[col] = lhs_clauses[i] if i < len(lhs_clauses) else None\n",
    "\n",
    "        out_rows.append(base)\n",
    "\n",
    "    core_cols = ['Rule','LHS_features','RHS_label'] + feature_cols\n",
    "    cols_order = meta_cols + core_cols + keep_qual_cols\n",
    "    return pd.DataFrame(out_rows)[cols_order]\n",
    "\n",
    "# Acquire DT/RIPPERK rules DFs\n",
    "dt_source = None\n",
    "rk_source = None\n",
    "try:\n",
    "    dt_source = rules_dt_f\n",
    "except NameError:\n",
    "    try:\n",
    "        dt_source = rules_dt\n",
    "    except NameError:\n",
    "        dt_source = None\n",
    "try:\n",
    "    rk_source = rules_ripperk_f\n",
    "except NameError:\n",
    "    try:\n",
    "        rk_source = rules_ripperk\n",
    "    except NameError:\n",
    "        rk_source = None\n",
    "\n",
    "if dt_source is None and rk_source is None:\n",
    "    raise NameError(\"Neither DT nor RIPPERK rules were found in the current scope. Please run the earlier cells that load 'rules_dt_f' and 'rules_ripperk_f'.\")\n",
    "\n",
    "# Build expanded DataFrames (one row per rule)\n",
    "dt_rules_all_expanded = _expand_rules(dt_source, 'dt') if dt_source is not None else pd.DataFrame()\n",
    "ripperk_rules_all_expanded = _expand_rules(rk_source, 'ripperk') if rk_source is not None else pd.DataFrame()\n",
    "\n",
    "print('dt_rules_all_expanded shape:', dt_rules_all_expanded.shape)\n",
    "print('ripperk_rules_all_expanded shape:', ripperk_rules_all_expanded.shape)\n",
    "display(dt_rules_all_expanded)\n",
    "display(ripperk_rules_all_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7624d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_rules_all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fix CRM feature/value extraction by parsing from LHS_features (robust to \"_binned_(...]\" etc.) ---\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _parse_lhs_list(s: str) -> list[str]:\n",
    "    \"\"\"Parse LHS_features like \"['A_1','B_(0,1]']\" -> ['A_1','B_(0,1]'].\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    txt = str(s).strip()\n",
    "    try:\n",
    "        out = ast.literal_eval(txt)\n",
    "        return [str(x) for x in out] if isinstance(out, list) else [str(out)]\n",
    "    except Exception:\n",
    "        # Fallback splitter (best effort)\n",
    "        inner = txt.strip().strip(\"[]\")\n",
    "        parts = []\n",
    "        buff, in_q = [], None\n",
    "        for ch in inner:\n",
    "            if ch in (\"'\", '\"'):\n",
    "                in_q = ch if in_q is None else (None if in_q == ch else in_q)\n",
    "                buff.append(ch)\n",
    "            elif ch == \",\" and in_q is None:\n",
    "                parts.append(\"\".join(buff).strip().strip(\"'\\\"\"))\n",
    "                buff = []\n",
    "            else:\n",
    "                buff.append(ch)\n",
    "        if buff:\n",
    "            parts.append(\"\".join(buff).strip().strip(\"'\\\"\"))\n",
    "        return parts\n",
    "\n",
    "def _split_clause(clause: str) -> tuple[str, str | None]:\n",
    "    \"\"\"\n",
    "    Split a clause into (base, value) at the LAST underscore:\n",
    "      'IV Antibiotics_1'                             -> ('IV Antibiotics', '1')\n",
    "      'LacticAcid_binned_(-0.001, 1.0]'             -> ('LacticAcid_binned', '(-0.001, 1.0]')\n",
    "      \"responded_existence:('A','B')_0\"             -> (\"responded_existence:('A','B')\", '0')\n",
    "      'org:group_U|count|literal_0.0'               -> ('org:group_U|count|literal', '0.0')\n",
    "    If no underscore: value = None.\n",
    "    \"\"\"\n",
    "    if clause is None:\n",
    "        return (None, None)\n",
    "    cs = str(clause).strip()\n",
    "    base, sep, val = cs.rpartition('_')  # last underscore\n",
    "    if sep == '':\n",
    "        return (cs, None)\n",
    "    return (base, val)\n",
    "\n",
    "# Rebuild feature_{i}_lhs and feature_{i}_value for i = 1..3 from LHS_features\n",
    "for i in (1, 2, 3):\n",
    "    lhs_out, val_out = [], []\n",
    "    for s in crm_rules_all_expanded['LHS_features']:\n",
    "        lst = _parse_lhs_list(s)\n",
    "        if len(lst) >= i:\n",
    "            b, v = _split_clause(lst[i-1])\n",
    "        else:\n",
    "            b, v = (np.nan, np.nan)\n",
    "        lhs_out.append(b)\n",
    "        val_out.append(v)\n",
    "    crm_rules_all_expanded[f'feature_{i}_lhs'] = lhs_out\n",
    "    crm_rules_all_expanded[f'feature_{i}_value'] = val_out\n",
    "\n",
    "# quick spot-check\n",
    "preview_cols = [\n",
    "    'Rule', 'LHS_features',\n",
    "    'feature_1_lhs','feature_1_value',\n",
    "    'feature_2_lhs','feature_2_value',\n",
    "    'feature_3_lhs','feature_3_value',\n",
    "]\n",
    "display(crm_rules_all_expanded[[c for c in preview_cols if c in crm_rules_all_expanded.columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d782da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DT & RIPPERK: split feature_i_lhs into base (feature_i_lhs) and value (feature_i_value) for i=1..3 ---\n",
    "\n",
    "def _split_dt_rk_clause(clause: str):\n",
    "    \"\"\"\n",
    "    Split a DT/RIPPERK clause into (base, value).\n",
    "    Rules:\n",
    "      - If it looks like \"<...>_(<interval>) <op> <rhs>\", return:\n",
    "            base = part before the last \"_\", value = \"(<interval>) <op> <rhs>\"\n",
    "        e.g., \"X_binned_(0,1] = 0\" -> (\"X_binned\", \"(0,1] = 0\")\n",
    "      - Else, if it looks like \"<lhs> <op> <rhs>\", return:\n",
    "            base = <lhs>, value = <rhs>   (operator is dropped, matches your examples)\n",
    "        e.g., \"mr[... ] = 1\" -> (\"mr[...]\", \"1\")\n",
    "      - Else (no operator), try last \"_\" split; if interval suffix, value = that suffix; else value=None.\n",
    "    \"\"\"\n",
    "    if clause is None or (isinstance(clause, float) and pd.isna(clause)):\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "    s = str(clause).strip()\n",
    "\n",
    "    # Extract LHS / operator / RHS if present\n",
    "    m = re.match(r\"^(.*?)(?:\\s*)(<=|>=|=|<|>)(?:\\s*)(.+)$\", s)\n",
    "    if m:\n",
    "        lhs = m.group(1).strip()\n",
    "        op  = m.group(2).strip()\n",
    "        rhs = m.group(3).strip()\n",
    "\n",
    "        # Look for interval suffix after the LAST underscore on the LHS\n",
    "        u = lhs.rfind(\"_\")\n",
    "        if u != -1:\n",
    "            suffix = lhs[u+1:].strip()\n",
    "            # interval if it starts with '(' or '['\n",
    "            if suffix.startswith(\"(\") or suffix.startswith(\"[\"):\n",
    "                base = lhs[:u].strip()\n",
    "                value = f\"{suffix} {op} {rhs}\"   # include operator, e.g. \"(0,1] = 0\"\n",
    "                return (base, value)\n",
    "\n",
    "        # No interval suffix: keep base as full LHS, value is RHS only (operator dropped)\n",
    "        return (lhs, rhs)\n",
    "\n",
    "    # If there's no explicit operator, try to peel off an interval suffix by last underscore\n",
    "    u = s.rfind(\"_\")\n",
    "    if u != -1:\n",
    "        suffix = s[u+1:].strip()\n",
    "        if suffix.startswith(\"(\") or suffix.startswith(\"[\"):\n",
    "            return (s[:u].strip(), suffix)\n",
    "    # Fallback: no split\n",
    "    return (s, np.nan)\n",
    "\n",
    "def _apply_split_base_value(df: pd.DataFrame, name: str):\n",
    "    if df is None or len(df) == 0:\n",
    "        return\n",
    "    for i in (1, 2, 3):\n",
    "        col = f\"feature_{i}_lhs\"\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        bases, vals = [], []\n",
    "        for v in df[col]:\n",
    "            b, val = _split_dt_rk_clause(v)\n",
    "            bases.append(b)\n",
    "            vals.append(val)\n",
    "        df[col] = bases\n",
    "        df[f\"feature_{i}_value\"] = vals\n",
    "\n",
    "# Apply to DT and RIPPERK (these DataFrames should already exist in your notebook)\n",
    "_apply_split_base_value(dt_rules_all_expanded, \"dt\")\n",
    "_apply_split_base_value(ripperk_rules_all_expanded, \"ripperk\")\n",
    "\n",
    "# quick sanity check\n",
    "def _preview(df, title):\n",
    "    if df is None or len(df) == 0: \n",
    "        return\n",
    "    show = ['Rule','LHS_features',\n",
    "            'feature_1_lhs','feature_1_value',\n",
    "            'feature_2_lhs','feature_2_value',\n",
    "            'feature_3_lhs','feature_3_value']\n",
    "    print(f\"\\n=== Preview: {title} ===\")\n",
    "    display(df[[c for c in show if c in df.columns]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_preview(dt_rules_all_expanded, \"DT\")\n",
    "_preview(ripperk_rules_all_expanded, \"RIPPERK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226030b",
   "metadata": {},
   "source": [
    "## Similarity based on 80% similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e816436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Similar DT ↔ CRM rules with variable feature counts, positional matching, per-feature similarity ≥ 80% ---\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "THRESHOLD = 0.80  # 80%\n",
    "\n",
    "def _norm_text(x):\n",
    "    \"\"\"Normalize text for fair string similarity: lower, trim, collapse spaces.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def _sim_ratio(a, b):\n",
    "    \"\"\"SequenceMatcher ratio on normalized strings; returns 0.0 if any empty.\"\"\"\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Columns to carry & compare\n",
    "meta_cols = [c for c in ['Dataset','Labeling','Encoding'] if c in dt_rules_all_expanded.columns and c in crm_rules_all_expanded.columns]\n",
    "compare_cols = ['feature_1_lhs','feature_2_lhs','feature_3_lhs']\n",
    "\n",
    "# Select and normalize\n",
    "sel_cols = meta_cols + ['RHS_label','Rule'] + compare_cols\n",
    "dt = dt_rules_all_expanded[sel_cols].copy()\n",
    "crm = crm_rules_all_expanded[sel_cols].copy()\n",
    "\n",
    "for i in range(1, 4):\n",
    "    dt[f'f{i}_norm'] = dt[f'feature_{i}_lhs'].map(_norm_text)\n",
    "    crm[f'f{i}_norm'] = crm[f'feature_{i}_lhs'].map(_norm_text)\n",
    "\n",
    "# Build a presence pattern (positional) like \"110\" meaning f1,f2 present; f3 absent\n",
    "def _presence_pattern(df, side_suffix=\"\"):\n",
    "    pres = []\n",
    "    for i in range(1, 4):\n",
    "        pres.append((df[f'f{i}_norm{side_suffix}'] != \"\").astype(int).astype(str))\n",
    "    pat = pres[0] + pres[1] + pres[2]\n",
    "    return pat\n",
    "\n",
    "# Merge inside same group (Dataset, Labeling, Encoding, RHS_label)\n",
    "pairs = dt.merge(crm, on=meta_cols + ['RHS_label'], how='inner', suffixes=('_dt', '_crm'))\n",
    "\n",
    "# Presence patterns per side\n",
    "pairs['pattern_dt']  = _presence_pattern(pairs, side_suffix=\"_dt\")\n",
    "pairs['pattern_crm'] = _presence_pattern(pairs, side_suffix=\"_crm\")\n",
    "\n",
    "# Require identical presence pattern and at least one feature present\n",
    "mask_same_pattern = pairs['pattern_dt'] == pairs['pattern_crm']\n",
    "mask_nonempty     = pairs['pattern_dt'].str.contains('1')  # at least one '1'\n",
    "\n",
    "# Similarity per feature (only meaningful when present on both sides)\n",
    "for i in range(1, 4):\n",
    "    pairs[f'sim_f{i}'] = [\n",
    "        _sim_ratio(a, b) for a, b in zip(pairs[f'f{i}_norm_dt'], pairs[f'f{i}_norm_crm'])\n",
    "    ]\n",
    "    # If either side is empty at this position, mark sim as NaN (excluded from avg and checks)\n",
    "    empties = (pairs[f'f{i}_norm_dt'] == \"\") | (pairs[f'f{i}_norm_crm'] == \"\")\n",
    "    pairs.loc[empties, f'sim_f{i}'] = np.nan\n",
    "\n",
    "# For each present feature position, require sim_fi ≥ THRESHOLD\n",
    "def _meets_threshold(row):\n",
    "    sims = []\n",
    "    ok = True\n",
    "    for i in (1,2,3):\n",
    "        a_present = row[f'f{i}_norm_dt']  != \"\"\n",
    "        b_present = row[f'f{i}_norm_crm'] != \"\"\n",
    "        if a_present and b_present:\n",
    "            sims.append(row[f'sim_f{i}'])\n",
    "            if row[f'sim_f{i}'] < THRESHOLD:\n",
    "                ok = False\n",
    "    # If no positions present (shouldn’t happen due to mask_nonempty), mark False\n",
    "    if not sims:\n",
    "        return False\n",
    "    return ok\n",
    "\n",
    "pairs['meets_threshold'] = pairs.apply(_meets_threshold, axis=1)\n",
    "\n",
    "# Average similarity across present positions only (for sorting)\n",
    "pairs['avg_sim'] = pairs[['sim_f1','sim_f2','sim_f3']].mean(axis=1, skipna=True)\n",
    "\n",
    "# Keep only good matches\n",
    "similar_rules = (\n",
    "    pairs.loc[mask_same_pattern & mask_nonempty & pairs['meets_threshold'],\n",
    "              meta_cols +\n",
    "              ['RHS_label',\n",
    "               'pattern_dt', 'avg_sim',\n",
    "               'Rule_dt','feature_1_lhs_dt','feature_2_lhs_dt','feature_3_lhs_dt',\n",
    "               'Rule_crm','feature_1_lhs_crm','feature_2_lhs_crm','feature_3_lhs_crm',\n",
    "               'sim_f1','sim_f2','sim_f3']]\n",
    "    .sort_values(by=meta_cols + ['avg_sim'], ascending=[True, True, True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Similar DT↔CRM rule pairs found:\", similar_rules.shape[0])\n",
    "display(similar_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82edab66",
   "metadata": {},
   "source": [
    "## Visualizing IMpresseD Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ef248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Build pattern-attribute table using the repository functions (no guessing) ===\n",
    "# Input  : 3_extracted_features/BPI15A/BPI15A_decl2_features/IMPresseD/IMPresseD.csv\n",
    "# Assumes: every column except 'Case_ID' and 'Label' is a 0/1 pattern indicator\n",
    "# Output : pattern_attributes.csv saved next to the input\n",
    "\n",
    "from helper_functions.IMPresseD.IMIPD import (\n",
    "    create_pattern_attributes,\n",
    ")\n",
    "\n",
    "# ----- paths -----\n",
    "ENCODED_CSV = \"3_extracted_features/BPI15A/BPI15A_payload_560925_features/IMPresseD/IMPresseD.csv\"\n",
    "OUT_CSV = \"IMPresseD_patterns/BPI15A/BPI15A_payload_560925_features/pattern_attributes.csv\"\n",
    "\n",
    "# ----- load -----\n",
    "df = pd.read_csv(ENCODED_CSV)\n",
    "\n",
    "# sanity checks\n",
    "assert \"Case_ID\" in df.columns, \"Expected a 'Case_ID' column.\"\n",
    "assert \"Outcome\"   in df.columns, \"Expected a 'Outcome' column (binary 0/1).\"\n",
    "\n",
    "# identify pattern columns (everything except Case_ID & Outcome)\n",
    "pattern_cols = [c for c in df.columns if c not in (\"Case_ID\", \"Outcome\")]\n",
    "if not pattern_cols:\n",
    "    raise RuntimeError(\"No pattern columns found. Expected all non-Case_ID/Outcome columns to be patterns.\")\n",
    "\n",
    "# ensure binary ints for patterns and label\n",
    "df[pattern_cols] = df[pattern_cols].fillna(0).astype(int)\n",
    "df[\"Outcome\"] = df[\"Outcome\"].fillna(0).astype(int)\n",
    "\n",
    "# IMIPD expects a \"patient_data\" table with pattern columns + the label\n",
    "patient_data = df[[\"Case_ID\", \"Outcome\"] + pattern_cols].reset_index(drop=True)\n",
    "\n",
    "# ----- similarity inputs (required by the API) -----\n",
    "n = len(patient_data)\n",
    "pair_cases = []\n",
    "start_search_points = {}\n",
    "k = 0\n",
    "for i in range(n - 1):\n",
    "    start_search_points[i] = k\n",
    "    for j in range(i + 1, n):\n",
    "        pair_cases.append((i, j))\n",
    "        k += 1\n",
    "\n",
    "pairwise = np.zeros(len(pair_cases), dtype=float)  # similarity will become 0 for all patterns\n",
    "\n",
    "# ----- compute attributes via the repo function -----\n",
    "attrs = create_pattern_attributes(\n",
    "    patient_data=patient_data,\n",
    "    label_class=\"Outcome\",\n",
    "    pattern_list=pattern_cols,\n",
    "    pairwise_distances_array=pairwise,\n",
    "    pair_cases=pair_cases,\n",
    "    start_search_points=start_search_points,\n",
    "    outcome_type=\"binary\",\n",
    ")\n",
    "\n",
    "# nice ordering\n",
    "attrs = attrs.sort_values(\n",
    "    by=[\"Outcome_Interest\", \"Frequency_Interest\"],\n",
    "    ascending=[False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# save & preview\n",
    "attrs.to_csv(OUT_CSV, index=False)\n",
    "print(f\"✅ Saved pattern attributes → {OUT_CSV}\")\n",
    "display(attrs.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dafa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Make Case_Distance_Interest informative by adding real case-level covariates ===\n",
    "# Uses the repo functions from IMPresseD.IMIPD\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "from helper_functions.IMPresseD.IMIPD import (\n",
    "    create_pattern_attributes,\n",
    "    calculate_pairwise_case_distance,\n",
    ")\n",
    "\n",
    "# ---------- PATHS ----------\n",
    "ENCODED_CSV = \"3_extracted_features/BPI15A/BPI15A_payload_560925_features/IMPresseD/IMPresseD.csv\"\n",
    "RAW_LOG_CSV = \"2_labelled_logs/BPI15A/bpi15A_payload_560925.csv\"  # <-- the event log passed to --log_path\n",
    "OUT_CSV     = \"IMPresseD_patterns/BPI15A/BPI15A_payload_560925_features/pattern_attributes_with_similarity.csv\"\n",
    "\n",
    "# ---------- COLUMN NAMES ----------\n",
    "CASE_ID_COL = \"case:concept:name\"\n",
    "TS_COL      = \"time:timestamp\"\n",
    "# LABEL_COL = \"case:Label\"         # not needed below, we use the encoded Label\n",
    "ENC_CASE_ID = \"Case_ID\"            \n",
    "ENC_LABEL   = \"Outcome\"              # in the encoded file (0/1)\n",
    "\n",
    "NUMERIC_ATTRS_HINT = [\"case:SUMleges\"]\n",
    "CATEGORICAL_ATTRS_HINT = [\n",
    "    \"question\", \"dateFinished\", \"action_code\", \"activityNameEN\", \"activityNameNL\",\n",
    "    \"lifecycle:transition\", \"case:caseStatus\", \"case:last_phase\", \"case:case_type\",\n",
    "    \"case:Responsible_actor\", \"case:parts\", \"case:termName\", \"case:requestComplete\",\n",
    "    \"case:IDofConceptCase\", \"case:Label\", \"case:landRegisterID\", \"case:caseProcedure\",\n",
    "    \"case:Includes_subCases\", \"monitoringResource\", \"org:resource\", \"dateStop\"\n",
    "]\n",
    "\n",
    "# ---------- 1) LOAD DATA ----------\n",
    "enc = pd.read_csv(ENCODED_CSV)\n",
    "log = pd.read_csv(RAW_LOG_CSV)\n",
    "\n",
    "# Basic checks\n",
    "assert ENC_CASE_ID in enc.columns and ENC_LABEL in enc.columns, \"Encoded CSV must have Case_ID and Label.\"\n",
    "assert CASE_ID_COL in log.columns, \"Raw log must have the case id column.\"\n",
    "\n",
    "# Keep only the cases that appear in the encoded set (order matters later)\n",
    "keep_cases = enc[ENC_CASE_ID].dropna().astype(str).unique().tolist()\n",
    "log[CASE_ID_COL] = log[CASE_ID_COL].astype(str)\n",
    "log = log[log[CASE_ID_COL].isin(keep_cases)].copy()\n",
    "\n",
    "# Parse timestamps for duration features\n",
    "if TS_COL in log.columns:\n",
    "    log[TS_COL] = pd.to_datetime(log[TS_COL], errors=\"coerce\")\n",
    "\n",
    "# ---------- 2) BUILD CASE-LEVEL COVARIATES ----------\n",
    "# Helpers for aggregations\n",
    "def first_valid(s):\n",
    "    s = s.dropna()\n",
    "    return s.iloc[0] if len(s) else np.nan\n",
    "\n",
    "def mode_or_last(s):\n",
    "    s = s.dropna()\n",
    "    if s.empty:\n",
    "        return np.nan\n",
    "    m = s.mode(dropna=True)\n",
    "    return m.iloc[0] if not m.empty else s.iloc[-1]\n",
    "\n",
    "# Which hints are actually present in the raw log?\n",
    "present_numeric = [c for c in NUMERIC_ATTRS_HINT if c in log.columns]\n",
    "present_cats    = [c for c in CATEGORICAL_ATTRS_HINT if c in log.columns]\n",
    "\n",
    "# Group by case\n",
    "gb = log.groupby(CASE_ID_COL, sort=False)\n",
    "\n",
    "# Start with core derived covariates per case\n",
    "case_df = pd.DataFrame(index=gb.size().index)\n",
    "case_df.index.name = CASE_ID_COL\n",
    "case_df[\"event_count\"] = gb.size()\n",
    "if TS_COL in log.columns:\n",
    "    case_df[\"duration_hours\"] = (gb[TS_COL].max() - gb[TS_COL].min()).dt.total_seconds() / 3600.0\n",
    "else:\n",
    "    case_df[\"duration_hours\"] = np.nan\n",
    "\n",
    "# Add numeric “case:*” columns (first_valid is safe for true case-level attributes)\n",
    "for c in present_numeric:\n",
    "    case_df[c] = gb[c].agg(first_valid)\n",
    "\n",
    "# Add categorical columns\n",
    "for c in present_cats:\n",
    "    # If it's a case-level attribute (starts with \"case:\"), take first_valid.\n",
    "    # Otherwise (event-level, e.g., org:resource), take the mode (fallback to last).\n",
    "    agg_fn = first_valid if c.startswith(\"case:\") else mode_or_last\n",
    "    case_df[c] = gb[c].agg(agg_fn)\n",
    "\n",
    "# ---------- 3) ALIGN COVARIATES TO ENCODED ORDER (robustly) ----------\n",
    "# Normalize ids to string for matching (AFTER dropping NaNs)\n",
    "enc_ids = enc[ENC_CASE_ID].dropna().astype(str)\n",
    "raw_index = case_df.index.astype(str)\n",
    "\n",
    "def try_direct_merge():\n",
    "    overlap = set(enc_ids).intersection(set(raw_index))\n",
    "    # If most IDs overlap by value, do a direct value-based merge\n",
    "    if len(overlap) >= max(1, int(0.8 * len(enc_ids))):\n",
    "        merged = (\n",
    "            enc[[ENC_CASE_ID]]\n",
    "            .astype({ENC_CASE_ID: str})\n",
    "            .merge(\n",
    "                case_df.reset_index().rename(columns={CASE_ID_COL: ENC_CASE_ID}).astype({ENC_CASE_ID: str}),\n",
    "                on=ENC_CASE_ID,\n",
    "                how=\"left\"\n",
    "            )\n",
    "        )\n",
    "        print(f\"Alignment strategy: direct id match (overlap={len(overlap)}/{len(enc_ids)})\")\n",
    "        return merged\n",
    "    return None\n",
    "\n",
    "def try_enumeration(order_list, tag):\n",
    "    # If encoded IDs are 0..n-1 as strings, map them to an enumeration of raw cases\n",
    "    if not enc_ids.str.fullmatch(r\"\\d+\").all():\n",
    "        return None\n",
    "    mapping = pd.Series(order_list, index=[str(i) for i in range(len(order_list))])\n",
    "    mapped = enc_ids.map(mapping)\n",
    "    if mapped.notna().all():\n",
    "        tmp = enc[[ENC_CASE_ID]].copy()\n",
    "        tmp[\"_RAW_ID_\"] = mapped\n",
    "        merged = (\n",
    "            tmp.merge(\n",
    "                case_df.reset_index().rename(columns={CASE_ID_COL: \"_RAW_ID_\"}),\n",
    "                on=\"_RAW_ID_\",\n",
    "                how=\"left\"\n",
    "            ).drop(columns=[\"_RAW_ID_\"])\n",
    "        )\n",
    "        print(f\"Alignment strategy: enumeration ({tag})\")\n",
    "        return merged\n",
    "    return None\n",
    "\n",
    "# Try strategies in order\n",
    "case_df_aligned = try_direct_merge()\n",
    "if case_df_aligned is None:\n",
    "    # First-occurrence enumeration (order as they appear in raw log)\n",
    "    raw_first = log[CASE_ID_COL].dropna().astype(str).drop_duplicates().tolist()\n",
    "    case_df_aligned = try_enumeration(raw_first, \"first-occurrence\")\n",
    "\n",
    "if case_df_aligned is None:\n",
    "    # Sorted enumeration\n",
    "    raw_sorted = sorted(log[CASE_ID_COL].dropna().astype(str).unique().tolist())\n",
    "    case_df_aligned = try_enumeration(raw_sorted, \"sorted\")\n",
    "\n",
    "USE_PATTERN_SPACE_FALLBACK = False\n",
    "if case_df_aligned is None:\n",
    "    print(\"⚠️ Could not align encoded Case_ID to raw cases by value or enumeration. \"\n",
    "          \"Falling back to pattern-based distances for Case_Distance_Interest.\")\n",
    "    USE_PATTERN_SPACE_FALLBACK = True\n",
    "else:\n",
    "    case_df = case_df_aligned  # proceed with aligned covariates\n",
    "\n",
    "# ---------- 4) COMPUTE PAIRWISE DISTANCES ----------\n",
    "# Prepare covariate matrix (numeric + one-hot categoricals)\n",
    "if not USE_PATTERN_SPACE_FALLBACK:\n",
    "    # Numeric columns available in the aligned frame\n",
    "    num_cols = [\"event_count\", \"duration_hours\"] + [c for c in present_numeric if c in case_df.columns]\n",
    "    num_cols = [c for c in num_cols if c in case_df.columns]  # guard\n",
    "\n",
    "    cat_cols = [c for c in present_cats if c in case_df.columns]\n",
    "    if cat_cols:\n",
    "        cat_onehot = pd.get_dummies(case_df[cat_cols].astype(\"category\"), dummy_na=False)\n",
    "    else:\n",
    "        cat_onehot = pd.DataFrame(index=case_df.index)\n",
    "\n",
    "    X_features = pd.concat([case_df[num_cols], cat_onehot], axis=1).fillna(0)\n",
    "\n",
    "    # If there are literally no covariates, fall back to pattern space\n",
    "    if X_features.shape[1] == 0:\n",
    "        USE_PATTERN_SPACE_FALLBACK = True\n",
    "\n",
    "# If alignment failed or no covariates exist, compute distances in pattern space (binary)\n",
    "if USE_PATTERN_SPACE_FALLBACK:\n",
    "    pattern_cols = [c for c in enc.columns if c not in (ENC_CASE_ID, ENC_LABEL)]\n",
    "    X_features = enc[pattern_cols].astype(int)\n",
    "    num_for_distance = []  # all binary → Jaccard by the repo function\n",
    "else:\n",
    "    num_for_distance = [c for c in X_features.columns if c in num_cols]\n",
    "\n",
    "pairwise = calculate_pairwise_case_distance(X_features, num_col=num_for_distance)\n",
    "\n",
    "# Build (i,j) index pairs in condensed pdist order (must match the row order of enc/patient_data)\n",
    "n = len(enc)\n",
    "pair_cases = []\n",
    "start_search_points = {}\n",
    "k = 0\n",
    "for i in range(n - 1):\n",
    "    start_search_points[i] = k\n",
    "    for j in range(i + 1, n):\n",
    "        pair_cases.append((i, j))\n",
    "        k += 1\n",
    "\n",
    "# ---------- 5) RECOMPUTE PATTERN ATTRIBUTES (NOW WITH SIMILARITY) ----------\n",
    "pattern_cols = [c for c in enc.columns if c not in (ENC_CASE_ID, ENC_LABEL)]\n",
    "enc[pattern_cols] = enc[pattern_cols].fillna(0).astype(int)\n",
    "enc[ENC_LABEL] = enc[ENC_LABEL].fillna(0).astype(int)\n",
    "\n",
    "patient_data = enc[[ENC_CASE_ID, ENC_LABEL] + pattern_cols].reset_index(drop=True)\n",
    "\n",
    "attrs = create_pattern_attributes(\n",
    "    patient_data=patient_data,\n",
    "    label_class=ENC_LABEL,\n",
    "    pattern_list=pattern_cols,\n",
    "    pairwise_distances_array=pairwise,\n",
    "    pair_cases=pair_cases,\n",
    "    start_search_points=start_search_points,\n",
    "    outcome_type=\"binary\",\n",
    ")\n",
    "\n",
    "attrs = attrs.sort_values(\n",
    "    by=[\"Outcome_Interest\", \"Frequency_Interest\", \"Case_Distance_Interest\"],\n",
    "    ascending=[False, False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "attrs.to_csv(OUT_CSV, index=False)\n",
    "print(f\"✅ Saved pattern attributes with similarity → {OUT_CSV}\")\n",
    "\n",
    "print(attrs[\"Case_Distance_Interest\"].describe())\n",
    "attrs.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdebd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions.IMPresseD import tools\n",
    "\n",
    "target_patterns = [\"01-HOOFD-100_160\", \"01-HOOFD-101\"]\n",
    "df3 = attrs[attrs[\"patterns\"].isin(target_patterns)]\n",
    "\n",
    "# Ensure the save directory exists (tools.threeD_ploting saves to \"<folder>/pattern/...\")\n",
    "out_dir = \"IMPresseD_patterns/sepsis/sepsis_decl_features/\"\n",
    "os.makedirs(os.path.join(out_dir, \"pattern\"), exist_ok=True)\n",
    "\n",
    "# choose three axes that actually vary in your data\n",
    "tools.threeD_ploting(\n",
    "    df3,\n",
    "    \"Frequency_Interest\", \"Outcome_Interest\", 'Case_Distance_Interest',\n",
    "    folder_address=out_dir,\n",
    "    activity_level=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f2018",
   "metadata": {},
   "source": [
    "### Phase 3: comparing runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c79c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Collect and average runtimes across labelings for two experiment sets ---\n",
    "\n",
    "def _pick_root(candidates=(\"4.output\", \"4_output\")) -> Path:\n",
    "    for c in candidates:\n",
    "        p = Path(c)\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Could not find either '4.output' or '4_output'.\")\n",
    "\n",
    "def _list_subdirs(path: Path):\n",
    "    return sorted([d for d in path.iterdir() if d.is_dir()])\n",
    "\n",
    "def _choose_txt_file(enc_dir: Path, priority=(\"runtime_seconds.txt\", \"runtime.txt\")) -> Path:\n",
    "    # Prefer a known filename if present; otherwise take the first *.txt lexicographically\n",
    "    files = sorted(enc_dir.glob(\"*.txt\"))\n",
    "    if not files:\n",
    "        return None\n",
    "    by_name = {f.name.lower(): f for f in files}\n",
    "    for name in priority:\n",
    "        if name.lower() in by_name:\n",
    "            return by_name[name.lower()]\n",
    "    return files[0]\n",
    "\n",
    "_float_re = re.compile(r\"([-+]?\\d+(?:\\.\\d+)?)\")\n",
    "\n",
    "def _read_seconds(txt_file: Path):\n",
    "    try:\n",
    "        s = txt_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        s = txt_file.read_text(errors=\"ignore\")\n",
    "    m = _float_re.search(s)\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "def collect_runtime_averages(\n",
    "    dataset=\"traffic\",\n",
    "    experiment_sets=(\"random\", \"ipweights\"),\n",
    "    root_candidates=(\"4.output\", \"4_output\"),\n",
    "):\n",
    "    root = _pick_root(root_candidates)\n",
    "\n",
    "    rows = []\n",
    "    for exp in experiment_sets:\n",
    "        exp_dir = root / exp / dataset\n",
    "        if not exp_dir.exists():\n",
    "            # Skip missing experiment set or dataset\n",
    "            continue\n",
    "\n",
    "        # Labelings = subfolders under /<exp>/<dataset>/\n",
    "        labelings = _list_subdirs(exp_dir)\n",
    "\n",
    "        # Gather the union of encodings across all labelings\n",
    "        encodings = set()\n",
    "        for lab in labelings:\n",
    "            for enc_dir in _list_subdirs(lab):\n",
    "                encodings.add(enc_dir.name)\n",
    "\n",
    "        # For each encoding, try to read the runtime for each labeling\n",
    "        for enc in sorted(encodings):\n",
    "            for lab in labelings:\n",
    "                enc_dir = lab / enc\n",
    "                if not enc_dir.exists():\n",
    "                    continue\n",
    "                txt = _choose_txt_file(enc_dir)\n",
    "                if txt is None:\n",
    "                    continue\n",
    "                secs = _read_seconds(txt)\n",
    "                if secs is None:\n",
    "                    continue\n",
    "                rows.append({\n",
    "                    \"experiment\": exp,\n",
    "                    \"labeling\": lab.name,\n",
    "                    \"encoding\": enc,\n",
    "                    \"seconds\": secs,\n",
    "                    \"txt_path\": str(txt),\n",
    "                })\n",
    "\n",
    "    df_runs = pd.DataFrame(rows).sort_values([\"experiment\", \"labeling\", \"encoding\"]).reset_index(drop=True)\n",
    "\n",
    "    # Average over labelings for each (experiment, encoding)\n",
    "    if df_runs.empty:\n",
    "        print(\"No runtimes found. Check the folder structure and .txt files.\")\n",
    "        return df_runs, pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    agg = (\n",
    "        df_runs\n",
    "        .groupby([\"experiment\", \"encoding\"])[\"seconds\"]\n",
    "        .agg(count=\"count\", mean=\"mean\", std=\"std\", min=\"min\", max=\"max\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            \"count\": \"n_labelings\",\n",
    "            \"mean\": \"avg_seconds\",\n",
    "            \"std\": \"std_seconds\",\n",
    "            \"min\": \"min_seconds\",\n",
    "            \"max\": \"max_seconds\",\n",
    "        })\n",
    "    )\n",
    "    # Convenience: also add hours\n",
    "    agg[\"avg_hours\"] = agg[\"avg_seconds\"] / 3600.0\n",
    "\n",
    "    # Wide comparison: rows=encoding, cols=experiment, values=avg_seconds\n",
    "    df_avg_wide = agg.pivot(index=\"encoding\", columns=\"experiment\", values=\"avg_seconds\").sort_index()\n",
    "\n",
    "    # show quick previews\n",
    "    display_cols = [\"experiment\", \"encoding\", \"n_labelings\", \"avg_seconds\", \"avg_hours\"]\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        print(\"Per-run entries (df_runs):\")\n",
    "        display(df_runs)\n",
    "        print(\"\\nAverages per (experiment, encoding) (df_avg):\")\n",
    "        display(agg[display_cols].sort_values([\"experiment\", \"encoding\"]))\n",
    "        print(\"\\nWide comparison of avg seconds by experiment (df_avg_wide):\")\n",
    "        display(df_avg_wide)\n",
    "    except Exception:\n",
    "        # Fallback if display is not available\n",
    "        print(df_runs)\n",
    "        print(agg[display_cols].sort_values([\"experiment\", \"encoding\"]))\n",
    "        print(df_avg_wide)\n",
    "\n",
    "    return df_runs, agg, df_avg_wide\n",
    "\n",
    "# ---- Run ----\n",
    "df_runs, df_avg, df_avg_wide = collect_runtime_averages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert df_avg_wide (avg seconds) → minutes ---\n",
    "if 'df_avg_wide' not in globals():\n",
    "    raise NameError(\"df_avg_wide is not defined. Run the previous cell first.\")\n",
    "\n",
    "df_avg_wide_min = (df_avg_wide / 60).rename_axis(\"encoding\").copy()\n",
    "df_avg_wide_min.columns = [f\"{c} (min)\" for c in df_avg_wide_min.columns]\n",
    "\n",
    "from IPython.display import display\n",
    "display(df_avg_wide_min.round(2))\n",
    "\n",
    "# Optional: persist\n",
    "# df_avg_wide_min.to_csv(\"5_analysis/runtime_averages_wide_minutes.csv\")\n",
    "# To overwrite the original variable:\n",
    "# df_avg_wide = df_avg_wide_min.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a2a2b",
   "metadata": {},
   "source": [
    "## Comparing rules of IPW and Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules_random_path = os.path.join('5_analysis', 'random', 'combined_sorted_all.csv')\n",
    "all_rules_random = pd.read_csv(all_rules_random_path, sep=',')\n",
    "\n",
    "all_rules_ipw_path = os.path.join('5_analysis', 'ipweights', 'combined_sorted_all.csv')\n",
    "all_rules_ipw = pd.read_csv(all_rules_ipw_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_rules(df_in: pd.DataFrame, exclude_list=None) -> pd.DataFrame:\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # Harmonize encoding column name\n",
    "    if 'Encoding' not in df.columns and 'Feature Encoding' in df.columns:\n",
    "        df = df.rename(columns={'Feature Encoding': 'Encoding'})\n",
    "\n",
    "    # Exclude encodings (case/whitespace-insensitive)\n",
    "    if 'Encoding' in df.columns:\n",
    "        excl = {e.lower().strip() for e in (exclude_list or [\"mr\", \"mra\", \"tr\", \"tra\"])}\n",
    "        enc_norm = df['Encoding'].astype(str).str.strip().str.lower()\n",
    "        df = df[~enc_norm.isin(excl)].copy()\n",
    "\n",
    "    # Ensure Odds ratio is numeric and filter OR > 1\n",
    "    if 'Odds ratio' in df.columns:\n",
    "        df['Odds ratio'] = pd.to_numeric(df['Odds ratio'], errors='coerce')\n",
    "        df = df[df['Odds ratio'] > 1].copy()\n",
    "\n",
    "    # ---------- Normalize Labeling ----------\n",
    "    if 'Labeling' in df.columns:\n",
    "        try:\n",
    "            KNOWN_PREFIXES\n",
    "        except NameError:\n",
    "            KNOWN_PREFIXES = set(\n",
    "                df.get('Dataset', pd.Series([], dtype=str))\n",
    "                  .astype(str).str.strip().str.lower()\n",
    "                  .str.replace(r'\\s+', '', regex=True)\n",
    "                  .unique().tolist()\n",
    "            ) | {'sepsis','traffic','bpi15a','bpic15a','bpic2015','bpi2015','bpi15'}\n",
    "\n",
    "        def _strip_prefix_suffix(x: str) -> str:\n",
    "            s = str(x)\n",
    "            s = re.sub(r'(_features?)$', '', s, flags=re.I)\n",
    "            s = s.strip().lower().replace(' ', '_')\n",
    "            changed = True\n",
    "            while changed:\n",
    "                changed = False\n",
    "                for p in sorted(KNOWN_PREFIXES, key=len, reverse=True):\n",
    "                    if s.startswith(p + '_'):\n",
    "                        s = s[len(p) + 1:]\n",
    "                        changed = True\n",
    "            return s\n",
    "\n",
    "        base_series = df['Labeling']\n",
    "        if '_normalize_side' in globals() and callable(globals()['_normalize_side']):\n",
    "            try:\n",
    "                tmp = _normalize_side(df)\n",
    "                if isinstance(tmp, pd.DataFrame):\n",
    "                    if 'Labeling_norm' in tmp.columns:\n",
    "                        base_series = tmp['Labeling_norm']\n",
    "                    elif 'Labeling' in tmp.columns:\n",
    "                        base_series = tmp['Labeling']\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        df['Labeling'] = base_series.apply(_strip_prefix_suffix)\n",
    "        low = df['Labeling'].astype(str).str.lower()\n",
    "        df.loc[low.str.contains('decl', na=False),    'Labeling'] = 'declare'\n",
    "        df.loc[low.str.contains('payload', na=False), 'Labeling'] = 'payload'\n",
    "        df.loc[low.str.contains('mr', na=False),      'Labeling'] = 'sequential'\n",
    "\n",
    "    # ---------- Extract exact LHS and RHS label ----------\n",
    "    def extract_lhs_exact(rule_str: str) -> str:\n",
    "        m = re.search(r\"^(.*?)(?=\\s*-->)\", str(rule_str))\n",
    "        return m.group(1) if m else str(rule_str)\n",
    "\n",
    "    def parse_rhs_label(rule_str: str):\n",
    "        m = re.search(r\"-->\\s*(Label|!Label)\", str(rule_str))\n",
    "        if not m:\n",
    "            return None\n",
    "        return 1 if m.group(1) == \"Label\" else 0\n",
    "\n",
    "    df['LHS_features'] = df['Rule'].apply(extract_lhs_exact)\n",
    "    df['RHS_label']    = df['Rule'].apply(parse_rhs_label)\n",
    "\n",
    "    # ---------- Split LHS into up to 3 features ----------\n",
    "    def _find_outer_brackets_span(text: str):\n",
    "        s = str(text); start = s.find('[')\n",
    "        if start < 0: return (None, None)\n",
    "        depth = 0; in_s = in_d = esc = False; end = None\n",
    "        for i, ch in enumerate(s[start:], start):\n",
    "            if esc: esc = False; continue\n",
    "            if ch == '\\\\': esc = True; continue\n",
    "            if in_s: \n",
    "                if ch == \"'\": in_s = False\n",
    "                continue\n",
    "            if in_d:\n",
    "                if ch == '\"': in_d = False\n",
    "                continue\n",
    "            if ch == \"'\": in_s = True; continue\n",
    "            if ch == '\"': in_d = True; continue\n",
    "            if ch == '[': depth += 1; continue\n",
    "            if ch == ']':\n",
    "                depth -= 1\n",
    "                if depth == 0: end = i; break\n",
    "        return (start, end)\n",
    "\n",
    "    def _split_top_level_commas(content: str):\n",
    "        parts, curr = [], \"\"\n",
    "        in_s = in_d = esc = False\n",
    "        for ch in content:\n",
    "            if esc:\n",
    "                curr += ch; esc = False; continue\n",
    "            if ch == '\\\\':\n",
    "                curr += ch; esc = True; continue\n",
    "            if in_s:\n",
    "                curr += ch\n",
    "                if ch == \"'\": in_s = False\n",
    "                continue\n",
    "            if in_d:\n",
    "                curr += ch\n",
    "                if ch == '\"': in_d = False\n",
    "                continue\n",
    "            if ch == \"'\":\n",
    "                curr += ch; in_s = True; continue\n",
    "            if ch == '\"':\n",
    "                curr += ch; in_d = True; continue\n",
    "            if ch == ',':\n",
    "                parts.append(curr.strip()); curr = \"\"\n",
    "            else:\n",
    "                curr += ch\n",
    "        parts.append(curr.strip())\n",
    "        return parts\n",
    "\n",
    "    def _strip_one_layer_quotes(s_: str):\n",
    "        s_ = s_.strip()\n",
    "        if len(s_) >= 2 and ((s_[0] == s_[-1] == \"'\") or (s_[0] == s_[-1] == '\"')):\n",
    "            return s_[1:-1]\n",
    "        return s_\n",
    "\n",
    "    def split_lhs_items(lhs_text: str):\n",
    "        s = str(lhs_text)\n",
    "        start, end = _find_outer_brackets_span(s)\n",
    "        if start is None or end is None: return []\n",
    "        inner = s[start+1:end]\n",
    "        raw_items = _split_top_level_commas(inner)\n",
    "        return [_strip_one_layer_quotes(x).strip() for x in raw_items if x != \"\"]\n",
    "\n",
    "    def _pad3(items):\n",
    "        items = items[:3]\n",
    "        return items + [\"\"] * (3 - len(items))\n",
    "\n",
    "    lhs_split = df['LHS_features'].apply(split_lhs_items).apply(_pad3)\n",
    "    lhs_df = pd.DataFrame(lhs_split.tolist(), columns=['feature_1_lhs','feature_2_lhs','feature_3_lhs'])\n",
    "\n",
    "    # ---------- Final table (now appending LB odds ratio, Support LHS, Confidence if present) ----------\n",
    "    # Coerce to numeric if they exist (safe no-ops if not present)\n",
    "    for col in ['LB odds ratio', 'Support LHS', 'Confidence']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    base_cols = ['Dataset','Labeling','Encoding','Rule','LHS_features','RHS_label']\n",
    "    extra_cols = [c for c in ['LB odds ratio','Support LHS','Confidence'] if c in df.columns]\n",
    "    select_cols = base_cols + extra_cols\n",
    "\n",
    "    have_cols = [c for c in select_cols if c in (list(df.columns) + ['LHS_features','RHS_label'])]\n",
    "    out = pd.concat(\n",
    "        [df[have_cols].reset_index(drop=True), lhs_df.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    sort_cols = [c for c in ['Dataset','Labeling','Encoding'] if c in out.columns]\n",
    "    if sort_cols:\n",
    "        out = out.sort_values(by=sort_cols, ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------- Build the two expanded DataFrames ----------\n",
    "if 'all_rules_random' not in globals() or not isinstance(all_rules_random, pd.DataFrame):\n",
    "    raise ValueError(\"all_rules_random is not available as a DataFrame.\")\n",
    "if 'all_rules_ipw' not in globals() or not isinstance(all_rules_ipw, pd.DataFrame):\n",
    "    raise ValueError(\"all_rules_ipw is not available as a DataFrame.\")\n",
    "\n",
    "random_rules_all_expanded = expand_rules(all_rules_random, exclude_encodings)\n",
    "ipw_rules_all_expanded    = expand_rules(all_rules_ipw,    exclude_encodings)\n",
    "\n",
    "display(random_rules_all_expanded)\n",
    "display(ipw_rules_all_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf722d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Find rules unique to each DF, with extra (RHS_label, feature_1_lhs) check ----------\n",
    "\n",
    "def _prepare_sets(df):\n",
    "    # Make comparable representations\n",
    "    rules = set(df['Rule'].astype(str))\n",
    "    pairs = set(zip(df['RHS_label'], df['feature_1_lhs'].astype(str).str.strip()))\n",
    "    return rules, pairs\n",
    "\n",
    "def _unique_after_pair_check(dfA, dfB, source_name):\n",
    "    \"\"\"\n",
    "    Keep rows from dfA whose Rule is not in dfB.\n",
    "    Then drop rows whose (RHS_label, feature_1_lhs) pair appears in dfB.\n",
    "    Return Dataset, Labeling, Encoding, Rule + requested metrics (if present) + Source.\n",
    "    \"\"\"\n",
    "    # Ensure necessary columns exist\n",
    "    needed = {'Dataset','Labeling','Encoding','Rule','RHS_label','feature_1_lhs'}\n",
    "    missingA = needed - set(dfA.columns)\n",
    "    missingB = {'Rule','RHS_label','feature_1_lhs'} - set(dfB.columns)\n",
    "    if missingA:\n",
    "        raise KeyError(f\"{source_name}: missing columns in dfA: {sorted(missingA)}\")\n",
    "    if missingB:\n",
    "        raise KeyError(f\"{source_name}: missing columns in dfB: {sorted(missingB)}\")\n",
    "\n",
    "    rules_B, pairs_B = _prepare_sets(dfB)\n",
    "\n",
    "    # Step 1: unique by full Rule string\n",
    "    mask_rule_unique = ~dfA['Rule'].astype(str).isin(rules_B)\n",
    "    cand = dfA.loc[mask_rule_unique].copy()\n",
    "\n",
    "    # Step 2: remove those whose (RHS_label, feature_1_lhs) pair appears in dfB\n",
    "    cand['_pair'] = list(zip(cand['RHS_label'], cand['feature_1_lhs'].astype(str).str.strip()))\n",
    "    cand = cand[~cand['_pair'].isin(pairs_B)].drop(columns=['_pair'])\n",
    "\n",
    "    # Choose metric cols if they exist\n",
    "    metric_cols = [c for c in ['LB odds ratio', 'Support LHS', 'Confidence'] if c in cand.columns]\n",
    "    # Optional: ensure numeric\n",
    "    for c in metric_cols:\n",
    "        cand[c] = pd.to_numeric(cand[c], errors='coerce')\n",
    "\n",
    "    base_cols = ['Dataset','Labeling','Encoding','Rule']\n",
    "    select_cols = base_cols + metric_cols\n",
    "\n",
    "    # Keep only requested columns, dedupe by base rule identity\n",
    "    out = (\n",
    "        cand[select_cols]\n",
    "        .drop_duplicates(subset=base_cols)\n",
    "        .copy()\n",
    "    )\n",
    "    out.insert(0, 'Variant', source_name)\n",
    "    return out\n",
    "\n",
    "# Compute unique sets\n",
    "unique_random_rules = _unique_after_pair_check( random_rules_all_expanded, ipw_rules_all_expanded, source_name='random' )\n",
    "unique_ipw_rules = _unique_after_pair_check( ipw_rules_all_expanded, random_rules_all_expanded, source_name='ipw' )\n",
    "\n",
    "# Combined (optional)\n",
    "combined_unique_rules = (\n",
    "    pd.concat([unique_random_rules, unique_ipw_rules], ignore_index=True)\n",
    "      .sort_values(['Variant','Dataset','Labeling', 'LB odds ratio','Encoding'], ascending=[True,True,True,False,True])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "combined_unique_rules\n",
    "#unique_ipw_rules.sort_values(['Dataset','Labeling', 'LB odds ratio','Encoding'], ascending=[True,True,False,True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43831c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save LaTeX\n",
    "out_fp_tex = os.path.join(root_dir, 'combined_unique_rules_ipw.tex')\n",
    "\n",
    "def fmt_rule(x):\n",
    "    return r'\\detokenize{' + str(x) + '}'\n",
    "\n",
    "combined_unique_rules.to_latex(\n",
    "    out_fp_tex,\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    longtable=True,\n",
    "    float_format=\"%.2f\",\n",
    "    formatters={\n",
    "        \"Rule\": fmt_rule,\n",
    "        \"Encoding\": fmt_rule\n",
    "    }\n",
    ")\n",
    "print(f\"✅ Saved combined_sorted_all.tex → {out_fp_tex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a summarized version of combined_unique_rules for each variant with total number of rules per labeling, en encoding\n",
    "summary_random = (\n",
    "    unique_random_rules\n",
    "    .groupby(['Labeling'])\n",
    "    .size()\n",
    "    .reset_index(name='num_unique_rules')\n",
    "    .sort_values(['Labeling','num_unique_rules'], ascending=[True,False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "summary_ipw = (\n",
    "    unique_ipw_rules\n",
    "    .groupby(['Labeling'])\n",
    "    .size()\n",
    "    .reset_index(name='num_unique_rules')\n",
    "    .sort_values(['Labeling','num_unique_rules'], ascending=[True,False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(summary_random)\n",
    "display(summary_ipw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
